{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e(i, d):\n",
    "    ei = np.zeros(d)\n",
    "    ei[i] = 1\n",
    "    return ei\n",
    "\n",
    "\n",
    "\n",
    "def KWSA(F, w, m, c, d):\n",
    "    \"\"\" \n",
    "    Kiefer-Wolfowitz stochastic approximation\n",
    "    for gradient estimation \n",
    "    \n",
    "    INPUT:\n",
    "    - F: objective function\n",
    "    - w: current weight\n",
    "    - m: sample size (null in this case)\n",
    "    - d: dimension\n",
    "    - c: costant\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    F_wc = np.array([F(w + c * e(i, d)) for i in range(d)])\n",
    "    return (F_wc - F(w)) / c\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def IRDSA(F, w, m, c, d):\n",
    "    \"\"\" \n",
    "    Improvised Random Direction stochastic approximation\n",
    "    for gradient estimation \n",
    "    \n",
    "    INPUT:\n",
    "    - F: objective function\n",
    "    - w: current weight\n",
    "    - m: sample dimension\n",
    "    - d: features dimension\n",
    "    - c: costant\n",
    "    \n",
    "    \"\"\"\n",
    "    z = np.random.normal(0, 1, (d, m))\n",
    "    F_w = F(w)\n",
    "    return np.mean([(F(w + c * z[:,i]) - F_w) / c * z[:,i] for i in range(m)], axis = 0)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def detZFW(F, L, d, w0, r=1, T=100, eps=1e-5):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    - F: loss function\n",
    "    - L: Lip constant\n",
    "    - d: dimension\n",
    "    - w0: starting point\n",
    "    - r: radius of the ball\n",
    "    - T: max iteration\n",
    "    - eps: tolerance\n",
    "    \"\"\"\n",
    "\n",
    "    gamma = lambda t: 2/(t+2)\n",
    "    c = lambda t: L*gamma(t)/d\n",
    "    w = w0\n",
    "    partial = 0\n",
    "    for t in range(1, T+1):\n",
    "        # comupute the gradient approx\n",
    "        gt = KWSA(F, w, None, c(t), d)\n",
    "        # compute the linear problem solution on the L1 Ball of radius r\n",
    "        i_k = np.argmax(np.abs(gt))\n",
    "        ei = e(i_k, d) * r\n",
    "        v = np.sign(-gt[i_k]) * ei\n",
    "        # compute step \n",
    "        w_pred = w\n",
    "        w = (1 - gamma(t)) * w + gamma(t) * v\n",
    "        partial += w\n",
    "        loss_eval = F(w_pred) - F(w)\n",
    "        print(f\"Loss evaluation at time {t}:\\t{loss_eval:.4f}\\n\")\n",
    "        if loss_eval < eps: break # check stopping condition\n",
    "    return F(w_pred), F(w), w, partial/T, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X, y = datasets.load_svmlight_file(\"../Data/covtype.libsvm.binary.scale.bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space Dimensions\n",
      "d: 54\n",
      "n: 581012\n"
     ]
    }
   ],
   "source": [
    "# space dimension\n",
    "d = X.shape[1]\n",
    "print(f\"Space Dimensions\\nd: {d}\")\n",
    "print(f\"n: {y.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w_star = np.linalg.inv(X * X.T) * X * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the objective function\n",
    "F = lambda w: 0.5 * np.sum(np.power(y - X @ w, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L: 6.401824257555926\n"
     ]
    }
   ],
   "source": [
    "# initialize prarameters for the algorithm\n",
    "\n",
    "# stating point \n",
    "np.random.seed(1007)\n",
    "w0 = np.random.rand(d)\n",
    "w0 = w0/np.sum(w0) * np.random.rand(1)\n",
    "#print(w0)\n",
    "#print(F(w0))\n",
    "\n",
    "# Lipschitz constant computation\n",
    "L = 2/X.shape[0] * norm(X.T @ X)\n",
    "print(f\"L: {L}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss evaluation at time 1:\t343218.6203\n",
      "\n",
      "Loss evaluation at time 2:\t60852.1867\n",
      "\n",
      "Loss evaluation at time 3:\t21546.1982\n",
      "\n",
      "Loss evaluation at time 4:\t10174.2399\n",
      "\n",
      "Loss evaluation at time 5:\t5634.6010\n",
      "\n",
      "Loss evaluation at time 6:\t3455.4252\n",
      "\n",
      "Loss evaluation at time 7:\t2275.3260\n",
      "\n",
      "Loss evaluation at time 8:\t1579.2618\n",
      "\n",
      "Loss evaluation at time 9:\t1141.5884\n",
      "\n",
      "Loss evaluation at time 10:\t852.3419\n",
      "\n",
      "Loss evaluation at time 11:\t653.4024\n",
      "\n",
      "Loss evaluation at time 12:\t512.0179\n",
      "\n",
      "Loss evaluation at time 13:\t408.7466\n",
      "\n",
      "Loss evaluation at time 14:\t331.5386\n",
      "\n",
      "Loss evaluation at time 15:\t272.6494\n",
      "\n",
      "Loss evaluation at time 16:\t226.9440\n",
      "\n",
      "Loss evaluation at time 17:\t190.9247\n",
      "\n",
      "Loss evaluation at time 18:\t162.1523\n",
      "\n",
      "Loss evaluation at time 19:\t138.8899\n",
      "\n",
      "Loss evaluation at time 20:\t119.8777\n",
      "\n",
      "Loss evaluation at time 21:\t104.1867\n",
      "\n",
      "Loss evaluation at time 22:\t91.1216\n",
      "\n",
      "Loss evaluation at time 23:\t80.1548\n",
      "\n",
      "Loss evaluation at time 24:\t70.8810\n",
      "\n",
      "Loss evaluation at time 25:\t62.9855\n",
      "\n",
      "Loss evaluation at time 26:\t56.2213\n",
      "\n",
      "Loss evaluation at time 27:\t50.3926\n",
      "\n",
      "Loss evaluation at time 28:\t45.3431\n",
      "\n",
      "Loss evaluation at time 29:\t40.9468\n",
      "\n",
      "Loss evaluation at time 30:\t37.1012\n",
      "\n",
      "Loss evaluation at time 31:\t33.7227\n",
      "\n",
      "Loss evaluation at time 32:\t30.7425\n",
      "\n",
      "Loss evaluation at time 33:\t28.1035\n",
      "\n",
      "Loss evaluation at time 34:\t25.7583\n",
      "\n",
      "Loss evaluation at time 35:\t23.6670\n",
      "\n",
      "Loss evaluation at time 36:\t21.7962\n",
      "\n",
      "Loss evaluation at time 37:\t20.1176\n",
      "\n",
      "Loss evaluation at time 38:\t18.6071\n",
      "\n",
      "Loss evaluation at time 39:\t17.2441\n",
      "\n",
      "Loss evaluation at time 40:\t16.0111\n",
      "\n",
      "Loss evaluation at time 41:\t14.8930\n",
      "\n",
      "Loss evaluation at time 42:\t13.8766\n",
      "\n",
      "Loss evaluation at time 43:\t12.9507\n",
      "\n",
      "Loss evaluation at time 44:\t12.1054\n",
      "\n",
      "Loss evaluation at time 45:\t11.3321\n",
      "\n",
      "Loss evaluation at time 46:\t10.6233\n",
      "\n",
      "Loss evaluation at time 47:\t9.9724\n",
      "\n",
      "Loss evaluation at time 48:\t9.3736\n",
      "\n",
      "Loss evaluation at time 49:\t8.8218\n",
      "\n",
      "Loss evaluation at time 50:\t8.3125\n",
      "\n",
      "Loss evaluation at time 51:\t7.8417\n",
      "\n",
      "Loss evaluation at time 52:\t7.4058\n",
      "\n",
      "Loss evaluation at time 53:\t7.0016\n",
      "\n",
      "Loss evaluation at time 54:\t6.6263\n",
      "\n",
      "Loss evaluation at time 55:\t6.2774\n",
      "\n",
      "Loss evaluation at time 56:\t5.9525\n",
      "\n",
      "Loss evaluation at time 57:\t5.6497\n",
      "\n",
      "Loss evaluation at time 58:\t5.3671\n",
      "\n",
      "Loss evaluation at time 59:\t5.1030\n",
      "\n",
      "Loss evaluation at time 60:\t4.8559\n",
      "\n",
      "Loss evaluation at time 61:\t4.6246\n",
      "\n",
      "Loss evaluation at time 62:\t4.4077\n",
      "\n",
      "Loss evaluation at time 63:\t4.2042\n",
      "\n",
      "Loss evaluation at time 64:\t4.0130\n",
      "\n",
      "Loss evaluation at time 65:\t3.8333\n",
      "\n",
      "Loss evaluation at time 66:\t3.6641\n",
      "\n",
      "Loss evaluation at time 67:\t3.5047\n",
      "\n",
      "Loss evaluation at time 68:\t3.3545\n",
      "\n",
      "Loss evaluation at time 69:\t3.2127\n",
      "\n",
      "Loss evaluation at time 70:\t3.0788\n",
      "\n",
      "Loss evaluation at time 71:\t2.9522\n",
      "\n",
      "Loss evaluation at time 72:\t2.8325\n",
      "\n",
      "Loss evaluation at time 73:\t2.7191\n",
      "\n",
      "Loss evaluation at time 74:\t2.6118\n",
      "\n",
      "Loss evaluation at time 75:\t2.5100\n",
      "\n",
      "Loss evaluation at time 76:\t2.4134\n",
      "\n",
      "Loss evaluation at time 77:\t2.3217\n",
      "\n",
      "Loss evaluation at time 78:\t2.2347\n",
      "\n",
      "Loss evaluation at time 79:\t2.1519\n",
      "\n",
      "Loss evaluation at time 80:\t2.0731\n",
      "\n",
      "Loss evaluation at time 81:\t1.9982\n",
      "\n",
      "Loss evaluation at time 82:\t1.9268\n",
      "\n",
      "Loss evaluation at time 83:\t1.8588\n",
      "\n",
      "Loss evaluation at time 84:\t1.7939\n",
      "\n",
      "Loss evaluation at time 85:\t1.7320\n",
      "\n",
      "Loss evaluation at time 86:\t1.6730\n",
      "\n",
      "Loss evaluation at time 87:\t1.6166\n",
      "\n",
      "Loss evaluation at time 88:\t1.5627\n",
      "\n",
      "Loss evaluation at time 89:\t1.5111\n",
      "\n",
      "Loss evaluation at time 90:\t1.4619\n",
      "\n",
      "Loss evaluation at time 91:\t1.4147\n",
      "\n",
      "Loss evaluation at time 92:\t1.3695\n",
      "\n",
      "Loss evaluation at time 93:\t1.3263\n",
      "\n",
      "Loss evaluation at time 94:\t1.2848\n",
      "\n",
      "Loss evaluation at time 95:\t1.2451\n",
      "\n",
      "Loss evaluation at time 96:\t1.2070\n",
      "\n",
      "Loss evaluation at time 97:\t1.1704\n",
      "\n",
      "Loss evaluation at time 98:\t1.1353\n",
      "\n",
      "Loss evaluation at time 99:\t1.1015\n",
      "\n",
      "Loss evaluation at time 100:\t1.0691\n",
      "\n",
      "CPU times: user 1min 33s, sys: 1.24 s, total: 1min 34s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fpred, f, w_det, mean, t = detZFW(F, L, d, w0, T=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT:\n",
      "\n",
      "F(w_pred) = 179684.5113658399\n",
      "\n",
      "F(w) = 179683.44223484417\n",
      "\n",
      "w = [2.77132211e-06 4.02983567e-06 3.08795393e-08 3.61756009e-06\n",
      " 2.69784349e-06 1.33729259e-06 3.56824604e-06 9.99808524e-01\n",
      " 3.75108695e-06 2.87166285e-06 3.92599860e-06 8.70501166e-07\n",
      " 1.45329881e-06 2.60587958e-06 2.46921740e-06 4.83692308e-06\n",
      " 3.96307199e-06 5.32262194e-08 1.63464558e-06 1.77673727e-06\n",
      " 4.14304857e-06 3.51816278e-06 4.02127965e-06 4.21880637e-07\n",
      " 4.91732298e-06 4.98055814e-06 3.62418132e-06 8.70545149e-07\n",
      " 2.30748277e-06 1.89517021e-06 4.86767458e-06 8.97616203e-07\n",
      " 4.09760962e-06 2.50305167e-06 9.36964163e-07 1.58319234e-06\n",
      " 3.75474925e-06 4.66322230e-07 2.68929516e-06 5.09959305e-07\n",
      " 4.26252570e-06 4.95833253e-06 2.29084708e-06 1.23152751e-06\n",
      " 1.08541133e-06 4.25249003e-06 3.62232723e-06 4.27706155e-06\n",
      " 2.70622791e-06 2.62828100e-07 8.66572037e-07 1.18812470e-06\n",
      " 2.15455175e-06 4.23199472e-06]\n",
      "\n",
      "average w = [1.39951766e-04 2.03506701e-04 1.55941674e-06 1.82686785e-04\n",
      " 1.36241096e-04 6.75332759e-05 1.80196425e-04 9.90330476e-01\n",
      " 1.89429891e-04 1.45018974e-04 1.98262929e-04 4.39603089e-05\n",
      " 7.33915900e-05 1.31596919e-04 1.24695479e-04 2.44264616e-04\n",
      " 2.00135135e-04 2.68792408e-06 8.25496016e-05 8.97252321e-05\n",
      " 2.09223953e-04 1.77667220e-04 2.03074622e-04 2.13049722e-05\n",
      " 2.48324811e-04 2.51518186e-04 1.83021157e-04 4.39625300e-05\n",
      " 1.16527880e-04 9.57060956e-05 2.45817567e-04 4.53296183e-05\n",
      " 2.06929286e-04 1.26404109e-04 4.73166902e-05 7.99512133e-05\n",
      " 1.89614837e-04 2.35492726e-05 1.35809405e-04 2.57529449e-05\n",
      " 2.15257548e-04 2.50395793e-04 1.15687778e-04 6.21921392e-05\n",
      " 5.48132723e-05 2.14750747e-04 1.82927525e-04 2.15991608e-04\n",
      " 1.36664510e-04 1.32728190e-05 4.37618879e-05 6.00002974e-05\n",
      " 1.08804863e-04 2.13715733e-04]\n",
      "\n",
      "T = 100\n"
     ]
    }
   ],
   "source": [
    "print(f'OUTPUT:\\n\\nF(w_pred) = {fpred}\\n\\nF(w) = {f}\\n\\nw = {w_det}\\n\\naverage w = {mean}\\n\\nT = {t}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Free Frank Wolfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochasticZFW(F, d,  w0, method = \"IRDSA\", r=1, T=100, eps=1e-5):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    - F: loss function\n",
    "    - d: dimension\n",
    "    - w0: starting point\n",
    "    - method: zeroth order oracle\n",
    "    - r: radius of the ball\n",
    "    - T: max iteration\n",
    "    - eps: tolerance\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters_dict = {\"KWSA\": {\"m\": None, \n",
    "                                \"c\": lambda t: 2 / (np.sqrt(d) * np.power(t+8, 1/3)),\n",
    "                                \"p\": lambda t: 4 / np.power(t+8, 2/3),\n",
    "                                \"oracle\": KWSA},\n",
    "                       \n",
    "                   \n",
    "                       \"RDSA\": {\"m\": 1, \n",
    "                                \"c\": lambda t: 2 / (np.power(d, 3/2) * np.power(t+8, 1/3)),\n",
    "                                \"p\": lambda t: 4 / (np.power(d, 1/3) * np.power(t+8, 2/3)),\n",
    "                                \"oracle\": IRDSA},\n",
    "                   \n",
    "                       \"IRDSA\": {\"m\": 6, \n",
    "                                \"c\": lambda t: 2 * np.sqrt(6) / (np.power(d, 3/2) * np.power(t+8, 1/3)),\n",
    "                                \"p\": lambda t: 4 / (np.power(1+d/6, 1/3) * np.power(t+8, 2/3)),\n",
    "                                \"oracle\": IRDSA}\n",
    "                  \n",
    "                        }\n",
    "    \n",
    "    return sZFW(F, d, w0, Parameters_dict[method], r, T, eps)\n",
    "    \n",
    "  \n",
    "\n",
    "    \n",
    "def sZFW(F, d, w0, params, r, T, eps):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    - F: loss function\n",
    "    - d: dimension\n",
    "    - w0: starting point\n",
    "    - params: dict of parameters for the selected method\n",
    "    - r: radius of the ball\n",
    "    - T: max iteration\n",
    "    - eps: tolerance\n",
    "    \"\"\"\n",
    "    \n",
    "    loss = []\n",
    "    gamma = lambda t: 2/(t+8)\n",
    "    w = w0\n",
    "    dt = np.zeros(d)\n",
    "    partial = 0\n",
    "    for t in range(1, T+1):\n",
    "        # comupute the gradient approx\n",
    "        gt = params[\"oracle\"](F, w, params[\"m\"], params[\"c\"](t), d)\n",
    "        dt = (1 - params[\"p\"](t)) * dt + params[\"p\"](t) * gt\n",
    "        # compute the linear problem solution on the L1 Ball of radius r\n",
    "        ei = e(np.argmax(np.abs(dt)), d) * r\n",
    "        v = np.sign(-dt) * ei\n",
    "        # compute step \n",
    "        w_pred = w\n",
    "        w = (1 - gamma(t)) * w + gamma(t) * v\n",
    "        partial += w\n",
    "        loss_eval = np.abs(F(w_pred) - F(w))\n",
    "        loss.append(loss_eval)\n",
    "        print(f\"Loss evaluation at time {t}:\\t{loss_eval:.4f}\\n\")\n",
    "        if loss_eval < eps: break # check stopping condition\n",
    "    return F(w_pred), F(w), w, partial/T, t, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss evaluation at time 1:\t23520.7633\n",
      "\n",
      "Loss evaluation at time 2:\t68256.0980\n",
      "\n",
      "Loss evaluation at time 3:\t35400.1179\n",
      "\n",
      "Loss evaluation at time 4:\t5251.6896\n",
      "\n",
      "Loss evaluation at time 5:\t68175.9540\n",
      "\n",
      "Loss evaluation at time 6:\t32987.8042\n",
      "\n",
      "Loss evaluation at time 7:\t52528.1515\n",
      "\n",
      "Loss evaluation at time 8:\t15011.0693\n",
      "\n",
      "Loss evaluation at time 9:\t11947.4145\n",
      "\n",
      "Loss evaluation at time 10:\t31412.1975\n",
      "\n",
      "Loss evaluation at time 11:\t22820.9349\n",
      "\n",
      "Loss evaluation at time 12:\t2880.4525\n",
      "\n",
      "Loss evaluation at time 13:\t17452.3038\n",
      "\n",
      "Loss evaluation at time 14:\t14552.4723\n",
      "\n",
      "Loss evaluation at time 15:\t12262.5886\n",
      "\n",
      "Loss evaluation at time 16:\t10430.8393\n",
      "\n",
      "Loss evaluation at time 17:\t10735.7815\n",
      "\n",
      "Loss evaluation at time 18:\t9265.6786\n",
      "\n",
      "Loss evaluation at time 19:\t8053.8229\n",
      "\n",
      "Loss evaluation at time 20:\t7045.8984\n",
      "\n",
      "Loss evaluation at time 21:\t6200.7023\n",
      "\n",
      "Loss evaluation at time 22:\t5486.6113\n",
      "\n",
      "Loss evaluation at time 23:\t4879.0894\n",
      "\n",
      "Loss evaluation at time 24:\t4358.9075\n",
      "\n",
      "Loss evaluation at time 25:\t3910.8544\n",
      "\n",
      "Loss evaluation at time 26:\t2474.8142\n",
      "\n",
      "Loss evaluation at time 27:\t2226.1146\n",
      "\n",
      "Loss evaluation at time 28:\t2009.9155\n",
      "\n",
      "Loss evaluation at time 29:\t1821.0679\n",
      "\n",
      "Loss evaluation at time 30:\t1655.3697\n",
      "\n",
      "Loss evaluation at time 31:\t1509.3692\n",
      "\n",
      "Loss evaluation at time 32:\t1380.2141\n",
      "\n",
      "Loss evaluation at time 33:\t1265.5335\n",
      "\n",
      "Loss evaluation at time 34:\t1163.3462\n",
      "\n",
      "Loss evaluation at time 35:\t1071.9880\n",
      "\n",
      "Loss evaluation at time 36:\t990.0539\n",
      "\n",
      "Loss evaluation at time 37:\t916.3527\n",
      "\n",
      "Loss evaluation at time 38:\t849.8696\n",
      "\n",
      "Loss evaluation at time 39:\t789.7368\n",
      "\n",
      "Loss evaluation at time 40:\t735.2090\n",
      "\n",
      "Loss evaluation at time 41:\t685.6437\n",
      "\n",
      "Loss evaluation at time 42:\t1471.8326\n",
      "\n",
      "Loss evaluation at time 43:\t570.6282\n",
      "\n",
      "Loss evaluation at time 44:\t534.2523\n",
      "\n",
      "Loss evaluation at time 45:\t500.9384\n",
      "\n",
      "Loss evaluation at time 46:\t1239.6897\n",
      "\n",
      "Loss evaluation at time 47:\t417.7315\n",
      "\n",
      "Loss evaluation at time 48:\t1127.6945\n",
      "\n",
      "Loss evaluation at time 49:\t1059.6937\n",
      "\n",
      "Loss evaluation at time 50:\t997.1088\n",
      "\n",
      "Loss evaluation at time 51:\t939.4090\n",
      "\n",
      "Loss evaluation at time 52:\t886.1244\n",
      "\n",
      "Loss evaluation at time 53:\t204.1538\n",
      "\n",
      "Loss evaluation at time 54:\t191.9464\n",
      "\n",
      "Loss evaluation at time 55:\t4189.5528\n",
      "\n",
      "Loss evaluation at time 56:\t938.4947\n",
      "\n",
      "Loss evaluation at time 57:\t889.1358\n",
      "\n",
      "Loss evaluation at time 58:\t843.2159\n",
      "\n",
      "Loss evaluation at time 59:\t800.4390\n",
      "\n",
      "Loss evaluation at time 60:\t760.5394\n",
      "\n",
      "Loss evaluation at time 61:\t2852.2238\n",
      "\n",
      "Loss evaluation at time 62:\t2774.4085\n",
      "\n",
      "Loss evaluation at time 63:\t345.8358\n",
      "\n",
      "Loss evaluation at time 64:\t328.3758\n",
      "\n",
      "Loss evaluation at time 65:\t312.0771\n",
      "\n",
      "Loss evaluation at time 66:\t296.8450\n",
      "\n",
      "Loss evaluation at time 67:\t282.5939\n",
      "\n",
      "Loss evaluation at time 68:\t269.2461\n",
      "\n",
      "Loss evaluation at time 69:\t256.7314\n",
      "\n",
      "Loss evaluation at time 70:\t244.9857\n",
      "\n",
      "Loss evaluation at time 71:\t2423.6586\n",
      "\n",
      "Loss evaluation at time 72:\t298.2544\n",
      "\n",
      "Loss evaluation at time 73:\t285.3218\n",
      "\n",
      "Loss evaluation at time 74:\t749.1319\n",
      "\n",
      "Loss evaluation at time 75:\t252.4067\n",
      "\n",
      "Loss evaluation at time 76:\t2269.3148\n",
      "\n",
      "Loss evaluation at time 77:\t298.3966\n",
      "\n",
      "Loss evaluation at time 78:\t736.9708\n",
      "\n",
      "Loss evaluation at time 79:\t266.4929\n",
      "\n",
      "Loss evaluation at time 80:\t694.8160\n",
      "\n",
      "Loss evaluation at time 81:\t237.8524\n",
      "\n",
      "Loss evaluation at time 82:\t228.4279\n",
      "\n",
      "Loss evaluation at time 83:\t219.4985\n",
      "\n",
      "Loss evaluation at time 84:\t211.0322\n",
      "\n",
      "Loss evaluation at time 85:\t202.9992\n",
      "\n",
      "Loss evaluation at time 86:\t195.3722\n",
      "\n",
      "Loss evaluation at time 87:\t188.1258\n",
      "\n",
      "Loss evaluation at time 88:\t592.8332\n",
      "\n",
      "Loss evaluation at time 89:\t571.9986\n",
      "\n",
      "Loss evaluation at time 90:\t552.1400\n",
      "\n",
      "Loss evaluation at time 91:\t533.2006\n",
      "\n",
      "Loss evaluation at time 92:\t2208.6437\n",
      "\n",
      "Loss evaluation at time 93:\t2162.9747\n",
      "\n",
      "Loss evaluation at time 94:\t598.3050\n",
      "\n",
      "Loss evaluation at time 95:\t578.7091\n",
      "\n",
      "Loss evaluation at time 96:\t559.9697\n",
      "\n",
      "Loss evaluation at time 97:\t542.0402\n",
      "\n",
      "Loss evaluation at time 98:\t524.8771\n",
      "\n",
      "Loss evaluation at time 99:\t508.4395\n",
      "\n",
      "Loss evaluation at time 100:\t147.8907\n",
      "\n",
      "Loss evaluation at time 101:\t142.7485\n",
      "\n",
      "Loss evaluation at time 102:\t137.8413\n",
      "\n",
      "Loss evaluation at time 103:\t133.1560\n",
      "\n",
      "Loss evaluation at time 104:\t467.1473\n",
      "\n",
      "Loss evaluation at time 105:\t453.2408\n",
      "\n",
      "Loss evaluation at time 106:\t439.8873\n",
      "\n",
      "Loss evaluation at time 107:\t427.0595\n",
      "\n",
      "Loss evaluation at time 108:\t414.7316\n",
      "\n",
      "Loss evaluation at time 109:\t402.8793\n",
      "\n",
      "Loss evaluation at time 110:\t391.4798\n",
      "\n",
      "Loss evaluation at time 111:\t380.5114\n",
      "\n",
      "Loss evaluation at time 112:\t369.9538\n",
      "\n",
      "Loss evaluation at time 113:\t359.7879\n",
      "\n",
      "Loss evaluation at time 114:\t349.9955\n",
      "\n",
      "Loss evaluation at time 115:\t340.5595\n",
      "\n",
      "Loss evaluation at time 116:\t331.4638\n",
      "\n",
      "Loss evaluation at time 117:\t322.6929\n",
      "\n",
      "Loss evaluation at time 118:\t314.2325\n",
      "\n",
      "Loss evaluation at time 119:\t306.0688\n",
      "\n",
      "Loss evaluation at time 120:\t298.1888\n",
      "\n",
      "Loss evaluation at time 121:\t21.5650\n",
      "\n",
      "Loss evaluation at time 122:\t20.1546\n",
      "\n",
      "Loss evaluation at time 123:\t18.8218\n",
      "\n",
      "Loss evaluation at time 124:\t284.5844\n",
      "\n",
      "Loss evaluation at time 125:\t277.5053\n",
      "\n",
      "Loss evaluation at time 126:\t270.6619\n",
      "\n",
      "Loss evaluation at time 127:\t6.3278\n",
      "\n",
      "Loss evaluation at time 128:\t5.3845\n",
      "\n",
      "Loss evaluation at time 129:\t4.4978\n",
      "\n",
      "Loss evaluation at time 130:\t3.6644\n",
      "\n",
      "Loss evaluation at time 131:\t2.8811\n",
      "\n",
      "Loss evaluation at time 132:\t2.1450\n",
      "\n",
      "Loss evaluation at time 133:\t1.4535\n",
      "\n",
      "Loss evaluation at time 134:\t0.8040\n",
      "\n",
      "Loss evaluation at time 135:\t0.1940\n",
      "\n",
      "Loss evaluation at time 136:\t0.3786\n",
      "\n",
      "Loss evaluation at time 137:\t0.9160\n",
      "\n",
      "Loss evaluation at time 138:\t1.4202\n",
      "\n",
      "Loss evaluation at time 139:\t1.8931\n",
      "\n",
      "Loss evaluation at time 140:\t2.3364\n",
      "\n",
      "Loss evaluation at time 141:\t2.7519\n",
      "\n",
      "Loss evaluation at time 142:\t3.1409\n",
      "\n",
      "Loss evaluation at time 143:\t242.8747\n",
      "\n",
      "Loss evaluation at time 144:\t237.4370\n",
      "\n",
      "Loss evaluation at time 145:\t232.1623\n",
      "\n",
      "Loss evaluation at time 146:\t11.4476\n",
      "\n",
      "Loss evaluation at time 147:\t11.6521\n",
      "\n",
      "Loss evaluation at time 148:\t11.8377\n",
      "\n",
      "Loss evaluation at time 149:\t12.0057\n",
      "\n",
      "Loss evaluation at time 150:\t12.1571\n",
      "\n",
      "Loss evaluation at time 151:\t12.2928\n",
      "\n",
      "Loss evaluation at time 152:\t12.4139\n",
      "\n",
      "Loss evaluation at time 153:\t12.5211\n",
      "\n",
      "Loss evaluation at time 154:\t12.6154\n",
      "\n",
      "Loss evaluation at time 155:\t12.6974\n",
      "\n",
      "Loss evaluation at time 156:\t12.7679\n",
      "\n",
      "Loss evaluation at time 157:\t12.8276\n",
      "\n",
      "Loss evaluation at time 158:\t12.8772\n",
      "\n",
      "Loss evaluation at time 159:\t12.9172\n",
      "\n",
      "Loss evaluation at time 160:\t12.9483\n",
      "\n",
      "Loss evaluation at time 161:\t12.9710\n",
      "\n",
      "Loss evaluation at time 162:\t213.6963\n",
      "\n",
      "Loss evaluation at time 163:\t209.3452\n",
      "\n",
      "Loss evaluation at time 164:\t205.1126\n",
      "\n",
      "Loss evaluation at time 165:\t19.0405\n",
      "\n",
      "Loss evaluation at time 166:\t18.9618\n",
      "\n",
      "Loss evaluation at time 167:\t18.8778\n",
      "\n",
      "Loss evaluation at time 168:\t18.7889\n",
      "\n",
      "Loss evaluation at time 169:\t198.5745\n",
      "\n",
      "Loss evaluation at time 170:\t194.6815\n",
      "\n",
      "Loss evaluation at time 171:\t190.8907\n",
      "\n",
      "Loss evaluation at time 172:\t187.1987\n",
      "\n",
      "Loss evaluation at time 173:\t183.6023\n",
      "\n",
      "Loss evaluation at time 174:\t180.0983\n",
      "\n",
      "Loss evaluation at time 175:\t176.6839\n",
      "\n",
      "Loss evaluation at time 176:\t173.3562\n",
      "\n",
      "Loss evaluation at time 177:\t170.1124\n",
      "\n",
      "Loss evaluation at time 178:\t166.9498\n",
      "\n",
      "Loss evaluation at time 179:\t163.8661\n",
      "\n",
      "Loss evaluation at time 180:\t35.4888\n",
      "\n",
      "Loss evaluation at time 181:\t160.6750\n",
      "\n",
      "Loss evaluation at time 182:\t36.4037\n",
      "\n",
      "Loss evaluation at time 183:\t157.5976\n",
      "\n",
      "Loss evaluation at time 184:\t154.7626\n",
      "\n",
      "Loss evaluation at time 185:\t151.9961\n",
      "\n",
      "Loss evaluation at time 186:\t149.2958\n",
      "\n",
      "Loss evaluation at time 187:\t146.6597\n",
      "\n",
      "Loss evaluation at time 188:\t144.0861\n",
      "\n",
      "Loss evaluation at time 189:\t42.5221\n",
      "\n",
      "Loss evaluation at time 190:\t42.1443\n",
      "\n",
      "Loss evaluation at time 191:\t141.5379\n",
      "\n",
      "Loss evaluation at time 192:\t139.1011\n",
      "\n",
      "Loss evaluation at time 193:\t136.7204\n",
      "\n",
      "Loss evaluation at time 194:\t134.3944\n",
      "\n",
      "Loss evaluation at time 195:\t132.1215\n",
      "\n",
      "Loss evaluation at time 196:\t129.9001\n",
      "\n",
      "Loss evaluation at time 197:\t127.7288\n",
      "\n",
      "Loss evaluation at time 198:\t125.6062\n",
      "\n",
      "Loss evaluation at time 199:\t48.4401\n",
      "\n",
      "Loss evaluation at time 200:\t48.0120\n",
      "\n",
      "Loss evaluation at time 201:\t47.5856\n",
      "\n",
      "Loss evaluation at time 202:\t47.1612\n",
      "\n",
      "Loss evaluation at time 203:\t46.7387\n",
      "\n",
      "Loss evaluation at time 204:\t46.3185\n",
      "\n",
      "Loss evaluation at time 205:\t45.9005\n",
      "\n",
      "Loss evaluation at time 206:\t45.4849\n",
      "\n",
      "Loss evaluation at time 207:\t45.0717\n",
      "\n",
      "Loss evaluation at time 208:\t44.6612\n",
      "\n",
      "Loss evaluation at time 209:\t44.2532\n",
      "\n",
      "Loss evaluation at time 210:\t43.8480\n",
      "\n",
      "Loss evaluation at time 211:\t43.4455\n",
      "\n",
      "Loss evaluation at time 212:\t43.0459\n",
      "\n",
      "Loss evaluation at time 213:\t42.6492\n",
      "\n",
      "Loss evaluation at time 214:\t42.2555\n",
      "\n",
      "Loss evaluation at time 215:\t41.8647\n",
      "\n",
      "Loss evaluation at time 216:\t41.4770\n",
      "\n",
      "Loss evaluation at time 217:\t41.0923\n",
      "\n",
      "Loss evaluation at time 218:\t124.8010\n",
      "\n",
      "Loss evaluation at time 219:\t122.8712\n",
      "\n",
      "Loss evaluation at time 220:\t120.9814\n",
      "\n",
      "Loss evaluation at time 221:\t42.7876\n",
      "\n",
      "Loss evaluation at time 222:\t119.1861\n",
      "\n",
      "Loss evaluation at time 223:\t117.3780\n",
      "\n",
      "Loss evaluation at time 224:\t115.6065\n",
      "\n",
      "Loss evaluation at time 225:\t113.8709\n",
      "\n",
      "Loss evaluation at time 226:\t112.1703\n",
      "\n",
      "Loss evaluation at time 227:\t110.5036\n",
      "\n",
      "Loss evaluation at time 228:\t108.8702\n",
      "\n",
      "Loss evaluation at time 229:\t107.2691\n",
      "\n",
      "Loss evaluation at time 230:\t105.6995\n",
      "\n",
      "Loss evaluation at time 231:\t104.1608\n",
      "\n",
      "Loss evaluation at time 232:\t102.6521\n",
      "\n",
      "Loss evaluation at time 233:\t101.1727\n",
      "\n",
      "Loss evaluation at time 234:\t99.7219\n",
      "\n",
      "Loss evaluation at time 235:\t49.3686\n",
      "\n",
      "Loss evaluation at time 236:\t98.4830\n",
      "\n",
      "Loss evaluation at time 237:\t97.0885\n",
      "\n",
      "Loss evaluation at time 238:\t49.7789\n",
      "\n",
      "Loss evaluation at time 239:\t49.3572\n",
      "\n",
      "Loss evaluation at time 240:\t48.9387\n",
      "\n",
      "Loss evaluation at time 241:\t48.5234\n",
      "\n",
      "Loss evaluation at time 242:\t48.1113\n",
      "\n",
      "Loss evaluation at time 243:\t47.7023\n",
      "\n",
      "Loss evaluation at time 244:\t47.2966\n",
      "\n",
      "Loss evaluation at time 245:\t46.8941\n",
      "\n",
      "Loss evaluation at time 246:\t46.4948\n",
      "\n",
      "Loss evaluation at time 247:\t46.0988\n",
      "\n",
      "Loss evaluation at time 248:\t45.7061\n",
      "\n",
      "Loss evaluation at time 249:\t45.3166\n",
      "\n",
      "Loss evaluation at time 250:\t44.9303\n",
      "\n",
      "Loss evaluation at time 251:\t44.5474\n",
      "\n",
      "Loss evaluation at time 252:\t44.1677\n",
      "\n",
      "Loss evaluation at time 253:\t43.7912\n",
      "\n",
      "Loss evaluation at time 254:\t43.4180\n",
      "\n",
      "Loss evaluation at time 255:\t43.0481\n",
      "\n",
      "Loss evaluation at time 256:\t42.6814\n",
      "\n",
      "Loss evaluation at time 257:\t42.3179\n",
      "\n",
      "Loss evaluation at time 258:\t41.9577\n",
      "\n",
      "Loss evaluation at time 259:\t41.6007\n",
      "\n",
      "Loss evaluation at time 260:\t41.2469\n",
      "\n",
      "Loss evaluation at time 261:\t40.8963\n",
      "\n",
      "Loss evaluation at time 262:\t40.5489\n",
      "\n",
      "Loss evaluation at time 263:\t40.2046\n",
      "\n",
      "Loss evaluation at time 264:\t39.8635\n",
      "\n",
      "Loss evaluation at time 265:\t39.5255\n",
      "\n",
      "Loss evaluation at time 266:\t39.1907\n",
      "\n",
      "Loss evaluation at time 267:\t38.8589\n",
      "\n",
      "Loss evaluation at time 268:\t38.5302\n",
      "\n",
      "Loss evaluation at time 269:\t38.2046\n",
      "\n",
      "Loss evaluation at time 270:\t37.8820\n",
      "\n",
      "Loss evaluation at time 271:\t37.5625\n",
      "\n",
      "Loss evaluation at time 272:\t37.2459\n",
      "\n",
      "Loss evaluation at time 273:\t36.9324\n",
      "\n",
      "Loss evaluation at time 274:\t36.6218\n",
      "\n",
      "Loss evaluation at time 275:\t36.3142\n",
      "\n",
      "Loss evaluation at time 276:\t36.0094\n",
      "\n",
      "Loss evaluation at time 277:\t35.7076\n",
      "\n",
      "Loss evaluation at time 278:\t35.4087\n",
      "\n",
      "Loss evaluation at time 279:\t35.1126\n",
      "\n",
      "Loss evaluation at time 280:\t34.8193\n",
      "\n",
      "Loss evaluation at time 281:\t34.5289\n",
      "\n",
      "Loss evaluation at time 282:\t34.2412\n",
      "\n",
      "Loss evaluation at time 283:\t33.9563\n",
      "\n",
      "Loss evaluation at time 284:\t33.6742\n",
      "\n",
      "Loss evaluation at time 285:\t99.8750\n",
      "\n",
      "Loss evaluation at time 286:\t98.6439\n",
      "\n",
      "Loss evaluation at time 287:\t97.4331\n",
      "\n",
      "Loss evaluation at time 288:\t96.2421\n",
      "\n",
      "Loss evaluation at time 289:\t95.0706\n",
      "\n",
      "Loss evaluation at time 290:\t93.9182\n",
      "\n",
      "Loss evaluation at time 291:\t92.7844\n",
      "\n",
      "Loss evaluation at time 292:\t91.6689\n",
      "\n",
      "Loss evaluation at time 293:\t90.5713\n",
      "\n",
      "Loss evaluation at time 294:\t89.4913\n",
      "\n",
      "Loss evaluation at time 295:\t88.4285\n",
      "\n",
      "Loss evaluation at time 296:\t87.3826\n",
      "\n",
      "Loss evaluation at time 297:\t86.3532\n",
      "\n",
      "Loss evaluation at time 298:\t85.3400\n",
      "\n",
      "Loss evaluation at time 299:\t84.3428\n",
      "\n",
      "Loss evaluation at time 300:\t83.3611\n",
      "\n",
      "Loss evaluation at time 301:\t82.3947\n",
      "\n",
      "Loss evaluation at time 302:\t81.4434\n",
      "\n",
      "Loss evaluation at time 303:\t80.5067\n",
      "\n",
      "Loss evaluation at time 304:\t79.5844\n",
      "\n",
      "Loss evaluation at time 305:\t78.6763\n",
      "\n",
      "Loss evaluation at time 306:\t77.7820\n",
      "\n",
      "Loss evaluation at time 307:\t76.9014\n",
      "\n",
      "Loss evaluation at time 308:\t76.0341\n",
      "\n",
      "Loss evaluation at time 309:\t75.1799\n",
      "\n",
      "Loss evaluation at time 310:\t74.3385\n",
      "\n",
      "Loss evaluation at time 311:\t73.5098\n",
      "\n",
      "Loss evaluation at time 312:\t72.6934\n",
      "\n",
      "Loss evaluation at time 313:\t71.8892\n",
      "\n",
      "Loss evaluation at time 314:\t71.0969\n",
      "\n",
      "Loss evaluation at time 315:\t70.3163\n",
      "\n",
      "Loss evaluation at time 316:\t69.5472\n",
      "\n",
      "Loss evaluation at time 317:\t68.7893\n",
      "\n",
      "Loss evaluation at time 318:\t68.0426\n",
      "\n",
      "Loss evaluation at time 319:\t43.5524\n",
      "\n",
      "Loss evaluation at time 320:\t43.2486\n",
      "\n",
      "Loss evaluation at time 321:\t42.9471\n",
      "\n",
      "Loss evaluation at time 322:\t42.6479\n",
      "\n",
      "Loss evaluation at time 323:\t42.3509\n",
      "\n",
      "Loss evaluation at time 324:\t42.0562\n",
      "\n",
      "Loss evaluation at time 325:\t41.7637\n",
      "\n",
      "Loss evaluation at time 326:\t41.4733\n",
      "\n",
      "Loss evaluation at time 327:\t41.1852\n",
      "\n",
      "Loss evaluation at time 328:\t40.8993\n",
      "\n",
      "Loss evaluation at time 329:\t40.6156\n",
      "\n",
      "Loss evaluation at time 330:\t40.3341\n",
      "\n",
      "Loss evaluation at time 331:\t40.0547\n",
      "\n",
      "Loss evaluation at time 332:\t39.7775\n",
      "\n",
      "Loss evaluation at time 333:\t39.5024\n",
      "\n",
      "Loss evaluation at time 334:\t39.2294\n",
      "\n",
      "Loss evaluation at time 335:\t69.5395\n",
      "\n",
      "Loss evaluation at time 336:\t68.8159\n",
      "\n",
      "Loss evaluation at time 337:\t68.1023\n",
      "\n",
      "Loss evaluation at time 338:\t67.3986\n",
      "\n",
      "Loss evaluation at time 339:\t66.7047\n",
      "\n",
      "Loss evaluation at time 340:\t39.9059\n",
      "\n",
      "Loss evaluation at time 341:\t39.6370\n",
      "\n",
      "Loss evaluation at time 342:\t39.3701\n",
      "\n",
      "Loss evaluation at time 343:\t39.1053\n",
      "\n",
      "Loss evaluation at time 344:\t38.8424\n",
      "\n",
      "Loss evaluation at time 345:\t66.6387\n",
      "\n",
      "Loss evaluation at time 346:\t65.9646\n",
      "\n",
      "Loss evaluation at time 347:\t38.9390\n",
      "\n",
      "Loss evaluation at time 348:\t38.6801\n",
      "\n",
      "Loss evaluation at time 349:\t38.4231\n",
      "\n",
      "Loss evaluation at time 350:\t38.1680\n",
      "\n",
      "Loss evaluation at time 351:\t37.9148\n",
      "\n",
      "Loss evaluation at time 352:\t37.6636\n",
      "\n",
      "Loss evaluation at time 353:\t37.4142\n",
      "\n",
      "Loss evaluation at time 354:\t37.1668\n",
      "\n",
      "Loss evaluation at time 355:\t36.9211\n",
      "\n",
      "Loss evaluation at time 356:\t36.6774\n",
      "\n",
      "Loss evaluation at time 357:\t36.4355\n",
      "\n",
      "Loss evaluation at time 358:\t36.1954\n",
      "\n",
      "Loss evaluation at time 359:\t35.9571\n",
      "\n",
      "Loss evaluation at time 360:\t35.7207\n",
      "\n",
      "Loss evaluation at time 361:\t35.4861\n",
      "\n",
      "Loss evaluation at time 362:\t35.2532\n",
      "\n",
      "Loss evaluation at time 363:\t35.0221\n",
      "\n",
      "Loss evaluation at time 364:\t34.7928\n",
      "\n",
      "Loss evaluation at time 365:\t34.5652\n",
      "\n",
      "Loss evaluation at time 366:\t67.2052\n",
      "\n",
      "Loss evaluation at time 367:\t34.5310\n",
      "\n",
      "Loss evaluation at time 368:\t34.3067\n",
      "\n",
      "Loss evaluation at time 369:\t34.0840\n",
      "\n",
      "Loss evaluation at time 370:\t33.8630\n",
      "\n",
      "Loss evaluation at time 371:\t33.6437\n",
      "\n",
      "Loss evaluation at time 372:\t33.4261\n",
      "\n",
      "Loss evaluation at time 373:\t33.2101\n",
      "\n",
      "Loss evaluation at time 374:\t67.0874\n",
      "\n",
      "Loss evaluation at time 375:\t66.4512\n",
      "\n",
      "Loss evaluation at time 376:\t65.8230\n",
      "\n",
      "Loss evaluation at time 377:\t65.2028\n",
      "\n",
      "Loss evaluation at time 378:\t64.5904\n",
      "\n",
      "Loss evaluation at time 379:\t63.9857\n",
      "\n",
      "Loss evaluation at time 380:\t63.3886\n",
      "\n",
      "Loss evaluation at time 381:\t62.7989\n",
      "\n",
      "Loss evaluation at time 382:\t62.2165\n",
      "\n",
      "Loss evaluation at time 383:\t34.5814\n",
      "\n",
      "Loss evaluation at time 384:\t34.3668\n",
      "\n",
      "Loss evaluation at time 385:\t34.1538\n",
      "\n",
      "Loss evaluation at time 386:\t33.9423\n",
      "\n",
      "Loss evaluation at time 387:\t33.7324\n",
      "\n",
      "Loss evaluation at time 388:\t33.5240\n",
      "\n",
      "Loss evaluation at time 389:\t62.1473\n",
      "\n",
      "Loss evaluation at time 390:\t61.5814\n",
      "\n",
      "Loss evaluation at time 391:\t61.0223\n",
      "\n",
      "Loss evaluation at time 392:\t60.4700\n",
      "\n",
      "Loss evaluation at time 393:\t33.9419\n",
      "\n",
      "Loss evaluation at time 394:\t33.7360\n",
      "\n",
      "Loss evaluation at time 395:\t33.5316\n",
      "\n",
      "Loss evaluation at time 396:\t33.3287\n",
      "\n",
      "Loss evaluation at time 397:\t33.1272\n",
      "\n",
      "Loss evaluation at time 398:\t32.9271\n",
      "\n",
      "Loss evaluation at time 399:\t32.7284\n",
      "\n",
      "Loss evaluation at time 400:\t60.4911\n",
      "\n",
      "Loss evaluation at time 401:\t59.9544\n",
      "\n",
      "Loss evaluation at time 402:\t59.4240\n",
      "\n",
      "Loss evaluation at time 403:\t58.8998\n",
      "\n",
      "Loss evaluation at time 404:\t58.3819\n",
      "\n",
      "Loss evaluation at time 405:\t57.8700\n",
      "\n",
      "Loss evaluation at time 406:\t57.3641\n",
      "\n",
      "Loss evaluation at time 407:\t56.8642\n",
      "\n",
      "Loss evaluation at time 408:\t56.3701\n",
      "\n",
      "Loss evaluation at time 409:\t55.8817\n",
      "\n",
      "Loss evaluation at time 410:\t55.3990\n",
      "\n",
      "Loss evaluation at time 411:\t54.9219\n",
      "\n",
      "Loss evaluation at time 412:\t54.4502\n",
      "\n",
      "Loss evaluation at time 413:\t53.9840\n",
      "\n",
      "Loss evaluation at time 414:\t53.5231\n",
      "\n",
      "Loss evaluation at time 415:\t53.0675\n",
      "\n",
      "Loss evaluation at time 416:\t52.6171\n",
      "\n",
      "Loss evaluation at time 417:\t52.1718\n",
      "\n",
      "Loss evaluation at time 418:\t51.7315\n",
      "\n",
      "Loss evaluation at time 419:\t51.2963\n",
      "\n",
      "Loss evaluation at time 420:\t50.8659\n",
      "\n",
      "Loss evaluation at time 421:\t50.4404\n",
      "\n",
      "Loss evaluation at time 422:\t50.0196\n",
      "\n",
      "Loss evaluation at time 423:\t49.6035\n",
      "\n",
      "Loss evaluation at time 424:\t49.1921\n",
      "\n",
      "Loss evaluation at time 425:\t48.7852\n",
      "\n",
      "Loss evaluation at time 426:\t35.5592\n",
      "\n",
      "Loss evaluation at time 427:\t48.4931\n",
      "\n",
      "Loss evaluation at time 428:\t48.0949\n",
      "\n",
      "Loss evaluation at time 429:\t47.7012\n",
      "\n",
      "Loss evaluation at time 430:\t35.6106\n",
      "\n",
      "Loss evaluation at time 431:\t35.4193\n",
      "\n",
      "Loss evaluation at time 432:\t35.2291\n",
      "\n",
      "Loss evaluation at time 433:\t35.0401\n",
      "\n",
      "Loss evaluation at time 434:\t34.8522\n",
      "\n",
      "Loss evaluation at time 435:\t47.8537\n",
      "\n",
      "Loss evaluation at time 436:\t47.4673\n",
      "\n",
      "Loss evaluation at time 437:\t47.0852\n",
      "\n",
      "Loss evaluation at time 438:\t46.7072\n",
      "\n",
      "Loss evaluation at time 439:\t46.3332\n",
      "\n",
      "Loss evaluation at time 440:\t45.9632\n",
      "\n",
      "Loss evaluation at time 441:\t45.5972\n",
      "\n",
      "Loss evaluation at time 442:\t45.2351\n",
      "\n",
      "Loss evaluation at time 443:\t44.8769\n",
      "\n",
      "Loss evaluation at time 444:\t44.5225\n",
      "\n",
      "Loss evaluation at time 445:\t44.1718\n",
      "\n",
      "Loss evaluation at time 446:\t43.8248\n",
      "\n",
      "Loss evaluation at time 447:\t43.4815\n",
      "\n",
      "Loss evaluation at time 448:\t43.1417\n",
      "\n",
      "Loss evaluation at time 449:\t42.8056\n",
      "\n",
      "Loss evaluation at time 450:\t42.4729\n",
      "\n",
      "Loss evaluation at time 451:\t42.1437\n",
      "\n",
      "Loss evaluation at time 452:\t41.8180\n",
      "\n",
      "Loss evaluation at time 453:\t41.4956\n",
      "\n",
      "Loss evaluation at time 454:\t41.1765\n",
      "\n",
      "Loss evaluation at time 455:\t40.8608\n",
      "\n",
      "Loss evaluation at time 456:\t40.5483\n",
      "\n",
      "Loss evaluation at time 457:\t40.2389\n",
      "\n",
      "Loss evaluation at time 458:\t39.9328\n",
      "\n",
      "Loss evaluation at time 459:\t39.6298\n",
      "\n",
      "Loss evaluation at time 460:\t39.3298\n",
      "\n",
      "Loss evaluation at time 461:\t39.0330\n",
      "\n",
      "Loss evaluation at time 462:\t36.2618\n",
      "\n",
      "Loss evaluation at time 463:\t38.8603\n",
      "\n",
      "Loss evaluation at time 464:\t38.5689\n",
      "\n",
      "Loss evaluation at time 465:\t36.1623\n",
      "\n",
      "Loss evaluation at time 466:\t35.9880\n",
      "\n",
      "Loss evaluation at time 467:\t35.8146\n",
      "\n",
      "Loss evaluation at time 468:\t35.6421\n",
      "\n",
      "Loss evaluation at time 469:\t35.4705\n",
      "\n",
      "Loss evaluation at time 470:\t35.2997\n",
      "\n",
      "Loss evaluation at time 471:\t35.1299\n",
      "\n",
      "Loss evaluation at time 472:\t34.9609\n",
      "\n",
      "Loss evaluation at time 473:\t34.7928\n",
      "\n",
      "Loss evaluation at time 474:\t34.6256\n",
      "\n",
      "Loss evaluation at time 475:\t34.4593\n",
      "\n",
      "Loss evaluation at time 476:\t34.2938\n",
      "\n",
      "Loss evaluation at time 477:\t34.1292\n",
      "\n",
      "Loss evaluation at time 478:\t33.9655\n",
      "\n",
      "Loss evaluation at time 479:\t33.8026\n",
      "\n",
      "Loss evaluation at time 480:\t33.6406\n",
      "\n",
      "Loss evaluation at time 481:\t33.4795\n",
      "\n",
      "Loss evaluation at time 482:\t33.3192\n",
      "\n",
      "Loss evaluation at time 483:\t33.1598\n",
      "\n",
      "Loss evaluation at time 484:\t33.0012\n",
      "\n",
      "Loss evaluation at time 485:\t32.8435\n",
      "\n",
      "Loss evaluation at time 486:\t32.6866\n",
      "\n",
      "Loss evaluation at time 487:\t32.5305\n",
      "\n",
      "Loss evaluation at time 488:\t32.3753\n",
      "\n",
      "Loss evaluation at time 489:\t32.2209\n",
      "\n",
      "Loss evaluation at time 490:\t32.0673\n",
      "\n",
      "Loss evaluation at time 491:\t31.9146\n",
      "\n",
      "Loss evaluation at time 492:\t31.7627\n",
      "\n",
      "Loss evaluation at time 493:\t31.6116\n",
      "\n",
      "Loss evaluation at time 494:\t31.4613\n",
      "\n",
      "Loss evaluation at time 495:\t31.3119\n",
      "\n",
      "Loss evaluation at time 496:\t31.1632\n",
      "\n",
      "Loss evaluation at time 497:\t31.0154\n",
      "\n",
      "Loss evaluation at time 498:\t30.8683\n",
      "\n",
      "Loss evaluation at time 499:\t30.7221\n",
      "\n",
      "Loss evaluation at time 500:\t30.5766\n",
      "\n",
      "Loss evaluation at time 501:\t30.4319\n",
      "\n",
      "Loss evaluation at time 502:\t30.2881\n",
      "\n",
      "Loss evaluation at time 503:\t30.1450\n",
      "\n",
      "Loss evaluation at time 504:\t30.0026\n",
      "\n",
      "Loss evaluation at time 505:\t29.8611\n",
      "\n",
      "Loss evaluation at time 506:\t29.7203\n",
      "\n",
      "Loss evaluation at time 507:\t29.5803\n",
      "\n",
      "Loss evaluation at time 508:\t29.4411\n",
      "\n",
      "Loss evaluation at time 509:\t29.3026\n",
      "\n",
      "Loss evaluation at time 510:\t29.1649\n",
      "\n",
      "Loss evaluation at time 511:\t29.0280\n",
      "\n",
      "Loss evaluation at time 512:\t28.8918\n",
      "\n",
      "Loss evaluation at time 513:\t28.7563\n",
      "\n",
      "Loss evaluation at time 514:\t28.6216\n",
      "\n",
      "Loss evaluation at time 515:\t28.4876\n",
      "\n",
      "Loss evaluation at time 516:\t28.3543\n",
      "\n",
      "Loss evaluation at time 517:\t28.2218\n",
      "\n",
      "Loss evaluation at time 518:\t28.0901\n",
      "\n",
      "Loss evaluation at time 519:\t27.9590\n",
      "\n",
      "Loss evaluation at time 520:\t27.8287\n",
      "\n",
      "Loss evaluation at time 521:\t27.6990\n",
      "\n",
      "Loss evaluation at time 522:\t27.5701\n",
      "\n",
      "Loss evaluation at time 523:\t27.4419\n",
      "\n",
      "Loss evaluation at time 524:\t27.3144\n",
      "\n",
      "Loss evaluation at time 525:\t27.1876\n",
      "\n",
      "Loss evaluation at time 526:\t27.0615\n",
      "\n",
      "Loss evaluation at time 527:\t26.9361\n",
      "\n",
      "Loss evaluation at time 528:\t26.8114\n",
      "\n",
      "Loss evaluation at time 529:\t26.6874\n",
      "\n",
      "Loss evaluation at time 530:\t26.5641\n",
      "\n",
      "Loss evaluation at time 531:\t26.4414\n",
      "\n",
      "Loss evaluation at time 532:\t26.3194\n",
      "\n",
      "Loss evaluation at time 533:\t43.9499\n",
      "\n",
      "Loss evaluation at time 534:\t26.2758\n",
      "\n",
      "Loss evaluation at time 535:\t43.7060\n",
      "\n",
      "Loss evaluation at time 536:\t43.4125\n",
      "\n",
      "Loss evaluation at time 537:\t43.1216\n",
      "\n",
      "Loss evaluation at time 538:\t42.8334\n",
      "\n",
      "Loss evaluation at time 539:\t42.5477\n",
      "\n",
      "Loss evaluation at time 540:\t42.2646\n",
      "\n",
      "Loss evaluation at time 541:\t41.9839\n",
      "\n",
      "Loss evaluation at time 542:\t41.7058\n",
      "\n",
      "Loss evaluation at time 543:\t41.4301\n",
      "\n",
      "Loss evaluation at time 544:\t41.1569\n",
      "\n",
      "Loss evaluation at time 545:\t40.8861\n",
      "\n",
      "Loss evaluation at time 546:\t40.6177\n",
      "\n",
      "Loss evaluation at time 547:\t40.3516\n",
      "\n",
      "Loss evaluation at time 548:\t40.0878\n",
      "\n",
      "Loss evaluation at time 549:\t39.8264\n",
      "\n",
      "Loss evaluation at time 550:\t39.5672\n",
      "\n",
      "Loss evaluation at time 551:\t39.3103\n",
      "\n",
      "Loss evaluation at time 552:\t27.2880\n",
      "\n",
      "Loss evaluation at time 553:\t27.1691\n",
      "\n",
      "Loss evaluation at time 554:\t27.0508\n",
      "\n",
      "Loss evaluation at time 555:\t26.9331\n",
      "\n",
      "Loss evaluation at time 556:\t26.8160\n",
      "\n",
      "Loss evaluation at time 557:\t26.6995\n",
      "\n",
      "Loss evaluation at time 558:\t26.5836\n",
      "\n",
      "Loss evaluation at time 559:\t26.4683\n",
      "\n",
      "Loss evaluation at time 560:\t26.3536\n",
      "\n",
      "Loss evaluation at time 561:\t26.2394\n",
      "\n",
      "Loss evaluation at time 562:\t26.1259\n",
      "\n",
      "Loss evaluation at time 563:\t26.0129\n",
      "\n",
      "Loss evaluation at time 564:\t25.9005\n",
      "\n",
      "Loss evaluation at time 565:\t25.7887\n",
      "\n",
      "Loss evaluation at time 566:\t25.6775\n",
      "\n",
      "Loss evaluation at time 567:\t25.5668\n",
      "\n",
      "Loss evaluation at time 568:\t25.4567\n",
      "\n",
      "Loss evaluation at time 569:\t25.3472\n",
      "\n",
      "Loss evaluation at time 570:\t25.2382\n",
      "\n",
      "Loss evaluation at time 571:\t25.1298\n",
      "\n",
      "Loss evaluation at time 572:\t40.1657\n",
      "\n",
      "Loss evaluation at time 573:\t39.9132\n",
      "\n",
      "Loss evaluation at time 574:\t39.6628\n",
      "\n",
      "Loss evaluation at time 575:\t39.4145\n",
      "\n",
      "Loss evaluation at time 576:\t39.1683\n",
      "\n",
      "Loss evaluation at time 577:\t38.9241\n",
      "\n",
      "Loss evaluation at time 578:\t38.6820\n",
      "\n",
      "Loss evaluation at time 579:\t38.4419\n",
      "\n",
      "Loss evaluation at time 580:\t38.2037\n",
      "\n",
      "Loss evaluation at time 581:\t37.9676\n",
      "\n",
      "Loss evaluation at time 582:\t37.7334\n",
      "\n",
      "Loss evaluation at time 583:\t37.5011\n",
      "\n",
      "Loss evaluation at time 584:\t37.2708\n",
      "\n",
      "Loss evaluation at time 585:\t37.0423\n",
      "\n",
      "Loss evaluation at time 586:\t36.8157\n",
      "\n",
      "Loss evaluation at time 587:\t36.5910\n",
      "\n",
      "Loss evaluation at time 588:\t36.3681\n",
      "\n",
      "Loss evaluation at time 589:\t36.1470\n",
      "\n",
      "Loss evaluation at time 590:\t35.9277\n",
      "\n",
      "Loss evaluation at time 591:\t35.7102\n",
      "\n",
      "Loss evaluation at time 592:\t35.4945\n",
      "\n",
      "Loss evaluation at time 593:\t35.2805\n",
      "\n",
      "Loss evaluation at time 594:\t35.0682\n",
      "\n",
      "Loss evaluation at time 595:\t34.8577\n",
      "\n",
      "Loss evaluation at time 596:\t26.2777\n",
      "\n",
      "Loss evaluation at time 597:\t34.7082\n",
      "\n",
      "Loss evaluation at time 598:\t34.5010\n",
      "\n",
      "Loss evaluation at time 599:\t34.2953\n",
      "\n",
      "Loss evaluation at time 600:\t34.0914\n",
      "\n",
      "Loss evaluation at time 601:\t33.8890\n",
      "\n",
      "Loss evaluation at time 602:\t33.6882\n",
      "\n",
      "Loss evaluation at time 603:\t33.4891\n",
      "\n",
      "Loss evaluation at time 604:\t33.2915\n",
      "\n",
      "Loss evaluation at time 605:\t33.0955\n",
      "\n",
      "Loss evaluation at time 606:\t32.9010\n",
      "\n",
      "Loss evaluation at time 607:\t32.7081\n",
      "\n",
      "Loss evaluation at time 608:\t32.5167\n",
      "\n",
      "Loss evaluation at time 609:\t32.3267\n",
      "\n",
      "Loss evaluation at time 610:\t32.1383\n",
      "\n",
      "Loss evaluation at time 611:\t31.9513\n",
      "\n",
      "Loss evaluation at time 612:\t31.7658\n",
      "\n",
      "Loss evaluation at time 613:\t31.5817\n",
      "\n",
      "Loss evaluation at time 614:\t31.3991\n",
      "\n",
      "Loss evaluation at time 615:\t31.2179\n",
      "\n",
      "Loss evaluation at time 616:\t31.0381\n",
      "\n",
      "Loss evaluation at time 617:\t30.8596\n",
      "\n",
      "Loss evaluation at time 618:\t30.6826\n",
      "\n",
      "Loss evaluation at time 619:\t30.5069\n",
      "\n",
      "Loss evaluation at time 620:\t30.3325\n",
      "\n",
      "Loss evaluation at time 621:\t30.1595\n",
      "\n",
      "Loss evaluation at time 622:\t29.9878\n",
      "\n",
      "Loss evaluation at time 623:\t29.8174\n",
      "\n",
      "Loss evaluation at time 624:\t29.6484\n",
      "\n",
      "Loss evaluation at time 625:\t29.4806\n",
      "\n",
      "Loss evaluation at time 626:\t29.3140\n",
      "\n",
      "Loss evaluation at time 627:\t29.1488\n",
      "\n",
      "Loss evaluation at time 628:\t28.9848\n",
      "\n",
      "Loss evaluation at time 629:\t28.8220\n",
      "\n",
      "Loss evaluation at time 630:\t28.6604\n",
      "\n",
      "Loss evaluation at time 631:\t28.5001\n",
      "\n",
      "Loss evaluation at time 632:\t28.3410\n",
      "\n",
      "Loss evaluation at time 633:\t28.1830\n",
      "\n",
      "Loss evaluation at time 634:\t28.0263\n",
      "\n",
      "Loss evaluation at time 635:\t27.8707\n",
      "\n",
      "Loss evaluation at time 636:\t27.7163\n",
      "\n",
      "Loss evaluation at time 637:\t27.5630\n",
      "\n",
      "Loss evaluation at time 638:\t27.4108\n",
      "\n",
      "Loss evaluation at time 639:\t27.2598\n",
      "\n",
      "Loss evaluation at time 640:\t27.1099\n",
      "\n",
      "Loss evaluation at time 641:\t26.9611\n",
      "\n",
      "Loss evaluation at time 642:\t27.3889\n",
      "\n",
      "Loss evaluation at time 643:\t27.2915\n",
      "\n",
      "Loss evaluation at time 644:\t27.1945\n",
      "\n",
      "Loss evaluation at time 645:\t27.0979\n",
      "\n",
      "Loss evaluation at time 646:\t27.0016\n",
      "\n",
      "Loss evaluation at time 647:\t26.9058\n",
      "\n",
      "Loss evaluation at time 648:\t26.8103\n",
      "\n",
      "Loss evaluation at time 649:\t26.7152\n",
      "\n",
      "Loss evaluation at time 650:\t26.6204\n",
      "\n",
      "Loss evaluation at time 651:\t26.5260\n",
      "\n",
      "Loss evaluation at time 652:\t26.4320\n",
      "\n",
      "Loss evaluation at time 653:\t26.3384\n",
      "\n",
      "Loss evaluation at time 654:\t26.2451\n",
      "\n",
      "Loss evaluation at time 655:\t26.1522\n",
      "\n",
      "Loss evaluation at time 656:\t27.7292\n",
      "\n",
      "Loss evaluation at time 657:\t27.5799\n",
      "\n",
      "Loss evaluation at time 658:\t27.4317\n",
      "\n",
      "Loss evaluation at time 659:\t27.2846\n",
      "\n",
      "Loss evaluation at time 660:\t27.1385\n",
      "\n",
      "Loss evaluation at time 661:\t26.9934\n",
      "\n",
      "Loss evaluation at time 662:\t26.8494\n",
      "\n",
      "Loss evaluation at time 663:\t26.7064\n",
      "\n",
      "Loss evaluation at time 664:\t26.5645\n",
      "\n",
      "Loss evaluation at time 665:\t26.4235\n",
      "\n",
      "Loss evaluation at time 666:\t26.2836\n",
      "\n",
      "Loss evaluation at time 667:\t26.1446\n",
      "\n",
      "Loss evaluation at time 668:\t26.0067\n",
      "\n",
      "Loss evaluation at time 669:\t25.8697\n",
      "\n",
      "Loss evaluation at time 670:\t25.7337\n",
      "\n",
      "Loss evaluation at time 671:\t25.5986\n",
      "\n",
      "Loss evaluation at time 672:\t25.4645\n",
      "\n",
      "Loss evaluation at time 673:\t25.3314\n",
      "\n",
      "Loss evaluation at time 674:\t25.1991\n",
      "\n",
      "Loss evaluation at time 675:\t25.0678\n",
      "\n",
      "Loss evaluation at time 676:\t24.9375\n",
      "\n",
      "Loss evaluation at time 677:\t24.8080\n",
      "\n",
      "Loss evaluation at time 678:\t24.6794\n",
      "\n",
      "Loss evaluation at time 679:\t24.5517\n",
      "\n",
      "Loss evaluation at time 680:\t24.4250\n",
      "\n",
      "Loss evaluation at time 681:\t24.2990\n",
      "\n",
      "Loss evaluation at time 682:\t24.1740\n",
      "\n",
      "Loss evaluation at time 683:\t24.0498\n",
      "\n",
      "Loss evaluation at time 684:\t23.9265\n",
      "\n",
      "Loss evaluation at time 685:\t23.8040\n",
      "\n",
      "Loss evaluation at time 686:\t23.6824\n",
      "\n",
      "Loss evaluation at time 687:\t23.5616\n",
      "\n",
      "Loss evaluation at time 688:\t23.4417\n",
      "\n",
      "Loss evaluation at time 689:\t23.3225\n",
      "\n",
      "Loss evaluation at time 690:\t23.2042\n",
      "\n",
      "Loss evaluation at time 691:\t23.0867\n",
      "\n",
      "Loss evaluation at time 692:\t22.9699\n",
      "\n",
      "Loss evaluation at time 693:\t22.8540\n",
      "\n",
      "Loss evaluation at time 694:\t22.7389\n",
      "\n",
      "Loss evaluation at time 695:\t22.6245\n",
      "\n",
      "Loss evaluation at time 696:\t22.5109\n",
      "\n",
      "Loss evaluation at time 697:\t22.3981\n",
      "\n",
      "Loss evaluation at time 698:\t22.2860\n",
      "\n",
      "Loss evaluation at time 699:\t22.1747\n",
      "\n",
      "Loss evaluation at time 700:\t22.0641\n",
      "\n",
      "Loss evaluation at time 701:\t21.9543\n",
      "\n",
      "Loss evaluation at time 702:\t21.8452\n",
      "\n",
      "Loss evaluation at time 703:\t21.7368\n",
      "\n",
      "Loss evaluation at time 704:\t21.6292\n",
      "\n",
      "Loss evaluation at time 705:\t21.5222\n",
      "\n",
      "Loss evaluation at time 706:\t21.4160\n",
      "\n",
      "Loss evaluation at time 707:\t21.3105\n",
      "\n",
      "Loss evaluation at time 708:\t21.2057\n",
      "\n",
      "Loss evaluation at time 709:\t21.1016\n",
      "\n",
      "Loss evaluation at time 710:\t20.9981\n",
      "\n",
      "Loss evaluation at time 711:\t20.8954\n",
      "\n",
      "Loss evaluation at time 712:\t20.7933\n",
      "\n",
      "Loss evaluation at time 713:\t20.6919\n",
      "\n",
      "Loss evaluation at time 714:\t20.5912\n",
      "\n",
      "Loss evaluation at time 715:\t20.4911\n",
      "\n",
      "Loss evaluation at time 716:\t20.3916\n",
      "\n",
      "Loss evaluation at time 717:\t20.2929\n",
      "\n",
      "Loss evaluation at time 718:\t20.1947\n",
      "\n",
      "Loss evaluation at time 719:\t20.0972\n",
      "\n",
      "Loss evaluation at time 720:\t20.0004\n",
      "\n",
      "Loss evaluation at time 721:\t19.9041\n",
      "\n",
      "Loss evaluation at time 722:\t19.8085\n",
      "\n",
      "Loss evaluation at time 723:\t19.7135\n",
      "\n",
      "Loss evaluation at time 724:\t19.6191\n",
      "\n",
      "Loss evaluation at time 725:\t19.5253\n",
      "\n",
      "Loss evaluation at time 726:\t19.4322\n",
      "\n",
      "Loss evaluation at time 727:\t19.3396\n",
      "\n",
      "Loss evaluation at time 728:\t19.2476\n",
      "\n",
      "Loss evaluation at time 729:\t19.1562\n",
      "\n",
      "Loss evaluation at time 730:\t19.0654\n",
      "\n",
      "Loss evaluation at time 731:\t18.9751\n",
      "\n",
      "Loss evaluation at time 732:\t18.8855\n",
      "\n",
      "Loss evaluation at time 733:\t18.7964\n",
      "\n",
      "Loss evaluation at time 734:\t18.7079\n",
      "\n",
      "Loss evaluation at time 735:\t18.6199\n",
      "\n",
      "Loss evaluation at time 736:\t18.5325\n",
      "\n",
      "Loss evaluation at time 737:\t18.4456\n",
      "\n",
      "Loss evaluation at time 738:\t18.3593\n",
      "\n",
      "Loss evaluation at time 739:\t18.2736\n",
      "\n",
      "Loss evaluation at time 740:\t18.1883\n",
      "\n",
      "Loss evaluation at time 741:\t18.1036\n",
      "\n",
      "Loss evaluation at time 742:\t18.0195\n",
      "\n",
      "Loss evaluation at time 743:\t17.9359\n",
      "\n",
      "Loss evaluation at time 744:\t17.8527\n",
      "\n",
      "Loss evaluation at time 745:\t17.7701\n",
      "\n",
      "Loss evaluation at time 746:\t17.6881\n",
      "\n",
      "Loss evaluation at time 747:\t17.6065\n",
      "\n",
      "Loss evaluation at time 748:\t17.5254\n",
      "\n",
      "Loss evaluation at time 749:\t17.4449\n",
      "\n",
      "Loss evaluation at time 750:\t17.3648\n",
      "\n",
      "Loss evaluation at time 751:\t17.2852\n",
      "\n",
      "Loss evaluation at time 752:\t17.2061\n",
      "\n",
      "Loss evaluation at time 753:\t17.1276\n",
      "\n",
      "Loss evaluation at time 754:\t17.0494\n",
      "\n",
      "Loss evaluation at time 755:\t16.9718\n",
      "\n",
      "Loss evaluation at time 756:\t16.8947\n",
      "\n",
      "Loss evaluation at time 757:\t16.8180\n",
      "\n",
      "Loss evaluation at time 758:\t16.7418\n",
      "\n",
      "Loss evaluation at time 759:\t16.6660\n",
      "\n",
      "Loss evaluation at time 760:\t16.5907\n",
      "\n",
      "Loss evaluation at time 761:\t16.5159\n",
      "\n",
      "Loss evaluation at time 762:\t16.4415\n",
      "\n",
      "Loss evaluation at time 763:\t16.3676\n",
      "\n",
      "Loss evaluation at time 764:\t16.2941\n",
      "\n",
      "Loss evaluation at time 765:\t16.2211\n",
      "\n",
      "Loss evaluation at time 766:\t16.1485\n",
      "\n",
      "Loss evaluation at time 767:\t16.0763\n",
      "\n",
      "Loss evaluation at time 768:\t16.0046\n",
      "\n",
      "Loss evaluation at time 769:\t15.9333\n",
      "\n",
      "Loss evaluation at time 770:\t15.8625\n",
      "\n",
      "Loss evaluation at time 771:\t15.7920\n",
      "\n",
      "Loss evaluation at time 772:\t15.7220\n",
      "\n",
      "Loss evaluation at time 773:\t26.2234\n",
      "\n",
      "Loss evaluation at time 774:\t26.1525\n",
      "\n",
      "Loss evaluation at time 775:\t26.0817\n",
      "\n",
      "Loss evaluation at time 776:\t26.0111\n",
      "\n",
      "Loss evaluation at time 777:\t25.9407\n",
      "\n",
      "Loss evaluation at time 778:\t25.8705\n",
      "\n",
      "Loss evaluation at time 779:\t25.8004\n",
      "\n",
      "Loss evaluation at time 780:\t25.7306\n",
      "\n",
      "Loss evaluation at time 781:\t25.6608\n",
      "\n",
      "Loss evaluation at time 782:\t25.5913\n",
      "\n",
      "Loss evaluation at time 783:\t25.5220\n",
      "\n",
      "Loss evaluation at time 784:\t16.3338\n",
      "\n",
      "Loss evaluation at time 785:\t16.2623\n",
      "\n",
      "Loss evaluation at time 786:\t16.1911\n",
      "\n",
      "Loss evaluation at time 787:\t16.1203\n",
      "\n",
      "Loss evaluation at time 788:\t16.0500\n",
      "\n",
      "Loss evaluation at time 789:\t15.9801\n",
      "\n",
      "Loss evaluation at time 790:\t15.9106\n",
      "\n",
      "Loss evaluation at time 791:\t15.8415\n",
      "\n",
      "Loss evaluation at time 792:\t15.7728\n",
      "\n",
      "Loss evaluation at time 793:\t15.7045\n",
      "\n",
      "Loss evaluation at time 794:\t15.6366\n",
      "\n",
      "Loss evaluation at time 795:\t15.5691\n",
      "\n",
      "Loss evaluation at time 796:\t15.5020\n",
      "\n",
      "Loss evaluation at time 797:\t15.4353\n",
      "\n",
      "Loss evaluation at time 798:\t15.3689\n",
      "\n",
      "Loss evaluation at time 799:\t15.3030\n",
      "\n",
      "Loss evaluation at time 800:\t15.2374\n",
      "\n",
      "Loss evaluation at time 801:\t15.1722\n",
      "\n",
      "Loss evaluation at time 802:\t15.1074\n",
      "\n",
      "Loss evaluation at time 803:\t15.0430\n",
      "\n",
      "Loss evaluation at time 804:\t14.9789\n",
      "\n",
      "Loss evaluation at time 805:\t14.9152\n",
      "\n",
      "Loss evaluation at time 806:\t14.8519\n",
      "\n",
      "Loss evaluation at time 807:\t14.7889\n",
      "\n",
      "Loss evaluation at time 808:\t25.2459\n",
      "\n",
      "Loss evaluation at time 809:\t25.1808\n",
      "\n",
      "Loss evaluation at time 810:\t25.1157\n",
      "\n",
      "Loss evaluation at time 811:\t25.0509\n",
      "\n",
      "Loss evaluation at time 812:\t24.9861\n",
      "\n",
      "Loss evaluation at time 813:\t24.9216\n",
      "\n",
      "Loss evaluation at time 814:\t24.8571\n",
      "\n",
      "Loss evaluation at time 815:\t24.7929\n",
      "\n",
      "Loss evaluation at time 816:\t24.7288\n",
      "\n",
      "Loss evaluation at time 817:\t15.2455\n",
      "\n",
      "Loss evaluation at time 818:\t24.6569\n",
      "\n",
      "Loss evaluation at time 819:\t15.2377\n",
      "\n",
      "Loss evaluation at time 820:\t24.5854\n",
      "\n",
      "Loss evaluation at time 821:\t24.5220\n",
      "\n",
      "Loss evaluation at time 822:\t24.4588\n",
      "\n",
      "Loss evaluation at time 823:\t24.3957\n",
      "\n",
      "Loss evaluation at time 824:\t24.3328\n",
      "\n",
      "Loss evaluation at time 825:\t24.2701\n",
      "\n",
      "Loss evaluation at time 826:\t15.5050\n",
      "\n",
      "Loss evaluation at time 827:\t15.4404\n",
      "\n",
      "Loss evaluation at time 828:\t15.3762\n",
      "\n",
      "Loss evaluation at time 829:\t15.3123\n",
      "\n",
      "Loss evaluation at time 830:\t15.2488\n",
      "\n",
      "Loss evaluation at time 831:\t15.1857\n",
      "\n",
      "Loss evaluation at time 832:\t15.1228\n",
      "\n",
      "Loss evaluation at time 833:\t15.0604\n",
      "\n",
      "Loss evaluation at time 834:\t14.9983\n",
      "\n",
      "Loss evaluation at time 835:\t14.9365\n",
      "\n",
      "Loss evaluation at time 836:\t14.8751\n",
      "\n",
      "Loss evaluation at time 837:\t14.8140\n",
      "\n",
      "Loss evaluation at time 838:\t14.7532\n",
      "\n",
      "Loss evaluation at time 839:\t14.6928\n",
      "\n",
      "Loss evaluation at time 840:\t14.6327\n",
      "\n",
      "Loss evaluation at time 841:\t14.5730\n",
      "\n",
      "Loss evaluation at time 842:\t14.5136\n",
      "\n",
      "Loss evaluation at time 843:\t14.4545\n",
      "\n",
      "Loss evaluation at time 844:\t14.3957\n",
      "\n",
      "Loss evaluation at time 845:\t14.3373\n",
      "\n",
      "Loss evaluation at time 846:\t14.2791\n",
      "\n",
      "Loss evaluation at time 847:\t14.2213\n",
      "\n",
      "Loss evaluation at time 848:\t14.1638\n",
      "\n",
      "Loss evaluation at time 849:\t14.1066\n",
      "\n",
      "Loss evaluation at time 850:\t14.0498\n",
      "\n",
      "Loss evaluation at time 851:\t13.9932\n",
      "\n",
      "Loss evaluation at time 852:\t13.9369\n",
      "\n",
      "Loss evaluation at time 853:\t13.8810\n",
      "\n",
      "Loss evaluation at time 854:\t13.8253\n",
      "\n",
      "Loss evaluation at time 855:\t13.7700\n",
      "\n",
      "Loss evaluation at time 856:\t13.7149\n",
      "\n",
      "Loss evaluation at time 857:\t13.6602\n",
      "\n",
      "Loss evaluation at time 858:\t13.6057\n",
      "\n",
      "Loss evaluation at time 859:\t13.5515\n",
      "\n",
      "Loss evaluation at time 860:\t13.4976\n",
      "\n",
      "Loss evaluation at time 861:\t13.4441\n",
      "\n",
      "Loss evaluation at time 862:\t13.3908\n",
      "\n",
      "Loss evaluation at time 863:\t13.3377\n",
      "\n",
      "Loss evaluation at time 864:\t13.2850\n",
      "\n",
      "Loss evaluation at time 865:\t13.2325\n",
      "\n",
      "Loss evaluation at time 866:\t13.1804\n",
      "\n",
      "Loss evaluation at time 867:\t13.1285\n",
      "\n",
      "Loss evaluation at time 868:\t13.0768\n",
      "\n",
      "Loss evaluation at time 869:\t13.0255\n",
      "\n",
      "Loss evaluation at time 870:\t12.9744\n",
      "\n",
      "Loss evaluation at time 871:\t12.9236\n",
      "\n",
      "Loss evaluation at time 872:\t12.8730\n",
      "\n",
      "Loss evaluation at time 873:\t12.8228\n",
      "\n",
      "Loss evaluation at time 874:\t12.7728\n",
      "\n",
      "Loss evaluation at time 875:\t12.7230\n",
      "\n",
      "Loss evaluation at time 876:\t12.6735\n",
      "\n",
      "Loss evaluation at time 877:\t12.6243\n",
      "\n",
      "Loss evaluation at time 878:\t12.5753\n",
      "\n",
      "Loss evaluation at time 879:\t12.5266\n",
      "\n",
      "Loss evaluation at time 880:\t12.4781\n",
      "\n",
      "Loss evaluation at time 881:\t12.4299\n",
      "\n",
      "Loss evaluation at time 882:\t12.3820\n",
      "\n",
      "Loss evaluation at time 883:\t12.3343\n",
      "\n",
      "Loss evaluation at time 884:\t12.2868\n",
      "\n",
      "Loss evaluation at time 885:\t12.2396\n",
      "\n",
      "Loss evaluation at time 886:\t12.1926\n",
      "\n",
      "Loss evaluation at time 887:\t12.1459\n",
      "\n",
      "Loss evaluation at time 888:\t12.0994\n",
      "\n",
      "Loss evaluation at time 889:\t12.0532\n",
      "\n",
      "Loss evaluation at time 890:\t12.0072\n",
      "\n",
      "Loss evaluation at time 891:\t11.9614\n",
      "\n",
      "Loss evaluation at time 892:\t11.9158\n",
      "\n",
      "Loss evaluation at time 893:\t11.8705\n",
      "\n",
      "Loss evaluation at time 894:\t11.8255\n",
      "\n",
      "Loss evaluation at time 895:\t11.7806\n",
      "\n",
      "Loss evaluation at time 896:\t11.7360\n",
      "\n",
      "Loss evaluation at time 897:\t11.6916\n",
      "\n",
      "Loss evaluation at time 898:\t11.6475\n",
      "\n",
      "Loss evaluation at time 899:\t11.6035\n",
      "\n",
      "Loss evaluation at time 900:\t11.5598\n",
      "\n",
      "Loss evaluation at time 901:\t11.5163\n",
      "\n",
      "Loss evaluation at time 902:\t11.4731\n",
      "\n",
      "Loss evaluation at time 903:\t11.4300\n",
      "\n",
      "Loss evaluation at time 904:\t11.3872\n",
      "\n",
      "Loss evaluation at time 905:\t11.3446\n",
      "\n",
      "Loss evaluation at time 906:\t11.3022\n",
      "\n",
      "Loss evaluation at time 907:\t11.2600\n",
      "\n",
      "Loss evaluation at time 908:\t11.2180\n",
      "\n",
      "Loss evaluation at time 909:\t11.1763\n",
      "\n",
      "Loss evaluation at time 910:\t11.1347\n",
      "\n",
      "Loss evaluation at time 911:\t11.0934\n",
      "\n",
      "Loss evaluation at time 912:\t11.0522\n",
      "\n",
      "Loss evaluation at time 913:\t11.0113\n",
      "\n",
      "Loss evaluation at time 914:\t10.9706\n",
      "\n",
      "Loss evaluation at time 915:\t10.9300\n",
      "\n",
      "Loss evaluation at time 916:\t10.8897\n",
      "\n",
      "Loss evaluation at time 917:\t10.8496\n",
      "\n",
      "Loss evaluation at time 918:\t10.8097\n",
      "\n",
      "Loss evaluation at time 919:\t10.7699\n",
      "\n",
      "Loss evaluation at time 920:\t10.7304\n",
      "\n",
      "Loss evaluation at time 921:\t10.6911\n",
      "\n",
      "Loss evaluation at time 922:\t10.6519\n",
      "\n",
      "Loss evaluation at time 923:\t10.6130\n",
      "\n",
      "Loss evaluation at time 924:\t10.5742\n",
      "\n",
      "Loss evaluation at time 925:\t10.5357\n",
      "\n",
      "Loss evaluation at time 926:\t10.4973\n",
      "\n",
      "Loss evaluation at time 927:\t10.4591\n",
      "\n",
      "Loss evaluation at time 928:\t10.4211\n",
      "\n",
      "Loss evaluation at time 929:\t10.3833\n",
      "\n",
      "Loss evaluation at time 930:\t10.3457\n",
      "\n",
      "Loss evaluation at time 931:\t10.3082\n",
      "\n",
      "Loss evaluation at time 932:\t10.2710\n",
      "\n",
      "Loss evaluation at time 933:\t10.2339\n",
      "\n",
      "Loss evaluation at time 934:\t10.1970\n",
      "\n",
      "Loss evaluation at time 935:\t10.1603\n",
      "\n",
      "Loss evaluation at time 936:\t10.1237\n",
      "\n",
      "Loss evaluation at time 937:\t10.0873\n",
      "\n",
      "Loss evaluation at time 938:\t10.0512\n",
      "\n",
      "Loss evaluation at time 939:\t10.0151\n",
      "\n",
      "Loss evaluation at time 940:\t9.9793\n",
      "\n",
      "Loss evaluation at time 941:\t9.9436\n",
      "\n",
      "Loss evaluation at time 942:\t9.9081\n",
      "\n",
      "Loss evaluation at time 943:\t9.8728\n",
      "\n",
      "Loss evaluation at time 944:\t9.8377\n",
      "\n",
      "Loss evaluation at time 945:\t9.8027\n",
      "\n",
      "Loss evaluation at time 946:\t9.7679\n",
      "\n",
      "Loss evaluation at time 947:\t9.7332\n",
      "\n",
      "Loss evaluation at time 948:\t9.6987\n",
      "\n",
      "Loss evaluation at time 949:\t9.6644\n",
      "\n",
      "Loss evaluation at time 950:\t9.6302\n",
      "\n",
      "Loss evaluation at time 951:\t9.5962\n",
      "\n",
      "Loss evaluation at time 952:\t9.5624\n",
      "\n",
      "Loss evaluation at time 953:\t9.5287\n",
      "\n",
      "Loss evaluation at time 954:\t9.4952\n",
      "\n",
      "Loss evaluation at time 955:\t9.4619\n",
      "\n",
      "Loss evaluation at time 956:\t9.4287\n",
      "\n",
      "Loss evaluation at time 957:\t9.3956\n",
      "\n",
      "Loss evaluation at time 958:\t9.3628\n",
      "\n",
      "Loss evaluation at time 959:\t9.3300\n",
      "\n",
      "Loss evaluation at time 960:\t9.2975\n",
      "\n",
      "Loss evaluation at time 961:\t9.2650\n",
      "\n",
      "Loss evaluation at time 962:\t9.2328\n",
      "\n",
      "Loss evaluation at time 963:\t9.2007\n",
      "\n",
      "Loss evaluation at time 964:\t9.1687\n",
      "\n",
      "Loss evaluation at time 965:\t9.1369\n",
      "\n",
      "Loss evaluation at time 966:\t9.1052\n",
      "\n",
      "Loss evaluation at time 967:\t9.0737\n",
      "\n",
      "Loss evaluation at time 968:\t9.0423\n",
      "\n",
      "Loss evaluation at time 969:\t9.0111\n",
      "\n",
      "Loss evaluation at time 970:\t8.9800\n",
      "\n",
      "Loss evaluation at time 971:\t8.9491\n",
      "\n",
      "Loss evaluation at time 972:\t8.9183\n",
      "\n",
      "Loss evaluation at time 973:\t8.8876\n",
      "\n",
      "Loss evaluation at time 974:\t8.8571\n",
      "\n",
      "Loss evaluation at time 975:\t8.8268\n",
      "\n",
      "Loss evaluation at time 976:\t8.7965\n",
      "\n",
      "Loss evaluation at time 977:\t8.7664\n",
      "\n",
      "Loss evaluation at time 978:\t8.7365\n",
      "\n",
      "Loss evaluation at time 979:\t8.7067\n",
      "\n",
      "Loss evaluation at time 980:\t8.6770\n",
      "\n",
      "Loss evaluation at time 981:\t8.6475\n",
      "\n",
      "Loss evaluation at time 982:\t8.6181\n",
      "\n",
      "Loss evaluation at time 983:\t8.5888\n",
      "\n",
      "Loss evaluation at time 984:\t8.5597\n",
      "\n",
      "Loss evaluation at time 985:\t8.5307\n",
      "\n",
      "Loss evaluation at time 986:\t8.5018\n",
      "\n",
      "Loss evaluation at time 987:\t8.4731\n",
      "\n",
      "Loss evaluation at time 988:\t8.4445\n",
      "\n",
      "Loss evaluation at time 989:\t8.4160\n",
      "\n",
      "Loss evaluation at time 990:\t8.3877\n",
      "\n",
      "Loss evaluation at time 991:\t8.3595\n",
      "\n",
      "Loss evaluation at time 992:\t8.3314\n",
      "\n",
      "Loss evaluation at time 993:\t8.3034\n",
      "\n",
      "Loss evaluation at time 994:\t22.2437\n",
      "\n",
      "Loss evaluation at time 995:\t8.3201\n",
      "\n",
      "Loss evaluation at time 996:\t22.1870\n",
      "\n",
      "Loss evaluation at time 997:\t22.1445\n",
      "\n",
      "Loss evaluation at time 998:\t22.1021\n",
      "\n",
      "Loss evaluation at time 999:\t22.0597\n",
      "\n",
      "Loss evaluation at time 1000:\t22.0173\n",
      "\n",
      "CPU times: user 2min 34s, sys: 663 ms, total: 2min 35s\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fpred, f, w, mean, t, loss = stochasticZFW(F, d, w0, method = \"IRDSA\", r=1, T=1000, eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdf0aca97d0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT:\n",
      "\n",
      "F(w_pred) = 183506.7064278634\n",
      "\n",
      "F(w) = 183528.72376379377\n",
      "\n",
      "w = [ 4.10911465e-04  1.57315358e-06  1.20546499e-08  1.41221084e-06\n",
      "  1.05317500e-06  5.22047748e-07  2.67517668e-01  7.31129174e-01\n",
      "  6.87140792e-04  2.27947111e-05  1.43396712e-04  3.39823294e-07\n",
      "  5.67333862e-07  1.01727444e-06  9.63924717e-07  1.88822163e-06\n",
      "  1.54709061e-06  2.07782710e-08  6.38127397e-07  6.93596671e-07\n",
      "  1.61734925e-06  1.37340846e-06  1.56981352e-06  1.64692333e-07\n",
      "  1.91960787e-06  1.94429340e-06  1.41479562e-06  3.39840463e-07\n",
      "  9.00787298e-07  7.39830121e-07  1.90022630e-06  3.50408370e-07\n",
      "  1.59961095e-06  9.77132823e-07  3.65768893e-07  6.18041258e-07\n",
      "  1.46576628e-06  1.82041291e-07  1.04983792e-06  1.99076184e-07\n",
      "  1.66399033e-06  1.93561704e-06  8.94293116e-07  4.80759533e-07\n",
      "  4.23719196e-07  1.66007264e-06  1.41407182e-06  1.66966478e-06\n",
      "  2.66707984e-05 -1.56600752e-05  3.38289454e-07  4.63816092e-07\n",
      "  8.41086607e-07  1.65207175e-06]\n",
      "\n",
      "average w = [ 5.72348063e-03  1.98020707e-04  1.51737905e-06  1.77762040e-04\n",
      "  1.32568403e-04  6.57127602e-05  4.62786450e-01  5.01884743e-01\n",
      "  1.34938472e-02  2.11928426e-03  4.05006115e-03  4.27752571e-05\n",
      "  7.14131499e-05  1.28049420e-04  1.21334024e-04  2.37679898e-04\n",
      "  1.94740030e-04  2.61546487e-06  8.03242861e-05  8.73064809e-05\n",
      "  2.03583837e-04  1.72877789e-04  1.97600276e-04  2.07306474e-05\n",
      "  2.41630641e-04  2.44737932e-04  1.78087398e-04  4.27774183e-05\n",
      "  1.13386601e-04  9.31261165e-05  2.39190985e-04  4.41076536e-05\n",
      "  2.01351028e-04  1.22996594e-04  4.60411594e-05  7.77959434e-05\n",
      "  1.84503331e-04  2.29144475e-05  1.32148349e-04  2.50587147e-05\n",
      "  2.09454783e-04  2.43645795e-04  1.12569146e-04  6.05156062e-05\n",
      "  5.33356538e-05  2.08961644e-04  1.77996291e-04  2.10169055e-04\n",
      "  2.10718675e-03 -1.97121196e-03  4.25821850e-05  5.83828506e-05\n",
      "  1.05871777e-04  2.07954532e-04]\n",
      "\n",
      "T = 1000\n"
     ]
    }
   ],
   "source": [
    "print(f'OUTPUT:\\n\\nF(w_pred) = {fpred}\\n\\nF(w) = {f}\\n\\nw = {w}\\n\\naverage w = {mean}\\n\\nT = {t}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeroth order stochastic accelerated gradient method with inexact updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InexactUpdate(g, d, v, r, gamma, mu):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    - g: gradient approximation \n",
    "    - d: dimension\n",
    "    - v: starting point\n",
    "    - r: radius\n",
    "    - gamma: decreasing coefficient\n",
    "    - mu: threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    haty = v\n",
    "    t = 1\n",
    "    while True:\n",
    "        # ARGMIN PROBLEM\n",
    "        ht1 = g + gamma*(haty - v)\n",
    "        i_k = np.argmax(np.abs(ht1))\n",
    "        ei = e(i_k, d) * r\n",
    "        yt = np.sign(-ht1[i_k]) * ei\n",
    "        if np.dot(ht1, yt - haty) >= - mu:\n",
    "            break\n",
    "        else:\n",
    "            haty = (t-1)/(t+1) * haty + 2/(t+1)*yt\n",
    "            t +=1\n",
    "    return haty\n",
    "    \n",
    "\n",
    "L = 2/X.shape[0] * norm(X.T @ X)\n",
    "# D = 2*r\n",
    "B = 1\n",
    "\n",
    "\n",
    "def IZFW(F, d, w0, L, B, r = 1, T = 100, eps = 1e-6):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    - F: loss function\n",
    "    - d: dimension\n",
    "    - w0: starting point\n",
    "    - L: lipschitz\n",
    "    - B: 1\n",
    "    - r: radius of the ball\n",
    "    - T: max iteration\n",
    "    - eps: tolerance\n",
    "    \"\"\"\n",
    "    \n",
    "    alpha = lambda t: 2/(t+2)\n",
    "    gamma = lambda t: 4*L/t\n",
    "    mu = lambda t: L*2*r/(t*T)\n",
    "    m = lambda t: 100 #t * (t+1) / 2*r * np.max([(d+5)*B*T, d+3])\n",
    "    c = 1 / (np.sqrt(2*T)) * np.max([1/(d+3), np.sqrt(2*r/(d*(T+1)))]) # smoothing parameter now fixed\n",
    "    \n",
    "    loss = []\n",
    "    v, w = w0, w0\n",
    "    partial = 0\n",
    "    \n",
    "    for t in range(1, T+1):\n",
    "        dt = (1-alpha(t)) * w + alpha(t) * v\n",
    "        g = IRDSA(F, dt, int(np.ceil(m(t))), c, d)\n",
    "        v = InexactUpdate(g, d, v, r, gamma(t), mu(t)) #ICG\n",
    "        w_pred = w\n",
    "        w = (1 - alpha(t)) * w + alpha(t) * v\n",
    "        partial += w\n",
    "        loss_eval = np.abs(F(w_pred) - F(w))\n",
    "        loss.append(loss_eval)\n",
    "        print(f\"Loss evaluation at time {t}:\\t{loss_eval:.4f}\\n\")\n",
    "        if loss_eval < eps: break # check stopping condition\n",
    "    return F(w_pred), F(w), w, partial/T, t, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I parametri degli algoritmi (L per deterministic FW e IGC + tutti quelli di IGC che sono collegati al gradiente, tipo varianza del grad e grad stesso)\n",
    "\n",
    "I grafici uguali o no? Che differenza c'è tra # oracolo e # di iterazioni? (Loss disponibile solo a fine chiamate oracolo)\n",
    "\n",
    "I dataset: il primo ok, secondo stesso preprocessing ma abbiamo risultati diversi, il terzo non sappiamo cos'è e come si usa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss evaluation at time 1:\t343218.6203\n",
      "\n",
      "Loss evaluation at time 2:\t51344.6769\n",
      "\n",
      "Loss evaluation at time 3:\t18048.9446\n",
      "\n",
      "Loss evaluation at time 4:\t8491.1310\n",
      "\n",
      "Loss evaluation at time 5:\t4692.4353\n",
      "\n",
      "Loss evaluation at time 6:\t8297.1382\n",
      "\n",
      "Loss evaluation at time 7:\t760.2760\n",
      "\n",
      "Loss evaluation at time 8:\t4573.0200\n",
      "\n",
      "Loss evaluation at time 9:\t3151.4525\n",
      "\n",
      "Loss evaluation at time 10:\t2267.2214\n",
      "\n",
      "Loss evaluation at time 11:\t18811.6069\n",
      "\n",
      "Loss evaluation at time 12:\t13999.0834\n",
      "\n",
      "Loss evaluation at time 13:\t3843.9474\n",
      "\n",
      "Loss evaluation at time 14:\t3007.0598\n",
      "\n",
      "Loss evaluation at time 15:\t4602.8195\n",
      "\n",
      "Loss evaluation at time 16:\t3762.1772\n",
      "\n",
      "Loss evaluation at time 17:\t1273.1034\n",
      "\n",
      "Loss evaluation at time 18:\t1036.8468\n",
      "\n",
      "Loss evaluation at time 19:\t2622.8724\n",
      "\n",
      "Loss evaluation at time 20:\t2230.3825\n",
      "\n",
      "Loss evaluation at time 21:\t386.5063\n",
      "\n",
      "Loss evaluation at time 22:\t313.2025\n",
      "\n",
      "Loss evaluation at time 23:\t9151.9422\n",
      "\n",
      "Loss evaluation at time 24:\t2429.4534\n",
      "\n",
      "Loss evaluation at time 25:\t769.6415\n",
      "\n",
      "Loss evaluation at time 26:\t669.5347\n",
      "\n",
      "Loss evaluation at time 27:\t1899.2705\n",
      "\n",
      "Loss evaluation at time 28:\t14167.8149\n",
      "\n",
      "Loss evaluation at time 29:\t2646.0458\n",
      "\n",
      "Loss evaluation at time 30:\t1186.0915\n",
      "\n",
      "Loss evaluation at time 31:\t1062.6029\n",
      "\n",
      "Loss evaluation at time 32:\t2099.5449\n",
      "\n",
      "Loss evaluation at time 33:\t810.3252\n",
      "\n",
      "Loss evaluation at time 34:\t5983.1526\n",
      "\n",
      "Loss evaluation at time 35:\t1058.6706\n",
      "\n",
      "Loss evaluation at time 36:\t2002.6324\n",
      "\n",
      "Loss evaluation at time 37:\t1830.1605\n",
      "\n",
      "Loss evaluation at time 38:\t1677.1521\n",
      "\n",
      "Loss evaluation at time 39:\t628.5440\n",
      "\n",
      "Loss evaluation at time 40:\t575.5057\n",
      "\n",
      "Loss evaluation at time 41:\t1417.8685\n",
      "\n",
      "Loss evaluation at time 42:\t1310.1783\n",
      "\n",
      "Loss evaluation at time 43:\t388.9126\n",
      "\n",
      "Loss evaluation at time 44:\t1172.9086\n",
      "\n",
      "Loss evaluation at time 45:\t1089.7771\n",
      "\n",
      "Loss evaluation at time 46:\t1014.4071\n",
      "\n",
      "Loss evaluation at time 47:\t945.9078\n",
      "\n",
      "Loss evaluation at time 48:\t171.9077\n",
      "\n",
      "Loss evaluation at time 49:\t156.3933\n",
      "\n",
      "Loss evaluation at time 50:\t142.5768\n",
      "\n",
      "Loss evaluation at time 51:\t824.7171\n",
      "\n",
      "Loss evaluation at time 52:\t100.2410\n",
      "\n",
      "Loss evaluation at time 53:\t758.9960\n",
      "\n",
      "Loss evaluation at time 54:\t4752.8521\n",
      "\n",
      "Loss evaluation at time 55:\t888.7692\n",
      "\n",
      "Loss evaluation at time 56:\t837.4114\n",
      "\n",
      "Loss evaluation at time 57:\t3388.5684\n",
      "\n",
      "Loss evaluation at time 58:\t292.6990\n",
      "\n",
      "Loss evaluation at time 59:\t274.0463\n",
      "\n",
      "Loss evaluation at time 60:\t256.9321\n",
      "\n",
      "Loss evaluation at time 61:\t241.2030\n",
      "\n",
      "Loss evaluation at time 62:\t811.2564\n",
      "\n",
      "Loss evaluation at time 63:\t199.7858\n",
      "\n",
      "Loss evaluation at time 64:\t753.2880\n",
      "\n",
      "Loss evaluation at time 65:\t715.6193\n",
      "\n",
      "Loss evaluation at time 66:\t3958.4945\n",
      "\n",
      "Loss evaluation at time 67:\t802.9564\n",
      "\n",
      "Loss evaluation at time 68:\t764.3602\n",
      "\n",
      "Loss evaluation at time 69:\t728.2268\n",
      "\n",
      "Loss evaluation at time 70:\t188.9882\n",
      "\n",
      "Loss evaluation at time 71:\t178.3869\n",
      "\n",
      "Loss evaluation at time 72:\t667.7398\n",
      "\n",
      "Loss evaluation at time 73:\t637.8539\n",
      "\n",
      "Loss evaluation at time 74:\t609.7457\n",
      "\n",
      "Loss evaluation at time 75:\t583.2842\n",
      "\n",
      "Loss evaluation at time 76:\t558.3498\n",
      "\n",
      "Loss evaluation at time 77:\t85.8924\n",
      "\n",
      "Loss evaluation at time 78:\t80.2929\n",
      "\n",
      "Loss evaluation at time 79:\t519.7813\n",
      "\n",
      "Loss evaluation at time 80:\t62.6555\n",
      "\n",
      "Loss evaluation at time 81:\t58.3398\n",
      "\n",
      "Loss evaluation at time 82:\t54.3495\n",
      "\n",
      "Loss evaluation at time 83:\t480.2303\n",
      "\n",
      "Loss evaluation at time 84:\t461.4670\n",
      "\n",
      "Loss evaluation at time 85:\t443.6799\n",
      "\n",
      "Loss evaluation at time 86:\t20.7167\n",
      "\n",
      "Loss evaluation at time 87:\t422.6315\n",
      "\n",
      "Loss evaluation at time 88:\t9.8113\n",
      "\n",
      "Loss evaluation at time 89:\t2521.7195\n",
      "\n",
      "Loss evaluation at time 90:\t457.4979\n",
      "\n",
      "Loss evaluation at time 91:\t441.0636\n",
      "\n",
      "Loss evaluation at time 92:\t425.4164\n",
      "\n",
      "Loss evaluation at time 93:\t36.4937\n",
      "\n",
      "Loss evaluation at time 94:\t406.3857\n",
      "\n",
      "Loss evaluation at time 95:\t26.0137\n",
      "\n",
      "Loss evaluation at time 96:\t23.7846\n",
      "\n",
      "Loss evaluation at time 97:\t385.2720\n",
      "\n",
      "Loss evaluation at time 98:\t372.3886\n",
      "\n",
      "Loss evaluation at time 99:\t360.0801\n",
      "\n",
      "Loss evaluation at time 100:\t348.3145\n",
      "\n",
      "CPU times: user 2min 52s, sys: 412 ms, total: 2min 52s\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fpred, f, w, mean, t, loss = IZFW(F, d, w0, L, B, r = 1, T = 100, eps = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd208588b50>]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT:\n",
      "\n",
      "F(w_pred) = 195918.2850875792\n",
      "\n",
      "F(w) = 195569.97054185363\n",
      "\n",
      "w = [3.12588381e-02 4.02983567e-06 3.08795393e-08 3.61756009e-06\n",
      " 5.63267261e-03 1.33729259e-06 3.81677030e-01 5.43780569e-01\n",
      " 1.37874824e-02 2.87166285e-06 2.36886474e-02 8.70501166e-07\n",
      " 1.45329881e-06 2.60587958e-06 2.46921740e-06 4.83692308e-06\n",
      " 3.96307199e-06 5.32262194e-08 1.63464558e-06 1.77673727e-06\n",
      " 4.14304857e-06 3.51816278e-06 4.02127965e-06 4.21880637e-07\n",
      " 4.91732298e-06 4.98055814e-06 3.62418132e-06 8.70545149e-07\n",
      " 2.30748277e-06 1.89517021e-06 4.86767458e-06 8.97616203e-07\n",
      " 4.09760962e-06 2.50305167e-06 9.36964163e-07 1.58319234e-06\n",
      " 3.75474925e-06 4.66322230e-07 2.68929516e-06 5.09959305e-07\n",
      " 4.26252570e-06 4.95833253e-06 2.29084708e-06 1.23152751e-06\n",
      " 1.08541133e-06 4.25249003e-06 3.62232723e-06 4.27706155e-06\n",
      " 2.70622791e-06 2.62828100e-07 8.66572037e-07 1.18812470e-06\n",
      " 2.15455175e-06 4.23199472e-06]\n",
      "\n",
      "average w = [4.85713243e-02 2.03506701e-04 1.55941674e-06 1.82686785e-04\n",
      " 1.44499666e-02 6.75332759e-05 4.34690000e-01 4.50918711e-01\n",
      " 2.62678613e-02 1.45018974e-04 1.62766943e-02 4.39603089e-05\n",
      " 7.33915900e-05 1.31596919e-04 1.24695479e-04 2.44264616e-04\n",
      " 2.00135135e-04 2.68792408e-06 8.25496016e-05 8.97252321e-05\n",
      " 2.09223953e-04 1.77667220e-04 2.03074622e-04 2.13049722e-05\n",
      " 2.48324811e-04 2.51518186e-04 1.83021157e-04 4.39625300e-05\n",
      " 1.16527880e-04 9.57060956e-05 2.45817567e-04 4.53296183e-05\n",
      " 2.06929286e-04 1.26404109e-04 4.73166902e-05 7.99512133e-05\n",
      " 1.89614837e-04 2.35492726e-05 1.35809405e-04 2.57529449e-05\n",
      " 2.15257548e-04 2.50395793e-04 1.15687778e-04 6.21921392e-05\n",
      " 5.48132723e-05 2.14750747e-04 1.82927525e-04 2.15991608e-04\n",
      " 1.36664510e-04 1.32728190e-05 4.37618879e-05 6.00002974e-05\n",
      " 1.08804863e-04 2.13715733e-04]\n",
      "\n",
      "T = 100\n"
     ]
    }
   ],
   "source": [
    "print(f'OUTPUT:\\n\\nF(w_pred) = {fpred}\\n\\nF(w) = {f}\\n\\nw = {w}\\n\\naverage w = {mean}\\n\\nT = {t}')# m=6, T=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT:\n",
      "\n",
      "F(w_pred) = 198152.00822366346\n",
      "\n",
      "F(w) = 198018.65622128965\n",
      "\n",
      "w = [4.47739238e-02 1.14471662e-03 4.80743181e-09 5.63194071e-07\n",
      " 4.20009460e-07 2.08194264e-07 3.76933956e-01 5.25665416e-01\n",
      " 2.27723602e-02 4.47070249e-07 2.64906774e-02 1.35522585e-07\n",
      " 2.20039787e-03 4.05692205e-07 3.84416172e-07 7.53028653e-07\n",
      " 6.16984540e-07 8.28643904e-09 2.54487188e-07 2.76608507e-07\n",
      " 6.45003906e-07 5.47719559e-07 6.26046507e-07 6.56798139e-08\n",
      " 7.65545583e-07 7.75390248e-07 5.64224887e-07 1.35529433e-07\n",
      " 3.59236773e-07 2.95046551e-07 7.57816151e-07 1.39743946e-07\n",
      " 6.37929816e-07 3.89683605e-07 1.45869771e-07 2.46476774e-07\n",
      " 5.84552147e-07 7.25986323e-08 4.18678626e-07 7.93922008e-08\n",
      " 6.63604513e-07 7.71930090e-07 3.56646873e-07 1.91728395e-07\n",
      " 1.68980532e-07 6.62042126e-07 5.63936236e-07 6.65867503e-07\n",
      " 4.21314775e-07 4.09179734e-08 1.34910885e-07 1.84971298e-07\n",
      " 3.35427952e-07 6.58851346e-07]\n",
      "\n",
      "average w = [2.18088624e-02 5.61318427e-03 7.23518488e-07 8.47607077e-05\n",
      " 6.32114238e-05 3.13332367e-05 3.41893760e-01 5.85978471e-01\n",
      " 2.39068738e-02 6.72840725e-05 1.35136211e-02 2.03961491e-05\n",
      " 4.49321245e-03 6.10566769e-05 5.78546338e-05 1.13330812e-04\n",
      " 9.28561732e-05 1.24710908e-06 3.83003219e-05 4.16295803e-05\n",
      " 9.70730878e-05 8.24317936e-05 9.42199993e-05 9.88481199e-06\n",
      " 1.15214610e-04 1.16696232e-04 8.49158455e-05 2.03971796e-05\n",
      " 5.40651343e-05 4.44045059e-05 1.14051331e-04 2.10314639e-05\n",
      " 9.60084372e-05 5.86473826e-05 2.19534005e-05 3.70947545e-05\n",
      " 8.79750981e-05 1.09260942e-05 6.30111331e-05 1.19485262e-05\n",
      " 9.98724792e-05 1.16175478e-04 5.36753544e-05 2.88551235e-05\n",
      " 2.54315700e-05 9.96373400e-05 8.48724035e-05 1.00213059e-04\n",
      " 6.34078736e-05 6.15815500e-06 2.03040882e-05 2.78381804e-05\n",
      " 5.04819067e-05 9.91571276e-05]\n",
      "\n",
      "T = 300\n"
     ]
    }
   ],
   "source": [
    "print(f'OUTPUT:\\n\\nF(w_pred) = {fpred}\\n\\nF(w) = {f}\\n\\nw = {w}\\n\\naverage w = {mean}\\n\\nT = {t}')#100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function numba.decorators._jit.<locals>.wrapper(func)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "njit(parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
