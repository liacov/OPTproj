{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e(i, d):\n",
    "    ei = np.zeros(d)\n",
    "    ei[i] = 1\n",
    "    return ei\n",
    "\n",
    "\n",
    "\n",
    "def KWSA(F, w, m, c, d):\n",
    "    \"\"\" \n",
    "    Kiefer-Wolfowitz stochastic approximation\n",
    "    for gradient estimation \n",
    "    \n",
    "    INPUT:\n",
    "    - F: objective function\n",
    "    - w: current weight\n",
    "    - m: sample size (null in this case)\n",
    "    - d: dimension\n",
    "    - c: costant\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    F_wc = np.array([F(w + c * e(i, d)) for i in range(d)])\n",
    "    return (F_wc - F(w)) / c\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def IRDSA(F, w, m, c, d):\n",
    "    \"\"\" \n",
    "    Improvised Random Direction stochastic approximation\n",
    "    for gradient estimation \n",
    "    \n",
    "    INPUT:\n",
    "    - F: objective function\n",
    "    - w: current weight\n",
    "    - m: sample dimension\n",
    "    - d: features dimension\n",
    "    - c: costant\n",
    "    \n",
    "    \"\"\"\n",
    "    z = np.random.normal(0, 1, (d, m))\n",
    "    F_w = F(w)\n",
    "    return np.mean([(F(w + c * z[:,i]) - F_w) / c * z[:,i] for i in range(m)], axis = 0)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def detZFW(F, L, d, w0, r=1, T=100, eps=1e-5):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    - F: loss function\n",
    "    - L: Lip constant\n",
    "    - d: dimension\n",
    "    - w0: starting point\n",
    "    - r: radius of the ball\n",
    "    - T: max iteration\n",
    "    - eps: tolerance\n",
    "    \"\"\"\n",
    "\n",
    "    gamma = lambda t: 2/(t+2)\n",
    "    c = lambda t: L*gamma(t)/d\n",
    "    w = w0\n",
    "    partial = 0\n",
    "    for t in range(1, T+1):\n",
    "        # comupute the gradient approx\n",
    "        gt = KWSA(F, w, None, c(t), d)\n",
    "        # compute the linear problem solution on the L1 Ball of radius r\n",
    "        i_k = np.argmax(np.abs(gt))\n",
    "        ei = e(i_k, d) * r\n",
    "        v = np.sign(-gt[i_k]) * ei\n",
    "        # compute step \n",
    "        w_pred = w\n",
    "        w = (1 - gamma(t)) * w + gamma(t) * v\n",
    "        partial += w\n",
    "        loss_eval = F(w_pred) - F(w)\n",
    "        print(f\"Loss evaluation at time {t}:\\t{loss_eval:.4f}\\n\")\n",
    "        if loss_eval < eps: break # check stopping condition\n",
    "    return F(w_pred), F(w), w, partial/T, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X, y = datasets.load_svmlight_file(\"../Data/covtype.libsvm.binary.scale.bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space Dimensions\n",
      "d: 54\n",
      "n: 581012\n"
     ]
    }
   ],
   "source": [
    "# space dimension\n",
    "d = X.shape[1]\n",
    "print(f\"Space Dimensions\\nd: {d}\")\n",
    "print(f\"n: {y.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w_star = np.linalg.inv(X * X.T) * X * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the objective function\n",
    "F = lambda w: 0.5 * np.sum(np.power(y - X @ w, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L: 3\n"
     ]
    }
   ],
   "source": [
    "# initialize prarameters for the algorithm\n",
    "\n",
    "# stating point \n",
    "np.random.seed(1007)\n",
    "w0 = np.random.rand(d)\n",
    "w0 = w0/np.sum(w0) * np.random.rand(1)\n",
    "#print(w0)\n",
    "#print(F(w0))\n",
    "\n",
    "# Lipschitz constant computation\n",
    "L = 3 #np.linalg.norm(X.dot(w0))\n",
    "print(f\"L: {L}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss evaluation at time 1:\t343218.6203\n",
      "\n",
      "Loss evaluation at time 2:\t60852.1867\n",
      "\n",
      "Loss evaluation at time 3:\t21546.1982\n",
      "\n",
      "Loss evaluation at time 4:\t10174.2399\n",
      "\n",
      "Loss evaluation at time 5:\t5634.6010\n",
      "\n",
      "Loss evaluation at time 6:\t3455.4252\n",
      "\n",
      "Loss evaluation at time 7:\t2275.3260\n",
      "\n",
      "Loss evaluation at time 8:\t1579.2618\n",
      "\n",
      "Loss evaluation at time 9:\t1141.5884\n",
      "\n",
      "Loss evaluation at time 10:\t852.3419\n",
      "\n",
      "Loss evaluation at time 11:\t653.4024\n",
      "\n",
      "Loss evaluation at time 12:\t512.0179\n",
      "\n",
      "Loss evaluation at time 13:\t408.7466\n",
      "\n",
      "Loss evaluation at time 14:\t331.5386\n",
      "\n",
      "Loss evaluation at time 15:\t272.6494\n",
      "\n",
      "Loss evaluation at time 16:\t226.9440\n",
      "\n",
      "Loss evaluation at time 17:\t190.9247\n",
      "\n",
      "Loss evaluation at time 18:\t162.1523\n",
      "\n",
      "Loss evaluation at time 19:\t138.8899\n",
      "\n",
      "Loss evaluation at time 20:\t119.8777\n",
      "\n",
      "Loss evaluation at time 21:\t104.1867\n",
      "\n",
      "Loss evaluation at time 22:\t91.1216\n",
      "\n",
      "Loss evaluation at time 23:\t80.1548\n",
      "\n",
      "Loss evaluation at time 24:\t70.8810\n",
      "\n",
      "Loss evaluation at time 25:\t62.9855\n",
      "\n",
      "Loss evaluation at time 26:\t56.2213\n",
      "\n",
      "Loss evaluation at time 27:\t50.3926\n",
      "\n",
      "Loss evaluation at time 28:\t45.3431\n",
      "\n",
      "Loss evaluation at time 29:\t40.9468\n",
      "\n",
      "Loss evaluation at time 30:\t37.1012\n",
      "\n",
      "Loss evaluation at time 31:\t33.7227\n",
      "\n",
      "Loss evaluation at time 32:\t30.7425\n",
      "\n",
      "Loss evaluation at time 33:\t28.1035\n",
      "\n",
      "Loss evaluation at time 34:\t25.7583\n",
      "\n",
      "Loss evaluation at time 35:\t23.6670\n",
      "\n",
      "Loss evaluation at time 36:\t21.7962\n",
      "\n",
      "Loss evaluation at time 37:\t20.1176\n",
      "\n",
      "Loss evaluation at time 38:\t18.6071\n",
      "\n",
      "Loss evaluation at time 39:\t17.2441\n",
      "\n",
      "Loss evaluation at time 40:\t16.0111\n",
      "\n",
      "Loss evaluation at time 41:\t14.8930\n",
      "\n",
      "Loss evaluation at time 42:\t13.8766\n",
      "\n",
      "Loss evaluation at time 43:\t12.9507\n",
      "\n",
      "Loss evaluation at time 44:\t12.1054\n",
      "\n",
      "Loss evaluation at time 45:\t11.3321\n",
      "\n",
      "Loss evaluation at time 46:\t10.6233\n",
      "\n",
      "Loss evaluation at time 47:\t9.9724\n",
      "\n",
      "Loss evaluation at time 48:\t9.3736\n",
      "\n",
      "Loss evaluation at time 49:\t8.8218\n",
      "\n",
      "Loss evaluation at time 50:\t8.3125\n",
      "\n",
      "Loss evaluation at time 51:\t7.8417\n",
      "\n",
      "Loss evaluation at time 52:\t7.4058\n",
      "\n",
      "Loss evaluation at time 53:\t7.0016\n",
      "\n",
      "Loss evaluation at time 54:\t6.6263\n",
      "\n",
      "Loss evaluation at time 55:\t6.2774\n",
      "\n",
      "Loss evaluation at time 56:\t5.9525\n",
      "\n",
      "Loss evaluation at time 57:\t5.6497\n",
      "\n",
      "Loss evaluation at time 58:\t5.3671\n",
      "\n",
      "Loss evaluation at time 59:\t5.1030\n",
      "\n",
      "Loss evaluation at time 60:\t4.8559\n",
      "\n",
      "Loss evaluation at time 61:\t4.6246\n",
      "\n",
      "Loss evaluation at time 62:\t4.4077\n",
      "\n",
      "Loss evaluation at time 63:\t4.2042\n",
      "\n",
      "Loss evaluation at time 64:\t4.0130\n",
      "\n",
      "Loss evaluation at time 65:\t3.8333\n",
      "\n",
      "Loss evaluation at time 66:\t3.6641\n",
      "\n",
      "Loss evaluation at time 67:\t3.5047\n",
      "\n",
      "Loss evaluation at time 68:\t3.3545\n",
      "\n",
      "Loss evaluation at time 69:\t3.2127\n",
      "\n",
      "Loss evaluation at time 70:\t3.0788\n",
      "\n",
      "Loss evaluation at time 71:\t2.9522\n",
      "\n",
      "Loss evaluation at time 72:\t2.8325\n",
      "\n",
      "Loss evaluation at time 73:\t2.7191\n",
      "\n",
      "Loss evaluation at time 74:\t2.6118\n",
      "\n",
      "Loss evaluation at time 75:\t2.5100\n",
      "\n",
      "Loss evaluation at time 76:\t2.4134\n",
      "\n",
      "Loss evaluation at time 77:\t2.3217\n",
      "\n",
      "Loss evaluation at time 78:\t2.2347\n",
      "\n",
      "Loss evaluation at time 79:\t2.1519\n",
      "\n",
      "Loss evaluation at time 80:\t2.0731\n",
      "\n",
      "Loss evaluation at time 81:\t1.9982\n",
      "\n",
      "Loss evaluation at time 82:\t1.9268\n",
      "\n",
      "Loss evaluation at time 83:\t1.8588\n",
      "\n",
      "Loss evaluation at time 84:\t1.7939\n",
      "\n",
      "Loss evaluation at time 85:\t1.7320\n",
      "\n",
      "Loss evaluation at time 86:\t1.6730\n",
      "\n",
      "Loss evaluation at time 87:\t1.6166\n",
      "\n",
      "Loss evaluation at time 88:\t1.5627\n",
      "\n",
      "Loss evaluation at time 89:\t1.5111\n",
      "\n",
      "Loss evaluation at time 90:\t1.4619\n",
      "\n",
      "Loss evaluation at time 91:\t1.4147\n",
      "\n",
      "Loss evaluation at time 92:\t1.3695\n",
      "\n",
      "Loss evaluation at time 93:\t1.3263\n",
      "\n",
      "Loss evaluation at time 94:\t1.2848\n",
      "\n",
      "Loss evaluation at time 95:\t1.2451\n",
      "\n",
      "Loss evaluation at time 96:\t1.2070\n",
      "\n",
      "Loss evaluation at time 97:\t1.1704\n",
      "\n",
      "Loss evaluation at time 98:\t1.1353\n",
      "\n",
      "Loss evaluation at time 99:\t1.1015\n",
      "\n",
      "Loss evaluation at time 100:\t1.0691\n",
      "\n",
      "CPU times: user 2min, sys: 3.24 s, total: 2min 4s\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fpred, f, w_det, mean, t = detZFW(F, L, d, w0, T=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT:\n",
      "\n",
      "F(w0) = 634571.9989119768\n",
      "\n",
      "F(w_pred) = 179684.5113658399\n",
      "\n",
      "F(w) = 179683.44223484417\n",
      "\n",
      "w = [2.77132211e-06 4.02983567e-06 3.08795393e-08 3.61756009e-06\n",
      " 2.69784349e-06 1.33729259e-06 3.56824604e-06 9.99808524e-01\n",
      " 3.75108695e-06 2.87166285e-06 3.92599860e-06 8.70501166e-07\n",
      " 1.45329881e-06 2.60587958e-06 2.46921740e-06 4.83692308e-06\n",
      " 3.96307199e-06 5.32262194e-08 1.63464558e-06 1.77673727e-06\n",
      " 4.14304857e-06 3.51816278e-06 4.02127965e-06 4.21880637e-07\n",
      " 4.91732298e-06 4.98055814e-06 3.62418132e-06 8.70545149e-07\n",
      " 2.30748277e-06 1.89517021e-06 4.86767458e-06 8.97616203e-07\n",
      " 4.09760962e-06 2.50305167e-06 9.36964163e-07 1.58319234e-06\n",
      " 3.75474925e-06 4.66322230e-07 2.68929516e-06 5.09959305e-07\n",
      " 4.26252570e-06 4.95833253e-06 2.29084708e-06 1.23152751e-06\n",
      " 1.08541133e-06 4.25249003e-06 3.62232723e-06 4.27706155e-06\n",
      " 2.70622791e-06 2.62828100e-07 8.66572037e-07 1.18812470e-06\n",
      " 2.15455175e-06 4.23199472e-06]\n",
      "\n",
      "average w = [1.39951766e-04 2.03506701e-04 1.55941674e-06 1.82686785e-04\n",
      " 1.36241096e-04 6.75332759e-05 1.80196425e-04 9.90330476e-01\n",
      " 1.89429891e-04 1.45018974e-04 1.98262929e-04 4.39603089e-05\n",
      " 7.33915900e-05 1.31596919e-04 1.24695479e-04 2.44264616e-04\n",
      " 2.00135135e-04 2.68792408e-06 8.25496016e-05 8.97252321e-05\n",
      " 2.09223953e-04 1.77667220e-04 2.03074622e-04 2.13049722e-05\n",
      " 2.48324811e-04 2.51518186e-04 1.83021157e-04 4.39625300e-05\n",
      " 1.16527880e-04 9.57060956e-05 2.45817567e-04 4.53296183e-05\n",
      " 2.06929286e-04 1.26404109e-04 4.73166902e-05 7.99512133e-05\n",
      " 1.89614837e-04 2.35492726e-05 1.35809405e-04 2.57529449e-05\n",
      " 2.15257548e-04 2.50395793e-04 1.15687778e-04 6.21921392e-05\n",
      " 5.48132723e-05 2.14750747e-04 1.82927525e-04 2.15991608e-04\n",
      " 1.36664510e-04 1.32728190e-05 4.37618879e-05 6.00002974e-05\n",
      " 1.08804863e-04 2.13715733e-04]\n",
      "\n",
      "T = 100\n"
     ]
    }
   ],
   "source": [
    "print(f'OUTPUT:\\n\\nF(w0) = {F(w0)}\\n\\nF(w_pred) = {fpred}\\n\\nF(w) = {f}\\n\\nw = {w_det}\\n\\naverage w = {mean}\\n\\nT = {t}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Free Frank Wolfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochasticZFW(F, d,  w0, method = \"IRDSA\", r=1, T=100, eps=1e-5):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    - F: loss function\n",
    "    - d: dimension\n",
    "    - w0: starting point\n",
    "    - method: zeroth order oracle\n",
    "    - r: radius of the ball\n",
    "    - T: max iteration\n",
    "    - eps: tolerance\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters_dict = {\"KWSA\": {\"m\": None, \n",
    "                                \"c\": lambda t: 2 / (np.sqrt(d) * np.power(t+8, 1/3)),\n",
    "                                \"p\": lambda t: 4 / np.power(t+8, 2/3),\n",
    "                                \"oracle\": KWSA},\n",
    "                       \n",
    "                   \n",
    "                       \"RDSA\": {\"m\": 1, \n",
    "                                \"c\": lambda t: 2 / (np.power(d, 3/2) * np.power(t+8, 1/3)),\n",
    "                                \"p\": lambda t: 4 / (np.power(d, 1/3) * np.power(t+8, 2/3)),\n",
    "                                \"oracle\": IRDSA},\n",
    "                   \n",
    "                       \"IRDSA\": {\"m\": 6, \n",
    "                                \"c\": lambda t: 2 * np.sqrt(6) / (np.power(d, 3/2) * np.power(t+8, 1/3)),\n",
    "                                \"p\": lambda t: 4 / (np.power(1+d/6, 1/3) * np.power(t+8, 2/3)),\n",
    "                                \"oracle\": IRDSA}\n",
    "                  \n",
    "                        }\n",
    "    \n",
    "    return sZFW(F, d, w0, Parameters_dict[method], r, T, eps)\n",
    "    \n",
    "  \n",
    "\n",
    "    \n",
    "def sZFW(F, d, w0, params, r, T, eps):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    - F: loss function\n",
    "    - d: dimension\n",
    "    - w0: starting point\n",
    "    - params: dict of parameters for the selected method\n",
    "    - r: radius of the ball\n",
    "    - T: max iteration\n",
    "    - eps: tolerance\n",
    "    \"\"\"\n",
    "    \n",
    "    loss = []\n",
    "    gamma = lambda t: 2/(t+8)\n",
    "    w = w0\n",
    "    dt = np.zeros(d)\n",
    "    partial = 0\n",
    "    for t in range(1, T+1):\n",
    "        # comupute the gradient approx\n",
    "        gt = params[\"oracle\"](F, w, params[\"m\"], params[\"c\"](t), d)\n",
    "        dt = (1 - params[\"p\"](t)) * dt + params[\"p\"](t) * gt\n",
    "        # compute the linear problem solution on the L1 Ball of radius r\n",
    "        ei = e(np.argmax(np.abs(dt)), d) * r\n",
    "        v = np.sign(-dt) * ei\n",
    "        # compute step \n",
    "        w_pred = w\n",
    "        w = (1 - gamma(t)) * w + gamma(t) * v\n",
    "        partial += w\n",
    "        loss_eval = np.abs(F(w_pred) - F(w))\n",
    "        loss.append(loss_eval)\n",
    "        print(f\"Loss evaluation at time {t}:\\t{loss_eval:.4f}\\n\")\n",
    "        if loss_eval < eps: break # check stopping condition\n",
    "    return F(w_pred), F(w), w, partial/T, t, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss evaluation at time 1:\t23520.7633\n",
      "\n",
      "Loss evaluation at time 2:\t68256.0980\n",
      "\n",
      "Loss evaluation at time 3:\t35400.1179\n",
      "\n",
      "Loss evaluation at time 4:\t5251.6896\n",
      "\n",
      "Loss evaluation at time 5:\t68175.9540\n",
      "\n",
      "Loss evaluation at time 6:\t32987.8042\n",
      "\n",
      "Loss evaluation at time 7:\t52528.1515\n",
      "\n",
      "Loss evaluation at time 8:\t15011.0693\n",
      "\n",
      "Loss evaluation at time 9:\t11947.4145\n",
      "\n",
      "Loss evaluation at time 10:\t31412.1975\n",
      "\n",
      "Loss evaluation at time 11:\t22820.9349\n",
      "\n",
      "Loss evaluation at time 12:\t2880.4525\n",
      "\n",
      "Loss evaluation at time 13:\t17452.3038\n",
      "\n",
      "Loss evaluation at time 14:\t14552.4723\n",
      "\n",
      "Loss evaluation at time 15:\t12262.5886\n",
      "\n",
      "Loss evaluation at time 16:\t10430.8393\n",
      "\n",
      "Loss evaluation at time 17:\t10735.7815\n",
      "\n",
      "Loss evaluation at time 18:\t9265.6786\n",
      "\n",
      "Loss evaluation at time 19:\t8053.8229\n",
      "\n",
      "Loss evaluation at time 20:\t7045.8984\n",
      "\n",
      "Loss evaluation at time 21:\t6200.7023\n",
      "\n",
      "Loss evaluation at time 22:\t5486.6113\n",
      "\n",
      "Loss evaluation at time 23:\t4879.0894\n",
      "\n",
      "Loss evaluation at time 24:\t4358.9075\n",
      "\n",
      "Loss evaluation at time 25:\t3910.8544\n",
      "\n",
      "Loss evaluation at time 26:\t2474.8142\n",
      "\n",
      "Loss evaluation at time 27:\t2226.1146\n",
      "\n",
      "Loss evaluation at time 28:\t2009.9155\n",
      "\n",
      "Loss evaluation at time 29:\t1821.0679\n",
      "\n",
      "Loss evaluation at time 30:\t1655.3697\n",
      "\n",
      "Loss evaluation at time 31:\t1509.3692\n",
      "\n",
      "Loss evaluation at time 32:\t1380.2141\n",
      "\n",
      "Loss evaluation at time 33:\t1265.5335\n",
      "\n",
      "Loss evaluation at time 34:\t1163.3462\n",
      "\n",
      "Loss evaluation at time 35:\t1071.9880\n",
      "\n",
      "Loss evaluation at time 36:\t990.0539\n",
      "\n",
      "Loss evaluation at time 37:\t916.3527\n",
      "\n",
      "Loss evaluation at time 38:\t849.8696\n",
      "\n",
      "Loss evaluation at time 39:\t789.7368\n",
      "\n",
      "Loss evaluation at time 40:\t735.2090\n",
      "\n",
      "Loss evaluation at time 41:\t685.6437\n",
      "\n",
      "Loss evaluation at time 42:\t1471.8326\n",
      "\n",
      "Loss evaluation at time 43:\t570.6282\n",
      "\n",
      "Loss evaluation at time 44:\t534.2523\n",
      "\n",
      "Loss evaluation at time 45:\t500.9384\n",
      "\n",
      "Loss evaluation at time 46:\t1239.6897\n",
      "\n",
      "Loss evaluation at time 47:\t417.7315\n",
      "\n",
      "Loss evaluation at time 48:\t1127.6945\n",
      "\n",
      "Loss evaluation at time 49:\t1059.6937\n",
      "\n",
      "Loss evaluation at time 50:\t997.1088\n",
      "\n",
      "Loss evaluation at time 51:\t939.4090\n",
      "\n",
      "Loss evaluation at time 52:\t886.1244\n",
      "\n",
      "Loss evaluation at time 53:\t204.1538\n",
      "\n",
      "Loss evaluation at time 54:\t191.9464\n",
      "\n",
      "Loss evaluation at time 55:\t4189.5528\n",
      "\n",
      "Loss evaluation at time 56:\t938.4947\n",
      "\n",
      "Loss evaluation at time 57:\t889.1358\n",
      "\n",
      "Loss evaluation at time 58:\t843.2159\n",
      "\n",
      "Loss evaluation at time 59:\t800.4390\n",
      "\n",
      "Loss evaluation at time 60:\t760.5394\n",
      "\n",
      "Loss evaluation at time 61:\t2852.2238\n",
      "\n",
      "Loss evaluation at time 62:\t2774.4085\n",
      "\n",
      "Loss evaluation at time 63:\t345.8358\n",
      "\n",
      "Loss evaluation at time 64:\t328.3758\n",
      "\n",
      "Loss evaluation at time 65:\t312.0771\n",
      "\n",
      "Loss evaluation at time 66:\t296.8450\n",
      "\n",
      "Loss evaluation at time 67:\t282.5939\n",
      "\n",
      "Loss evaluation at time 68:\t269.2461\n",
      "\n",
      "Loss evaluation at time 69:\t256.7314\n",
      "\n",
      "Loss evaluation at time 70:\t244.9857\n",
      "\n",
      "Loss evaluation at time 71:\t2423.6586\n",
      "\n",
      "Loss evaluation at time 72:\t298.2544\n",
      "\n",
      "Loss evaluation at time 73:\t285.3218\n",
      "\n",
      "Loss evaluation at time 74:\t749.1319\n",
      "\n",
      "Loss evaluation at time 75:\t252.4067\n",
      "\n",
      "Loss evaluation at time 76:\t2269.3148\n",
      "\n",
      "Loss evaluation at time 77:\t298.3966\n",
      "\n",
      "Loss evaluation at time 78:\t736.9708\n",
      "\n",
      "Loss evaluation at time 79:\t266.4929\n",
      "\n",
      "Loss evaluation at time 80:\t694.8160\n",
      "\n",
      "Loss evaluation at time 81:\t237.8524\n",
      "\n",
      "Loss evaluation at time 82:\t228.4279\n",
      "\n",
      "Loss evaluation at time 83:\t219.4985\n",
      "\n",
      "Loss evaluation at time 84:\t211.0322\n",
      "\n",
      "Loss evaluation at time 85:\t202.9992\n",
      "\n",
      "Loss evaluation at time 86:\t195.3722\n",
      "\n",
      "Loss evaluation at time 87:\t188.1258\n",
      "\n",
      "Loss evaluation at time 88:\t592.8332\n",
      "\n",
      "Loss evaluation at time 89:\t571.9986\n",
      "\n",
      "Loss evaluation at time 90:\t552.1400\n",
      "\n",
      "Loss evaluation at time 91:\t533.2006\n",
      "\n",
      "Loss evaluation at time 92:\t2208.6437\n",
      "\n",
      "Loss evaluation at time 93:\t2162.9747\n",
      "\n",
      "Loss evaluation at time 94:\t598.3050\n",
      "\n",
      "Loss evaluation at time 95:\t578.7091\n",
      "\n",
      "Loss evaluation at time 96:\t559.9697\n",
      "\n",
      "Loss evaluation at time 97:\t542.0402\n",
      "\n",
      "Loss evaluation at time 98:\t524.8771\n",
      "\n",
      "Loss evaluation at time 99:\t508.4395\n",
      "\n",
      "Loss evaluation at time 100:\t147.8907\n",
      "\n",
      "Loss evaluation at time 101:\t142.7485\n",
      "\n",
      "Loss evaluation at time 102:\t137.8413\n",
      "\n",
      "Loss evaluation at time 103:\t133.1560\n",
      "\n",
      "Loss evaluation at time 104:\t467.1473\n",
      "\n",
      "Loss evaluation at time 105:\t453.2408\n",
      "\n",
      "Loss evaluation at time 106:\t439.8873\n",
      "\n",
      "Loss evaluation at time 107:\t427.0595\n",
      "\n",
      "Loss evaluation at time 108:\t414.7316\n",
      "\n",
      "Loss evaluation at time 109:\t402.8793\n",
      "\n",
      "Loss evaluation at time 110:\t391.4798\n",
      "\n",
      "Loss evaluation at time 111:\t380.5114\n",
      "\n",
      "Loss evaluation at time 112:\t369.9538\n",
      "\n",
      "Loss evaluation at time 113:\t359.7879\n",
      "\n",
      "Loss evaluation at time 114:\t349.9955\n",
      "\n",
      "Loss evaluation at time 115:\t340.5595\n",
      "\n",
      "Loss evaluation at time 116:\t331.4638\n",
      "\n",
      "Loss evaluation at time 117:\t322.6929\n",
      "\n",
      "Loss evaluation at time 118:\t314.2325\n",
      "\n",
      "Loss evaluation at time 119:\t306.0688\n",
      "\n",
      "Loss evaluation at time 120:\t298.1888\n",
      "\n",
      "Loss evaluation at time 121:\t21.5650\n",
      "\n",
      "Loss evaluation at time 122:\t20.1546\n",
      "\n",
      "Loss evaluation at time 123:\t18.8218\n",
      "\n",
      "Loss evaluation at time 124:\t284.5844\n",
      "\n",
      "Loss evaluation at time 125:\t277.5053\n",
      "\n",
      "Loss evaluation at time 126:\t270.6619\n",
      "\n",
      "Loss evaluation at time 127:\t6.3278\n",
      "\n",
      "Loss evaluation at time 128:\t5.3845\n",
      "\n",
      "Loss evaluation at time 129:\t4.4978\n",
      "\n",
      "Loss evaluation at time 130:\t3.6644\n",
      "\n",
      "Loss evaluation at time 131:\t2.8811\n",
      "\n",
      "Loss evaluation at time 132:\t2.1450\n",
      "\n",
      "Loss evaluation at time 133:\t1.4535\n",
      "\n",
      "Loss evaluation at time 134:\t0.8040\n",
      "\n",
      "Loss evaluation at time 135:\t0.1940\n",
      "\n",
      "Loss evaluation at time 136:\t0.3786\n",
      "\n",
      "Loss evaluation at time 137:\t0.9160\n",
      "\n",
      "Loss evaluation at time 138:\t1.4202\n",
      "\n",
      "Loss evaluation at time 139:\t1.8931\n",
      "\n",
      "Loss evaluation at time 140:\t2.3364\n",
      "\n",
      "Loss evaluation at time 141:\t2.7519\n",
      "\n",
      "Loss evaluation at time 142:\t3.1409\n",
      "\n",
      "Loss evaluation at time 143:\t242.8747\n",
      "\n",
      "Loss evaluation at time 144:\t237.4370\n",
      "\n",
      "Loss evaluation at time 145:\t232.1623\n",
      "\n",
      "Loss evaluation at time 146:\t11.4476\n",
      "\n",
      "Loss evaluation at time 147:\t11.6521\n",
      "\n",
      "Loss evaluation at time 148:\t11.8377\n",
      "\n",
      "Loss evaluation at time 149:\t12.0057\n",
      "\n",
      "Loss evaluation at time 150:\t12.1571\n",
      "\n",
      "Loss evaluation at time 151:\t12.2928\n",
      "\n",
      "Loss evaluation at time 152:\t12.4139\n",
      "\n",
      "Loss evaluation at time 153:\t12.5211\n",
      "\n",
      "Loss evaluation at time 154:\t12.6154\n",
      "\n",
      "Loss evaluation at time 155:\t12.6974\n",
      "\n",
      "Loss evaluation at time 156:\t12.7679\n",
      "\n",
      "Loss evaluation at time 157:\t12.8276\n",
      "\n",
      "Loss evaluation at time 158:\t12.8772\n",
      "\n",
      "Loss evaluation at time 159:\t12.9172\n",
      "\n",
      "Loss evaluation at time 160:\t12.9483\n",
      "\n",
      "Loss evaluation at time 161:\t12.9710\n",
      "\n",
      "Loss evaluation at time 162:\t213.6963\n",
      "\n",
      "Loss evaluation at time 163:\t209.3452\n",
      "\n",
      "Loss evaluation at time 164:\t205.1126\n",
      "\n",
      "Loss evaluation at time 165:\t19.0405\n",
      "\n",
      "Loss evaluation at time 166:\t18.9618\n",
      "\n",
      "Loss evaluation at time 167:\t18.8778\n",
      "\n",
      "Loss evaluation at time 168:\t18.7889\n",
      "\n",
      "Loss evaluation at time 169:\t198.5745\n",
      "\n",
      "Loss evaluation at time 170:\t194.6815\n",
      "\n",
      "Loss evaluation at time 171:\t190.8907\n",
      "\n",
      "Loss evaluation at time 172:\t187.1987\n",
      "\n",
      "Loss evaluation at time 173:\t183.6023\n",
      "\n",
      "Loss evaluation at time 174:\t180.0983\n",
      "\n",
      "Loss evaluation at time 175:\t176.6839\n",
      "\n",
      "Loss evaluation at time 176:\t173.3562\n",
      "\n",
      "Loss evaluation at time 177:\t170.1124\n",
      "\n",
      "Loss evaluation at time 178:\t166.9498\n",
      "\n",
      "Loss evaluation at time 179:\t163.8661\n",
      "\n",
      "Loss evaluation at time 180:\t35.4888\n",
      "\n",
      "Loss evaluation at time 181:\t160.6750\n",
      "\n",
      "Loss evaluation at time 182:\t36.4037\n",
      "\n",
      "Loss evaluation at time 183:\t157.5976\n",
      "\n",
      "Loss evaluation at time 184:\t154.7626\n",
      "\n",
      "Loss evaluation at time 185:\t151.9961\n",
      "\n",
      "Loss evaluation at time 186:\t149.2958\n",
      "\n",
      "Loss evaluation at time 187:\t146.6597\n",
      "\n",
      "Loss evaluation at time 188:\t144.0861\n",
      "\n",
      "Loss evaluation at time 189:\t42.5221\n",
      "\n",
      "Loss evaluation at time 190:\t42.1443\n",
      "\n",
      "Loss evaluation at time 191:\t141.5379\n",
      "\n",
      "Loss evaluation at time 192:\t139.1011\n",
      "\n",
      "Loss evaluation at time 193:\t136.7204\n",
      "\n",
      "Loss evaluation at time 194:\t134.3944\n",
      "\n",
      "Loss evaluation at time 195:\t132.1215\n",
      "\n",
      "Loss evaluation at time 196:\t129.9001\n",
      "\n",
      "Loss evaluation at time 197:\t127.7288\n",
      "\n",
      "Loss evaluation at time 198:\t125.6062\n",
      "\n",
      "Loss evaluation at time 199:\t48.4401\n",
      "\n",
      "Loss evaluation at time 200:\t48.0120\n",
      "\n",
      "Loss evaluation at time 201:\t47.5856\n",
      "\n",
      "Loss evaluation at time 202:\t47.1612\n",
      "\n",
      "Loss evaluation at time 203:\t46.7387\n",
      "\n",
      "Loss evaluation at time 204:\t46.3185\n",
      "\n",
      "Loss evaluation at time 205:\t45.9005\n",
      "\n",
      "Loss evaluation at time 206:\t45.4849\n",
      "\n",
      "Loss evaluation at time 207:\t45.0717\n",
      "\n",
      "Loss evaluation at time 208:\t44.6612\n",
      "\n",
      "Loss evaluation at time 209:\t44.2532\n",
      "\n",
      "Loss evaluation at time 210:\t43.8480\n",
      "\n",
      "Loss evaluation at time 211:\t43.4455\n",
      "\n",
      "Loss evaluation at time 212:\t43.0459\n",
      "\n",
      "Loss evaluation at time 213:\t42.6492\n",
      "\n",
      "Loss evaluation at time 214:\t42.2555\n",
      "\n",
      "Loss evaluation at time 215:\t41.8647\n",
      "\n",
      "Loss evaluation at time 216:\t41.4770\n",
      "\n",
      "Loss evaluation at time 217:\t41.0923\n",
      "\n",
      "Loss evaluation at time 218:\t124.8010\n",
      "\n",
      "Loss evaluation at time 219:\t122.8712\n",
      "\n",
      "Loss evaluation at time 220:\t120.9814\n",
      "\n",
      "Loss evaluation at time 221:\t42.7876\n",
      "\n",
      "Loss evaluation at time 222:\t119.1861\n",
      "\n",
      "Loss evaluation at time 223:\t117.3780\n",
      "\n",
      "Loss evaluation at time 224:\t115.6065\n",
      "\n",
      "Loss evaluation at time 225:\t113.8709\n",
      "\n",
      "Loss evaluation at time 226:\t112.1703\n",
      "\n",
      "Loss evaluation at time 227:\t110.5036\n",
      "\n",
      "Loss evaluation at time 228:\t108.8702\n",
      "\n",
      "Loss evaluation at time 229:\t107.2691\n",
      "\n",
      "Loss evaluation at time 230:\t105.6995\n",
      "\n",
      "Loss evaluation at time 231:\t104.1608\n",
      "\n",
      "Loss evaluation at time 232:\t102.6521\n",
      "\n",
      "Loss evaluation at time 233:\t101.1727\n",
      "\n",
      "Loss evaluation at time 234:\t99.7219\n",
      "\n",
      "Loss evaluation at time 235:\t49.3686\n",
      "\n",
      "Loss evaluation at time 236:\t98.4830\n",
      "\n",
      "Loss evaluation at time 237:\t97.0885\n",
      "\n",
      "Loss evaluation at time 238:\t49.7789\n",
      "\n",
      "Loss evaluation at time 239:\t49.3572\n",
      "\n",
      "Loss evaluation at time 240:\t48.9387\n",
      "\n",
      "Loss evaluation at time 241:\t48.5234\n",
      "\n",
      "Loss evaluation at time 242:\t48.1113\n",
      "\n",
      "Loss evaluation at time 243:\t47.7023\n",
      "\n",
      "Loss evaluation at time 244:\t47.2966\n",
      "\n",
      "Loss evaluation at time 245:\t46.8941\n",
      "\n",
      "Loss evaluation at time 246:\t46.4948\n",
      "\n",
      "Loss evaluation at time 247:\t46.0988\n",
      "\n",
      "Loss evaluation at time 248:\t45.7061\n",
      "\n",
      "Loss evaluation at time 249:\t45.3166\n",
      "\n",
      "Loss evaluation at time 250:\t44.9303\n",
      "\n",
      "Loss evaluation at time 251:\t44.5474\n",
      "\n",
      "Loss evaluation at time 252:\t44.1677\n",
      "\n",
      "Loss evaluation at time 253:\t43.7912\n",
      "\n",
      "Loss evaluation at time 254:\t43.4180\n",
      "\n",
      "Loss evaluation at time 255:\t43.0481\n",
      "\n",
      "Loss evaluation at time 256:\t42.6814\n",
      "\n",
      "Loss evaluation at time 257:\t42.3179\n",
      "\n",
      "Loss evaluation at time 258:\t41.9577\n",
      "\n",
      "Loss evaluation at time 259:\t41.6007\n",
      "\n",
      "Loss evaluation at time 260:\t41.2469\n",
      "\n",
      "Loss evaluation at time 261:\t40.8963\n",
      "\n",
      "Loss evaluation at time 262:\t40.5489\n",
      "\n",
      "Loss evaluation at time 263:\t40.2046\n",
      "\n",
      "Loss evaluation at time 264:\t39.8635\n",
      "\n",
      "Loss evaluation at time 265:\t39.5255\n",
      "\n",
      "Loss evaluation at time 266:\t39.1907\n",
      "\n",
      "Loss evaluation at time 267:\t38.8589\n",
      "\n",
      "Loss evaluation at time 268:\t38.5302\n",
      "\n",
      "Loss evaluation at time 269:\t38.2046\n",
      "\n",
      "Loss evaluation at time 270:\t37.8820\n",
      "\n",
      "Loss evaluation at time 271:\t37.5625\n",
      "\n",
      "Loss evaluation at time 272:\t37.2459\n",
      "\n",
      "Loss evaluation at time 273:\t36.9324\n",
      "\n",
      "Loss evaluation at time 274:\t36.6218\n",
      "\n",
      "Loss evaluation at time 275:\t36.3142\n",
      "\n",
      "Loss evaluation at time 276:\t36.0094\n",
      "\n",
      "Loss evaluation at time 277:\t35.7076\n",
      "\n",
      "Loss evaluation at time 278:\t35.4087\n",
      "\n",
      "Loss evaluation at time 279:\t35.1126\n",
      "\n",
      "Loss evaluation at time 280:\t34.8193\n",
      "\n",
      "Loss evaluation at time 281:\t34.5289\n",
      "\n",
      "Loss evaluation at time 282:\t34.2412\n",
      "\n",
      "Loss evaluation at time 283:\t33.9563\n",
      "\n",
      "Loss evaluation at time 284:\t33.6742\n",
      "\n",
      "Loss evaluation at time 285:\t99.8750\n",
      "\n",
      "Loss evaluation at time 286:\t98.6439\n",
      "\n",
      "Loss evaluation at time 287:\t97.4331\n",
      "\n",
      "Loss evaluation at time 288:\t96.2421\n",
      "\n",
      "Loss evaluation at time 289:\t95.0706\n",
      "\n",
      "Loss evaluation at time 290:\t93.9182\n",
      "\n",
      "Loss evaluation at time 291:\t92.7844\n",
      "\n",
      "Loss evaluation at time 292:\t91.6689\n",
      "\n",
      "Loss evaluation at time 293:\t90.5713\n",
      "\n",
      "Loss evaluation at time 294:\t89.4913\n",
      "\n",
      "Loss evaluation at time 295:\t88.4285\n",
      "\n",
      "Loss evaluation at time 296:\t87.3826\n",
      "\n",
      "Loss evaluation at time 297:\t86.3532\n",
      "\n",
      "Loss evaluation at time 298:\t85.3400\n",
      "\n",
      "Loss evaluation at time 299:\t84.3428\n",
      "\n",
      "Loss evaluation at time 300:\t83.3611\n",
      "\n",
      "Loss evaluation at time 301:\t82.3947\n",
      "\n",
      "Loss evaluation at time 302:\t81.4434\n",
      "\n",
      "Loss evaluation at time 303:\t80.5067\n",
      "\n",
      "Loss evaluation at time 304:\t79.5844\n",
      "\n",
      "Loss evaluation at time 305:\t78.6763\n",
      "\n",
      "Loss evaluation at time 306:\t77.7820\n",
      "\n",
      "Loss evaluation at time 307:\t76.9014\n",
      "\n",
      "Loss evaluation at time 308:\t76.0341\n",
      "\n",
      "Loss evaluation at time 309:\t75.1799\n",
      "\n",
      "Loss evaluation at time 310:\t74.3385\n",
      "\n",
      "Loss evaluation at time 311:\t73.5098\n",
      "\n",
      "Loss evaluation at time 312:\t72.6934\n",
      "\n",
      "Loss evaluation at time 313:\t71.8892\n",
      "\n",
      "Loss evaluation at time 314:\t71.0969\n",
      "\n",
      "Loss evaluation at time 315:\t70.3163\n",
      "\n",
      "Loss evaluation at time 316:\t69.5472\n",
      "\n",
      "Loss evaluation at time 317:\t68.7893\n",
      "\n",
      "Loss evaluation at time 318:\t68.0426\n",
      "\n",
      "Loss evaluation at time 319:\t43.5524\n",
      "\n",
      "Loss evaluation at time 320:\t43.2486\n",
      "\n",
      "Loss evaluation at time 321:\t42.9471\n",
      "\n",
      "Loss evaluation at time 322:\t42.6479\n",
      "\n",
      "Loss evaluation at time 323:\t42.3509\n",
      "\n",
      "Loss evaluation at time 324:\t42.0562\n",
      "\n",
      "Loss evaluation at time 325:\t41.7637\n",
      "\n",
      "Loss evaluation at time 326:\t41.4733\n",
      "\n",
      "Loss evaluation at time 327:\t41.1852\n",
      "\n",
      "Loss evaluation at time 328:\t40.8993\n",
      "\n",
      "Loss evaluation at time 329:\t40.6156\n",
      "\n",
      "Loss evaluation at time 330:\t40.3341\n",
      "\n",
      "Loss evaluation at time 331:\t40.0547\n",
      "\n",
      "Loss evaluation at time 332:\t39.7775\n",
      "\n",
      "Loss evaluation at time 333:\t39.5024\n",
      "\n",
      "Loss evaluation at time 334:\t39.2294\n",
      "\n",
      "Loss evaluation at time 335:\t69.5395\n",
      "\n",
      "Loss evaluation at time 336:\t68.8159\n",
      "\n",
      "Loss evaluation at time 337:\t68.1023\n",
      "\n",
      "Loss evaluation at time 338:\t67.3986\n",
      "\n",
      "Loss evaluation at time 339:\t66.7047\n",
      "\n",
      "Loss evaluation at time 340:\t39.9059\n",
      "\n",
      "Loss evaluation at time 341:\t39.6370\n",
      "\n",
      "Loss evaluation at time 342:\t39.3701\n",
      "\n",
      "Loss evaluation at time 343:\t39.1053\n",
      "\n",
      "Loss evaluation at time 344:\t38.8424\n",
      "\n",
      "Loss evaluation at time 345:\t66.6387\n",
      "\n",
      "Loss evaluation at time 346:\t65.9646\n",
      "\n",
      "Loss evaluation at time 347:\t38.9390\n",
      "\n",
      "Loss evaluation at time 348:\t38.6801\n",
      "\n",
      "Loss evaluation at time 349:\t38.4231\n",
      "\n",
      "Loss evaluation at time 350:\t38.1680\n",
      "\n",
      "Loss evaluation at time 351:\t37.9148\n",
      "\n",
      "Loss evaluation at time 352:\t37.6636\n",
      "\n",
      "Loss evaluation at time 353:\t37.4142\n",
      "\n",
      "Loss evaluation at time 354:\t37.1668\n",
      "\n",
      "Loss evaluation at time 355:\t36.9211\n",
      "\n",
      "Loss evaluation at time 356:\t36.6774\n",
      "\n",
      "Loss evaluation at time 357:\t36.4355\n",
      "\n",
      "Loss evaluation at time 358:\t36.1954\n",
      "\n",
      "Loss evaluation at time 359:\t35.9571\n",
      "\n",
      "Loss evaluation at time 360:\t35.7207\n",
      "\n",
      "Loss evaluation at time 361:\t35.4861\n",
      "\n",
      "Loss evaluation at time 362:\t35.2532\n",
      "\n",
      "Loss evaluation at time 363:\t35.0221\n",
      "\n",
      "Loss evaluation at time 364:\t34.7928\n",
      "\n",
      "Loss evaluation at time 365:\t34.5652\n",
      "\n",
      "Loss evaluation at time 366:\t67.2052\n",
      "\n",
      "Loss evaluation at time 367:\t34.5310\n",
      "\n",
      "Loss evaluation at time 368:\t34.3067\n",
      "\n",
      "Loss evaluation at time 369:\t34.0840\n",
      "\n",
      "Loss evaluation at time 370:\t33.8630\n",
      "\n",
      "Loss evaluation at time 371:\t33.6437\n",
      "\n",
      "Loss evaluation at time 372:\t33.4261\n",
      "\n",
      "Loss evaluation at time 373:\t33.2101\n",
      "\n",
      "Loss evaluation at time 374:\t67.0874\n",
      "\n",
      "Loss evaluation at time 375:\t66.4512\n",
      "\n",
      "Loss evaluation at time 376:\t65.8230\n",
      "\n",
      "Loss evaluation at time 377:\t65.2028\n",
      "\n",
      "Loss evaluation at time 378:\t64.5904\n",
      "\n",
      "Loss evaluation at time 379:\t63.9857\n",
      "\n",
      "Loss evaluation at time 380:\t63.3886\n",
      "\n",
      "Loss evaluation at time 381:\t62.7989\n",
      "\n",
      "Loss evaluation at time 382:\t62.2165\n",
      "\n",
      "Loss evaluation at time 383:\t34.5814\n",
      "\n",
      "Loss evaluation at time 384:\t34.3668\n",
      "\n",
      "Loss evaluation at time 385:\t34.1538\n",
      "\n",
      "Loss evaluation at time 386:\t33.9423\n",
      "\n",
      "Loss evaluation at time 387:\t33.7324\n",
      "\n",
      "Loss evaluation at time 388:\t33.5240\n",
      "\n",
      "Loss evaluation at time 389:\t62.1473\n",
      "\n",
      "Loss evaluation at time 390:\t61.5814\n",
      "\n",
      "Loss evaluation at time 391:\t61.0223\n",
      "\n",
      "Loss evaluation at time 392:\t60.4700\n",
      "\n",
      "Loss evaluation at time 393:\t33.9419\n",
      "\n",
      "Loss evaluation at time 394:\t33.7360\n",
      "\n",
      "Loss evaluation at time 395:\t33.5316\n",
      "\n",
      "Loss evaluation at time 396:\t33.3287\n",
      "\n",
      "Loss evaluation at time 397:\t33.1272\n",
      "\n",
      "Loss evaluation at time 398:\t32.9271\n",
      "\n",
      "Loss evaluation at time 399:\t32.7284\n",
      "\n",
      "Loss evaluation at time 400:\t60.4911\n",
      "\n",
      "Loss evaluation at time 401:\t59.9544\n",
      "\n",
      "Loss evaluation at time 402:\t59.4240\n",
      "\n",
      "Loss evaluation at time 403:\t58.8998\n",
      "\n",
      "Loss evaluation at time 404:\t58.3819\n",
      "\n",
      "Loss evaluation at time 405:\t57.8700\n",
      "\n",
      "Loss evaluation at time 406:\t57.3641\n",
      "\n",
      "Loss evaluation at time 407:\t56.8642\n",
      "\n",
      "Loss evaluation at time 408:\t56.3701\n",
      "\n",
      "Loss evaluation at time 409:\t55.8817\n",
      "\n",
      "Loss evaluation at time 410:\t55.3990\n",
      "\n",
      "Loss evaluation at time 411:\t54.9219\n",
      "\n",
      "Loss evaluation at time 412:\t54.4502\n",
      "\n",
      "Loss evaluation at time 413:\t53.9840\n",
      "\n",
      "Loss evaluation at time 414:\t53.5231\n",
      "\n",
      "Loss evaluation at time 415:\t53.0675\n",
      "\n",
      "Loss evaluation at time 416:\t52.6171\n",
      "\n",
      "Loss evaluation at time 417:\t52.1718\n",
      "\n",
      "Loss evaluation at time 418:\t51.7315\n",
      "\n",
      "Loss evaluation at time 419:\t51.2963\n",
      "\n",
      "Loss evaluation at time 420:\t50.8659\n",
      "\n",
      "Loss evaluation at time 421:\t50.4404\n",
      "\n",
      "Loss evaluation at time 422:\t50.0196\n",
      "\n",
      "Loss evaluation at time 423:\t49.6035\n",
      "\n",
      "Loss evaluation at time 424:\t49.1921\n",
      "\n",
      "Loss evaluation at time 425:\t48.7852\n",
      "\n",
      "Loss evaluation at time 426:\t35.5592\n",
      "\n",
      "Loss evaluation at time 427:\t48.4931\n",
      "\n",
      "Loss evaluation at time 428:\t48.0949\n",
      "\n",
      "Loss evaluation at time 429:\t47.7012\n",
      "\n",
      "Loss evaluation at time 430:\t35.6106\n",
      "\n",
      "Loss evaluation at time 431:\t35.4193\n",
      "\n",
      "Loss evaluation at time 432:\t35.2291\n",
      "\n",
      "Loss evaluation at time 433:\t35.0401\n",
      "\n",
      "Loss evaluation at time 434:\t34.8522\n",
      "\n",
      "Loss evaluation at time 435:\t47.8537\n",
      "\n",
      "Loss evaluation at time 436:\t47.4673\n",
      "\n",
      "Loss evaluation at time 437:\t47.0852\n",
      "\n",
      "Loss evaluation at time 438:\t46.7072\n",
      "\n",
      "Loss evaluation at time 439:\t46.3332\n",
      "\n",
      "Loss evaluation at time 440:\t45.9632\n",
      "\n",
      "Loss evaluation at time 441:\t45.5972\n",
      "\n",
      "Loss evaluation at time 442:\t45.2351\n",
      "\n",
      "Loss evaluation at time 443:\t44.8769\n",
      "\n",
      "Loss evaluation at time 444:\t44.5225\n",
      "\n",
      "Loss evaluation at time 445:\t44.1718\n",
      "\n",
      "Loss evaluation at time 446:\t43.8248\n",
      "\n",
      "Loss evaluation at time 447:\t43.4815\n",
      "\n",
      "Loss evaluation at time 448:\t43.1417\n",
      "\n",
      "Loss evaluation at time 449:\t42.8056\n",
      "\n",
      "Loss evaluation at time 450:\t42.4729\n",
      "\n",
      "Loss evaluation at time 451:\t42.1437\n",
      "\n",
      "Loss evaluation at time 452:\t41.8180\n",
      "\n",
      "Loss evaluation at time 453:\t41.4956\n",
      "\n",
      "Loss evaluation at time 454:\t41.1765\n",
      "\n",
      "Loss evaluation at time 455:\t40.8608\n",
      "\n",
      "Loss evaluation at time 456:\t40.5483\n",
      "\n",
      "Loss evaluation at time 457:\t40.2389\n",
      "\n",
      "Loss evaluation at time 458:\t39.9328\n",
      "\n",
      "Loss evaluation at time 459:\t39.6298\n",
      "\n",
      "Loss evaluation at time 460:\t39.3298\n",
      "\n",
      "Loss evaluation at time 461:\t39.0330\n",
      "\n",
      "Loss evaluation at time 462:\t36.2618\n",
      "\n",
      "Loss evaluation at time 463:\t38.8603\n",
      "\n",
      "Loss evaluation at time 464:\t38.5689\n",
      "\n",
      "Loss evaluation at time 465:\t36.1623\n",
      "\n",
      "Loss evaluation at time 466:\t35.9880\n",
      "\n",
      "Loss evaluation at time 467:\t35.8146\n",
      "\n",
      "Loss evaluation at time 468:\t35.6421\n",
      "\n",
      "Loss evaluation at time 469:\t35.4705\n",
      "\n",
      "Loss evaluation at time 470:\t35.2997\n",
      "\n",
      "Loss evaluation at time 471:\t35.1299\n",
      "\n",
      "Loss evaluation at time 472:\t34.9609\n",
      "\n",
      "Loss evaluation at time 473:\t34.7928\n",
      "\n",
      "Loss evaluation at time 474:\t34.6256\n",
      "\n",
      "Loss evaluation at time 475:\t34.4593\n",
      "\n",
      "Loss evaluation at time 476:\t34.2938\n",
      "\n",
      "Loss evaluation at time 477:\t34.1292\n",
      "\n",
      "Loss evaluation at time 478:\t33.9655\n",
      "\n",
      "Loss evaluation at time 479:\t33.8026\n",
      "\n",
      "Loss evaluation at time 480:\t33.6406\n",
      "\n",
      "Loss evaluation at time 481:\t33.4795\n",
      "\n",
      "Loss evaluation at time 482:\t33.3192\n",
      "\n",
      "Loss evaluation at time 483:\t33.1598\n",
      "\n",
      "Loss evaluation at time 484:\t33.0012\n",
      "\n",
      "Loss evaluation at time 485:\t32.8435\n",
      "\n",
      "Loss evaluation at time 486:\t32.6866\n",
      "\n",
      "Loss evaluation at time 487:\t32.5305\n",
      "\n",
      "Loss evaluation at time 488:\t32.3753\n",
      "\n",
      "Loss evaluation at time 489:\t32.2209\n",
      "\n",
      "Loss evaluation at time 490:\t32.0673\n",
      "\n",
      "Loss evaluation at time 491:\t31.9146\n",
      "\n",
      "Loss evaluation at time 492:\t31.7627\n",
      "\n",
      "Loss evaluation at time 493:\t31.6116\n",
      "\n",
      "Loss evaluation at time 494:\t31.4613\n",
      "\n",
      "Loss evaluation at time 495:\t31.3119\n",
      "\n",
      "Loss evaluation at time 496:\t31.1632\n",
      "\n",
      "Loss evaluation at time 497:\t31.0154\n",
      "\n",
      "Loss evaluation at time 498:\t30.8683\n",
      "\n",
      "Loss evaluation at time 499:\t30.7221\n",
      "\n",
      "Loss evaluation at time 500:\t30.5766\n",
      "\n",
      "Loss evaluation at time 501:\t30.4319\n",
      "\n",
      "Loss evaluation at time 502:\t30.2881\n",
      "\n",
      "Loss evaluation at time 503:\t30.1450\n",
      "\n",
      "Loss evaluation at time 504:\t30.0026\n",
      "\n",
      "Loss evaluation at time 505:\t29.8611\n",
      "\n",
      "Loss evaluation at time 506:\t29.7203\n",
      "\n",
      "Loss evaluation at time 507:\t29.5803\n",
      "\n",
      "Loss evaluation at time 508:\t29.4411\n",
      "\n",
      "Loss evaluation at time 509:\t29.3026\n",
      "\n",
      "Loss evaluation at time 510:\t29.1649\n",
      "\n",
      "Loss evaluation at time 511:\t29.0280\n",
      "\n",
      "Loss evaluation at time 512:\t28.8918\n",
      "\n",
      "Loss evaluation at time 513:\t28.7563\n",
      "\n",
      "Loss evaluation at time 514:\t28.6216\n",
      "\n",
      "Loss evaluation at time 515:\t28.4876\n",
      "\n",
      "Loss evaluation at time 516:\t28.3543\n",
      "\n",
      "Loss evaluation at time 517:\t28.2218\n",
      "\n",
      "Loss evaluation at time 518:\t28.0901\n",
      "\n",
      "Loss evaluation at time 519:\t27.9590\n",
      "\n",
      "Loss evaluation at time 520:\t27.8287\n",
      "\n",
      "Loss evaluation at time 521:\t27.6990\n",
      "\n",
      "Loss evaluation at time 522:\t27.5701\n",
      "\n",
      "Loss evaluation at time 523:\t27.4419\n",
      "\n",
      "Loss evaluation at time 524:\t27.3144\n",
      "\n",
      "Loss evaluation at time 525:\t27.1876\n",
      "\n",
      "Loss evaluation at time 526:\t27.0615\n",
      "\n",
      "Loss evaluation at time 527:\t26.9361\n",
      "\n",
      "Loss evaluation at time 528:\t26.8114\n",
      "\n",
      "Loss evaluation at time 529:\t26.6874\n",
      "\n",
      "Loss evaluation at time 530:\t26.5641\n",
      "\n",
      "Loss evaluation at time 531:\t26.4414\n",
      "\n",
      "Loss evaluation at time 532:\t26.3194\n",
      "\n",
      "Loss evaluation at time 533:\t43.9499\n",
      "\n",
      "Loss evaluation at time 534:\t26.2758\n",
      "\n",
      "Loss evaluation at time 535:\t43.7060\n",
      "\n",
      "Loss evaluation at time 536:\t43.4125\n",
      "\n",
      "Loss evaluation at time 537:\t43.1216\n",
      "\n",
      "Loss evaluation at time 538:\t42.8334\n",
      "\n",
      "Loss evaluation at time 539:\t42.5477\n",
      "\n",
      "Loss evaluation at time 540:\t42.2646\n",
      "\n",
      "Loss evaluation at time 541:\t41.9839\n",
      "\n",
      "Loss evaluation at time 542:\t41.7058\n",
      "\n",
      "Loss evaluation at time 543:\t41.4301\n",
      "\n",
      "Loss evaluation at time 544:\t41.1569\n",
      "\n",
      "Loss evaluation at time 545:\t40.8861\n",
      "\n",
      "Loss evaluation at time 546:\t40.6177\n",
      "\n",
      "Loss evaluation at time 547:\t40.3516\n",
      "\n",
      "Loss evaluation at time 548:\t40.0878\n",
      "\n",
      "Loss evaluation at time 549:\t39.8264\n",
      "\n",
      "Loss evaluation at time 550:\t39.5672\n",
      "\n",
      "Loss evaluation at time 551:\t39.3103\n",
      "\n",
      "Loss evaluation at time 552:\t27.2880\n",
      "\n",
      "Loss evaluation at time 553:\t27.1691\n",
      "\n",
      "Loss evaluation at time 554:\t27.0508\n",
      "\n",
      "Loss evaluation at time 555:\t26.9331\n",
      "\n",
      "Loss evaluation at time 556:\t26.8160\n",
      "\n",
      "Loss evaluation at time 557:\t26.6995\n",
      "\n",
      "Loss evaluation at time 558:\t26.5836\n",
      "\n",
      "Loss evaluation at time 559:\t26.4683\n",
      "\n",
      "Loss evaluation at time 560:\t26.3536\n",
      "\n",
      "Loss evaluation at time 561:\t26.2394\n",
      "\n",
      "Loss evaluation at time 562:\t26.1259\n",
      "\n",
      "Loss evaluation at time 563:\t26.0129\n",
      "\n",
      "Loss evaluation at time 564:\t25.9005\n",
      "\n",
      "Loss evaluation at time 565:\t25.7887\n",
      "\n",
      "Loss evaluation at time 566:\t25.6775\n",
      "\n",
      "Loss evaluation at time 567:\t25.5668\n",
      "\n",
      "Loss evaluation at time 568:\t25.4567\n",
      "\n",
      "Loss evaluation at time 569:\t25.3472\n",
      "\n",
      "Loss evaluation at time 570:\t25.2382\n",
      "\n",
      "Loss evaluation at time 571:\t25.1298\n",
      "\n",
      "Loss evaluation at time 572:\t40.1657\n",
      "\n",
      "Loss evaluation at time 573:\t39.9132\n",
      "\n",
      "Loss evaluation at time 574:\t39.6628\n",
      "\n",
      "Loss evaluation at time 575:\t39.4145\n",
      "\n",
      "Loss evaluation at time 576:\t39.1683\n",
      "\n",
      "Loss evaluation at time 577:\t38.9241\n",
      "\n",
      "Loss evaluation at time 578:\t38.6820\n",
      "\n",
      "Loss evaluation at time 579:\t38.4419\n",
      "\n",
      "Loss evaluation at time 580:\t38.2037\n",
      "\n",
      "Loss evaluation at time 581:\t37.9676\n",
      "\n",
      "Loss evaluation at time 582:\t37.7334\n",
      "\n",
      "Loss evaluation at time 583:\t37.5011\n",
      "\n",
      "Loss evaluation at time 584:\t37.2708\n",
      "\n",
      "Loss evaluation at time 585:\t37.0423\n",
      "\n",
      "Loss evaluation at time 586:\t36.8157\n",
      "\n",
      "Loss evaluation at time 587:\t36.5910\n",
      "\n",
      "Loss evaluation at time 588:\t36.3681\n",
      "\n",
      "Loss evaluation at time 589:\t36.1470\n",
      "\n",
      "Loss evaluation at time 590:\t35.9277\n",
      "\n",
      "Loss evaluation at time 591:\t35.7102\n",
      "\n",
      "Loss evaluation at time 592:\t35.4945\n",
      "\n",
      "Loss evaluation at time 593:\t35.2805\n",
      "\n",
      "Loss evaluation at time 594:\t35.0682\n",
      "\n",
      "Loss evaluation at time 595:\t34.8577\n",
      "\n",
      "Loss evaluation at time 596:\t26.2777\n",
      "\n",
      "Loss evaluation at time 597:\t34.7082\n",
      "\n",
      "Loss evaluation at time 598:\t34.5010\n",
      "\n",
      "Loss evaluation at time 599:\t34.2953\n",
      "\n",
      "Loss evaluation at time 600:\t34.0914\n",
      "\n",
      "Loss evaluation at time 601:\t33.8890\n",
      "\n",
      "Loss evaluation at time 602:\t33.6882\n",
      "\n",
      "Loss evaluation at time 603:\t33.4891\n",
      "\n",
      "Loss evaluation at time 604:\t33.2915\n",
      "\n",
      "Loss evaluation at time 605:\t33.0955\n",
      "\n",
      "Loss evaluation at time 606:\t32.9010\n",
      "\n",
      "Loss evaluation at time 607:\t32.7081\n",
      "\n",
      "Loss evaluation at time 608:\t32.5167\n",
      "\n",
      "Loss evaluation at time 609:\t32.3267\n",
      "\n",
      "Loss evaluation at time 610:\t32.1383\n",
      "\n",
      "Loss evaluation at time 611:\t31.9513\n",
      "\n",
      "Loss evaluation at time 612:\t31.7658\n",
      "\n",
      "Loss evaluation at time 613:\t31.5817\n",
      "\n",
      "Loss evaluation at time 614:\t31.3991\n",
      "\n",
      "Loss evaluation at time 615:\t31.2179\n",
      "\n",
      "Loss evaluation at time 616:\t31.0381\n",
      "\n",
      "Loss evaluation at time 617:\t30.8596\n",
      "\n",
      "Loss evaluation at time 618:\t30.6826\n",
      "\n",
      "Loss evaluation at time 619:\t30.5069\n",
      "\n",
      "Loss evaluation at time 620:\t30.3325\n",
      "\n",
      "Loss evaluation at time 621:\t30.1595\n",
      "\n",
      "Loss evaluation at time 622:\t29.9878\n",
      "\n",
      "Loss evaluation at time 623:\t29.8174\n",
      "\n",
      "Loss evaluation at time 624:\t29.6484\n",
      "\n",
      "Loss evaluation at time 625:\t29.4806\n",
      "\n",
      "Loss evaluation at time 626:\t29.3140\n",
      "\n",
      "Loss evaluation at time 627:\t29.1488\n",
      "\n",
      "Loss evaluation at time 628:\t28.9848\n",
      "\n",
      "Loss evaluation at time 629:\t28.8220\n",
      "\n",
      "Loss evaluation at time 630:\t28.6604\n",
      "\n",
      "Loss evaluation at time 631:\t28.5001\n",
      "\n",
      "Loss evaluation at time 632:\t28.3410\n",
      "\n",
      "Loss evaluation at time 633:\t28.1830\n",
      "\n",
      "Loss evaluation at time 634:\t28.0263\n",
      "\n",
      "Loss evaluation at time 635:\t27.8707\n",
      "\n",
      "Loss evaluation at time 636:\t27.7163\n",
      "\n",
      "Loss evaluation at time 637:\t27.5630\n",
      "\n",
      "Loss evaluation at time 638:\t27.4108\n",
      "\n",
      "Loss evaluation at time 639:\t27.2598\n",
      "\n",
      "Loss evaluation at time 640:\t27.1099\n",
      "\n",
      "Loss evaluation at time 641:\t26.9611\n",
      "\n",
      "Loss evaluation at time 642:\t27.3889\n",
      "\n",
      "Loss evaluation at time 643:\t27.2915\n",
      "\n",
      "Loss evaluation at time 644:\t27.1945\n",
      "\n",
      "Loss evaluation at time 645:\t27.0979\n",
      "\n",
      "Loss evaluation at time 646:\t27.0016\n",
      "\n",
      "Loss evaluation at time 647:\t26.9058\n",
      "\n",
      "Loss evaluation at time 648:\t26.8103\n",
      "\n",
      "Loss evaluation at time 649:\t26.7152\n",
      "\n",
      "Loss evaluation at time 650:\t26.6204\n",
      "\n",
      "Loss evaluation at time 651:\t26.5260\n",
      "\n",
      "Loss evaluation at time 652:\t26.4320\n",
      "\n",
      "Loss evaluation at time 653:\t26.3384\n",
      "\n",
      "Loss evaluation at time 654:\t26.2451\n",
      "\n",
      "Loss evaluation at time 655:\t26.1522\n",
      "\n",
      "Loss evaluation at time 656:\t27.7292\n",
      "\n",
      "Loss evaluation at time 657:\t27.5799\n",
      "\n",
      "Loss evaluation at time 658:\t27.4317\n",
      "\n",
      "Loss evaluation at time 659:\t27.2846\n",
      "\n",
      "Loss evaluation at time 660:\t27.1385\n",
      "\n",
      "Loss evaluation at time 661:\t26.9934\n",
      "\n",
      "Loss evaluation at time 662:\t26.8494\n",
      "\n",
      "Loss evaluation at time 663:\t26.7064\n",
      "\n",
      "Loss evaluation at time 664:\t26.5645\n",
      "\n",
      "Loss evaluation at time 665:\t26.4235\n",
      "\n",
      "Loss evaluation at time 666:\t26.2836\n",
      "\n",
      "Loss evaluation at time 667:\t26.1446\n",
      "\n",
      "Loss evaluation at time 668:\t26.0067\n",
      "\n",
      "Loss evaluation at time 669:\t25.8697\n",
      "\n",
      "Loss evaluation at time 670:\t25.7337\n",
      "\n",
      "Loss evaluation at time 671:\t25.5986\n",
      "\n",
      "Loss evaluation at time 672:\t25.4645\n",
      "\n",
      "Loss evaluation at time 673:\t25.3314\n",
      "\n",
      "Loss evaluation at time 674:\t25.1991\n",
      "\n",
      "Loss evaluation at time 675:\t25.0678\n",
      "\n",
      "Loss evaluation at time 676:\t24.9375\n",
      "\n",
      "Loss evaluation at time 677:\t24.8080\n",
      "\n",
      "Loss evaluation at time 678:\t24.6794\n",
      "\n",
      "Loss evaluation at time 679:\t24.5517\n",
      "\n",
      "Loss evaluation at time 680:\t24.4250\n",
      "\n",
      "Loss evaluation at time 681:\t24.2990\n",
      "\n",
      "Loss evaluation at time 682:\t24.1740\n",
      "\n",
      "Loss evaluation at time 683:\t24.0498\n",
      "\n",
      "Loss evaluation at time 684:\t23.9265\n",
      "\n",
      "Loss evaluation at time 685:\t23.8040\n",
      "\n",
      "Loss evaluation at time 686:\t23.6824\n",
      "\n",
      "Loss evaluation at time 687:\t23.5616\n",
      "\n",
      "Loss evaluation at time 688:\t23.4417\n",
      "\n",
      "Loss evaluation at time 689:\t23.3225\n",
      "\n",
      "Loss evaluation at time 690:\t23.2042\n",
      "\n",
      "Loss evaluation at time 691:\t23.0867\n",
      "\n",
      "Loss evaluation at time 692:\t22.9699\n",
      "\n",
      "Loss evaluation at time 693:\t22.8540\n",
      "\n",
      "Loss evaluation at time 694:\t22.7389\n",
      "\n",
      "Loss evaluation at time 695:\t22.6245\n",
      "\n",
      "Loss evaluation at time 696:\t22.5109\n",
      "\n",
      "Loss evaluation at time 697:\t22.3981\n",
      "\n",
      "Loss evaluation at time 698:\t22.2860\n",
      "\n",
      "Loss evaluation at time 699:\t22.1747\n",
      "\n",
      "Loss evaluation at time 700:\t22.0641\n",
      "\n",
      "Loss evaluation at time 701:\t21.9543\n",
      "\n",
      "Loss evaluation at time 702:\t21.8452\n",
      "\n",
      "Loss evaluation at time 703:\t21.7368\n",
      "\n",
      "Loss evaluation at time 704:\t21.6292\n",
      "\n",
      "Loss evaluation at time 705:\t21.5222\n",
      "\n",
      "Loss evaluation at time 706:\t21.4160\n",
      "\n",
      "Loss evaluation at time 707:\t21.3105\n",
      "\n",
      "Loss evaluation at time 708:\t21.2057\n",
      "\n",
      "Loss evaluation at time 709:\t21.1016\n",
      "\n",
      "Loss evaluation at time 710:\t20.9981\n",
      "\n",
      "Loss evaluation at time 711:\t20.8954\n",
      "\n",
      "Loss evaluation at time 712:\t20.7933\n",
      "\n",
      "Loss evaluation at time 713:\t20.6919\n",
      "\n",
      "Loss evaluation at time 714:\t20.5912\n",
      "\n",
      "Loss evaluation at time 715:\t20.4911\n",
      "\n",
      "Loss evaluation at time 716:\t20.3916\n",
      "\n",
      "Loss evaluation at time 717:\t20.2929\n",
      "\n",
      "Loss evaluation at time 718:\t20.1947\n",
      "\n",
      "Loss evaluation at time 719:\t20.0972\n",
      "\n",
      "Loss evaluation at time 720:\t20.0004\n",
      "\n",
      "Loss evaluation at time 721:\t19.9041\n",
      "\n",
      "Loss evaluation at time 722:\t19.8085\n",
      "\n",
      "Loss evaluation at time 723:\t19.7135\n",
      "\n",
      "Loss evaluation at time 724:\t19.6191\n",
      "\n",
      "Loss evaluation at time 725:\t19.5253\n",
      "\n",
      "Loss evaluation at time 726:\t19.4322\n",
      "\n",
      "Loss evaluation at time 727:\t19.3396\n",
      "\n",
      "Loss evaluation at time 728:\t19.2476\n",
      "\n",
      "Loss evaluation at time 729:\t19.1562\n",
      "\n",
      "Loss evaluation at time 730:\t19.0654\n",
      "\n",
      "Loss evaluation at time 731:\t18.9751\n",
      "\n",
      "Loss evaluation at time 732:\t18.8855\n",
      "\n",
      "Loss evaluation at time 733:\t18.7964\n",
      "\n",
      "Loss evaluation at time 734:\t18.7079\n",
      "\n",
      "Loss evaluation at time 735:\t18.6199\n",
      "\n",
      "Loss evaluation at time 736:\t18.5325\n",
      "\n",
      "Loss evaluation at time 737:\t18.4456\n",
      "\n",
      "Loss evaluation at time 738:\t18.3593\n",
      "\n",
      "Loss evaluation at time 739:\t18.2736\n",
      "\n",
      "Loss evaluation at time 740:\t18.1883\n",
      "\n",
      "Loss evaluation at time 741:\t18.1036\n",
      "\n",
      "Loss evaluation at time 742:\t18.0195\n",
      "\n",
      "Loss evaluation at time 743:\t17.9359\n",
      "\n",
      "Loss evaluation at time 744:\t17.8527\n",
      "\n",
      "Loss evaluation at time 745:\t17.7701\n",
      "\n",
      "Loss evaluation at time 746:\t17.6881\n",
      "\n",
      "Loss evaluation at time 747:\t17.6065\n",
      "\n",
      "Loss evaluation at time 748:\t17.5254\n",
      "\n",
      "Loss evaluation at time 749:\t17.4449\n",
      "\n",
      "Loss evaluation at time 750:\t17.3648\n",
      "\n",
      "Loss evaluation at time 751:\t17.2852\n",
      "\n",
      "Loss evaluation at time 752:\t17.2061\n",
      "\n",
      "Loss evaluation at time 753:\t17.1276\n",
      "\n",
      "Loss evaluation at time 754:\t17.0494\n",
      "\n",
      "Loss evaluation at time 755:\t16.9718\n",
      "\n",
      "Loss evaluation at time 756:\t16.8947\n",
      "\n",
      "Loss evaluation at time 757:\t16.8180\n",
      "\n",
      "Loss evaluation at time 758:\t16.7418\n",
      "\n",
      "Loss evaluation at time 759:\t16.6660\n",
      "\n",
      "Loss evaluation at time 760:\t16.5907\n",
      "\n",
      "Loss evaluation at time 761:\t16.5159\n",
      "\n",
      "Loss evaluation at time 762:\t16.4415\n",
      "\n",
      "Loss evaluation at time 763:\t16.3676\n",
      "\n",
      "Loss evaluation at time 764:\t16.2941\n",
      "\n",
      "Loss evaluation at time 765:\t16.2211\n",
      "\n",
      "Loss evaluation at time 766:\t16.1485\n",
      "\n",
      "Loss evaluation at time 767:\t16.0763\n",
      "\n",
      "Loss evaluation at time 768:\t16.0046\n",
      "\n",
      "Loss evaluation at time 769:\t15.9333\n",
      "\n",
      "Loss evaluation at time 770:\t15.8625\n",
      "\n",
      "Loss evaluation at time 771:\t15.7920\n",
      "\n",
      "Loss evaluation at time 772:\t15.7220\n",
      "\n",
      "Loss evaluation at time 773:\t26.2234\n",
      "\n",
      "Loss evaluation at time 774:\t26.1525\n",
      "\n",
      "Loss evaluation at time 775:\t26.0817\n",
      "\n",
      "Loss evaluation at time 776:\t26.0111\n",
      "\n",
      "Loss evaluation at time 777:\t25.9407\n",
      "\n",
      "Loss evaluation at time 778:\t25.8705\n",
      "\n",
      "Loss evaluation at time 779:\t25.8004\n",
      "\n",
      "Loss evaluation at time 780:\t25.7306\n",
      "\n",
      "Loss evaluation at time 781:\t25.6608\n",
      "\n",
      "Loss evaluation at time 782:\t25.5913\n",
      "\n",
      "Loss evaluation at time 783:\t25.5220\n",
      "\n",
      "Loss evaluation at time 784:\t16.3338\n",
      "\n",
      "Loss evaluation at time 785:\t16.2623\n",
      "\n",
      "Loss evaluation at time 786:\t16.1911\n",
      "\n",
      "Loss evaluation at time 787:\t16.1203\n",
      "\n",
      "Loss evaluation at time 788:\t16.0500\n",
      "\n",
      "Loss evaluation at time 789:\t15.9801\n",
      "\n",
      "Loss evaluation at time 790:\t15.9106\n",
      "\n",
      "Loss evaluation at time 791:\t15.8415\n",
      "\n",
      "Loss evaluation at time 792:\t15.7728\n",
      "\n",
      "Loss evaluation at time 793:\t15.7045\n",
      "\n",
      "Loss evaluation at time 794:\t15.6366\n",
      "\n",
      "Loss evaluation at time 795:\t15.5691\n",
      "\n",
      "Loss evaluation at time 796:\t15.5020\n",
      "\n",
      "Loss evaluation at time 797:\t15.4353\n",
      "\n",
      "Loss evaluation at time 798:\t15.3689\n",
      "\n",
      "Loss evaluation at time 799:\t15.3030\n",
      "\n",
      "Loss evaluation at time 800:\t15.2374\n",
      "\n",
      "Loss evaluation at time 801:\t15.1722\n",
      "\n",
      "Loss evaluation at time 802:\t15.1074\n",
      "\n",
      "Loss evaluation at time 803:\t15.0430\n",
      "\n",
      "Loss evaluation at time 804:\t14.9789\n",
      "\n",
      "Loss evaluation at time 805:\t14.9152\n",
      "\n",
      "Loss evaluation at time 806:\t14.8519\n",
      "\n",
      "Loss evaluation at time 807:\t14.7889\n",
      "\n",
      "Loss evaluation at time 808:\t25.2459\n",
      "\n",
      "Loss evaluation at time 809:\t25.1808\n",
      "\n",
      "Loss evaluation at time 810:\t25.1157\n",
      "\n",
      "Loss evaluation at time 811:\t25.0509\n",
      "\n",
      "Loss evaluation at time 812:\t24.9861\n",
      "\n",
      "Loss evaluation at time 813:\t24.9216\n",
      "\n",
      "Loss evaluation at time 814:\t24.8571\n",
      "\n",
      "Loss evaluation at time 815:\t24.7929\n",
      "\n",
      "Loss evaluation at time 816:\t24.7288\n",
      "\n",
      "Loss evaluation at time 817:\t15.2455\n",
      "\n",
      "Loss evaluation at time 818:\t24.6569\n",
      "\n",
      "Loss evaluation at time 819:\t15.2377\n",
      "\n",
      "Loss evaluation at time 820:\t24.5854\n",
      "\n",
      "Loss evaluation at time 821:\t24.5220\n",
      "\n",
      "Loss evaluation at time 822:\t24.4588\n",
      "\n",
      "Loss evaluation at time 823:\t24.3957\n",
      "\n",
      "Loss evaluation at time 824:\t24.3328\n",
      "\n",
      "Loss evaluation at time 825:\t24.2701\n",
      "\n",
      "Loss evaluation at time 826:\t15.5050\n",
      "\n",
      "Loss evaluation at time 827:\t15.4404\n",
      "\n",
      "Loss evaluation at time 828:\t15.3762\n",
      "\n",
      "Loss evaluation at time 829:\t15.3123\n",
      "\n",
      "Loss evaluation at time 830:\t15.2488\n",
      "\n",
      "Loss evaluation at time 831:\t15.1857\n",
      "\n",
      "Loss evaluation at time 832:\t15.1228\n",
      "\n",
      "Loss evaluation at time 833:\t15.0604\n",
      "\n",
      "Loss evaluation at time 834:\t14.9983\n",
      "\n",
      "Loss evaluation at time 835:\t14.9365\n",
      "\n",
      "Loss evaluation at time 836:\t14.8751\n",
      "\n",
      "Loss evaluation at time 837:\t14.8140\n",
      "\n",
      "Loss evaluation at time 838:\t14.7532\n",
      "\n",
      "Loss evaluation at time 839:\t14.6928\n",
      "\n",
      "Loss evaluation at time 840:\t14.6327\n",
      "\n",
      "Loss evaluation at time 841:\t14.5730\n",
      "\n",
      "Loss evaluation at time 842:\t14.5136\n",
      "\n",
      "Loss evaluation at time 843:\t14.4545\n",
      "\n",
      "Loss evaluation at time 844:\t14.3957\n",
      "\n",
      "Loss evaluation at time 845:\t14.3373\n",
      "\n",
      "Loss evaluation at time 846:\t14.2791\n",
      "\n",
      "Loss evaluation at time 847:\t14.2213\n",
      "\n",
      "Loss evaluation at time 848:\t14.1638\n",
      "\n",
      "Loss evaluation at time 849:\t14.1066\n",
      "\n",
      "Loss evaluation at time 850:\t14.0498\n",
      "\n",
      "Loss evaluation at time 851:\t13.9932\n",
      "\n",
      "Loss evaluation at time 852:\t13.9369\n",
      "\n",
      "Loss evaluation at time 853:\t13.8810\n",
      "\n",
      "Loss evaluation at time 854:\t13.8253\n",
      "\n",
      "Loss evaluation at time 855:\t13.7700\n",
      "\n",
      "Loss evaluation at time 856:\t13.7149\n",
      "\n",
      "Loss evaluation at time 857:\t13.6602\n",
      "\n",
      "Loss evaluation at time 858:\t13.6057\n",
      "\n",
      "Loss evaluation at time 859:\t13.5515\n",
      "\n",
      "Loss evaluation at time 860:\t13.4976\n",
      "\n",
      "Loss evaluation at time 861:\t13.4441\n",
      "\n",
      "Loss evaluation at time 862:\t13.3908\n",
      "\n",
      "Loss evaluation at time 863:\t13.3377\n",
      "\n",
      "Loss evaluation at time 864:\t13.2850\n",
      "\n",
      "Loss evaluation at time 865:\t13.2325\n",
      "\n",
      "Loss evaluation at time 866:\t13.1804\n",
      "\n",
      "Loss evaluation at time 867:\t13.1285\n",
      "\n",
      "Loss evaluation at time 868:\t13.0768\n",
      "\n",
      "Loss evaluation at time 869:\t13.0255\n",
      "\n",
      "Loss evaluation at time 870:\t12.9744\n",
      "\n",
      "Loss evaluation at time 871:\t12.9236\n",
      "\n",
      "Loss evaluation at time 872:\t12.8730\n",
      "\n",
      "Loss evaluation at time 873:\t12.8228\n",
      "\n",
      "Loss evaluation at time 874:\t12.7728\n",
      "\n",
      "Loss evaluation at time 875:\t12.7230\n",
      "\n",
      "Loss evaluation at time 876:\t12.6735\n",
      "\n",
      "Loss evaluation at time 877:\t12.6243\n",
      "\n",
      "Loss evaluation at time 878:\t12.5753\n",
      "\n",
      "Loss evaluation at time 879:\t12.5266\n",
      "\n",
      "Loss evaluation at time 880:\t12.4781\n",
      "\n",
      "Loss evaluation at time 881:\t12.4299\n",
      "\n",
      "Loss evaluation at time 882:\t12.3820\n",
      "\n",
      "Loss evaluation at time 883:\t12.3343\n",
      "\n",
      "Loss evaluation at time 884:\t12.2868\n",
      "\n",
      "Loss evaluation at time 885:\t12.2396\n",
      "\n",
      "Loss evaluation at time 886:\t12.1926\n",
      "\n",
      "Loss evaluation at time 887:\t12.1459\n",
      "\n",
      "Loss evaluation at time 888:\t12.0994\n",
      "\n",
      "Loss evaluation at time 889:\t12.0532\n",
      "\n",
      "Loss evaluation at time 890:\t12.0072\n",
      "\n",
      "Loss evaluation at time 891:\t11.9614\n",
      "\n",
      "Loss evaluation at time 892:\t11.9158\n",
      "\n",
      "Loss evaluation at time 893:\t11.8705\n",
      "\n",
      "Loss evaluation at time 894:\t11.8255\n",
      "\n",
      "Loss evaluation at time 895:\t11.7806\n",
      "\n",
      "Loss evaluation at time 896:\t11.7360\n",
      "\n",
      "Loss evaluation at time 897:\t11.6916\n",
      "\n",
      "Loss evaluation at time 898:\t11.6475\n",
      "\n",
      "Loss evaluation at time 899:\t11.6035\n",
      "\n",
      "Loss evaluation at time 900:\t11.5598\n",
      "\n",
      "Loss evaluation at time 901:\t11.5163\n",
      "\n",
      "Loss evaluation at time 902:\t11.4731\n",
      "\n",
      "Loss evaluation at time 903:\t11.4300\n",
      "\n",
      "Loss evaluation at time 904:\t11.3872\n",
      "\n",
      "Loss evaluation at time 905:\t11.3446\n",
      "\n",
      "Loss evaluation at time 906:\t11.3022\n",
      "\n",
      "Loss evaluation at time 907:\t11.2600\n",
      "\n",
      "Loss evaluation at time 908:\t11.2180\n",
      "\n",
      "Loss evaluation at time 909:\t11.1763\n",
      "\n",
      "Loss evaluation at time 910:\t11.1347\n",
      "\n",
      "Loss evaluation at time 911:\t11.0934\n",
      "\n",
      "Loss evaluation at time 912:\t11.0522\n",
      "\n",
      "Loss evaluation at time 913:\t11.0113\n",
      "\n",
      "Loss evaluation at time 914:\t10.9706\n",
      "\n",
      "Loss evaluation at time 915:\t10.9300\n",
      "\n",
      "Loss evaluation at time 916:\t10.8897\n",
      "\n",
      "Loss evaluation at time 917:\t10.8496\n",
      "\n",
      "Loss evaluation at time 918:\t10.8097\n",
      "\n",
      "Loss evaluation at time 919:\t10.7699\n",
      "\n",
      "Loss evaluation at time 920:\t10.7304\n",
      "\n",
      "Loss evaluation at time 921:\t10.6911\n",
      "\n",
      "Loss evaluation at time 922:\t10.6519\n",
      "\n",
      "Loss evaluation at time 923:\t10.6130\n",
      "\n",
      "Loss evaluation at time 924:\t10.5742\n",
      "\n",
      "Loss evaluation at time 925:\t10.5357\n",
      "\n",
      "Loss evaluation at time 926:\t10.4973\n",
      "\n",
      "Loss evaluation at time 927:\t10.4591\n",
      "\n",
      "Loss evaluation at time 928:\t10.4211\n",
      "\n",
      "Loss evaluation at time 929:\t10.3833\n",
      "\n",
      "Loss evaluation at time 930:\t10.3457\n",
      "\n",
      "Loss evaluation at time 931:\t10.3082\n",
      "\n",
      "Loss evaluation at time 932:\t10.2710\n",
      "\n",
      "Loss evaluation at time 933:\t10.2339\n",
      "\n",
      "Loss evaluation at time 934:\t10.1970\n",
      "\n",
      "Loss evaluation at time 935:\t10.1603\n",
      "\n",
      "Loss evaluation at time 936:\t10.1237\n",
      "\n",
      "Loss evaluation at time 937:\t10.0873\n",
      "\n",
      "Loss evaluation at time 938:\t10.0512\n",
      "\n",
      "Loss evaluation at time 939:\t10.0151\n",
      "\n",
      "Loss evaluation at time 940:\t9.9793\n",
      "\n",
      "Loss evaluation at time 941:\t9.9436\n",
      "\n",
      "Loss evaluation at time 942:\t9.9081\n",
      "\n",
      "Loss evaluation at time 943:\t9.8728\n",
      "\n",
      "Loss evaluation at time 944:\t9.8377\n",
      "\n",
      "Loss evaluation at time 945:\t9.8027\n",
      "\n",
      "Loss evaluation at time 946:\t9.7679\n",
      "\n",
      "Loss evaluation at time 947:\t9.7332\n",
      "\n",
      "Loss evaluation at time 948:\t9.6987\n",
      "\n",
      "Loss evaluation at time 949:\t9.6644\n",
      "\n",
      "Loss evaluation at time 950:\t9.6302\n",
      "\n",
      "Loss evaluation at time 951:\t9.5962\n",
      "\n",
      "Loss evaluation at time 952:\t9.5624\n",
      "\n",
      "Loss evaluation at time 953:\t9.5287\n",
      "\n",
      "Loss evaluation at time 954:\t9.4952\n",
      "\n",
      "Loss evaluation at time 955:\t9.4619\n",
      "\n",
      "Loss evaluation at time 956:\t9.4287\n",
      "\n",
      "Loss evaluation at time 957:\t9.3956\n",
      "\n",
      "Loss evaluation at time 958:\t9.3628\n",
      "\n",
      "Loss evaluation at time 959:\t9.3300\n",
      "\n",
      "Loss evaluation at time 960:\t9.2975\n",
      "\n",
      "Loss evaluation at time 961:\t9.2650\n",
      "\n",
      "Loss evaluation at time 962:\t9.2328\n",
      "\n",
      "Loss evaluation at time 963:\t9.2007\n",
      "\n",
      "Loss evaluation at time 964:\t9.1687\n",
      "\n",
      "Loss evaluation at time 965:\t9.1369\n",
      "\n",
      "Loss evaluation at time 966:\t9.1052\n",
      "\n",
      "Loss evaluation at time 967:\t9.0737\n",
      "\n",
      "Loss evaluation at time 968:\t9.0423\n",
      "\n",
      "Loss evaluation at time 969:\t9.0111\n",
      "\n",
      "Loss evaluation at time 970:\t8.9800\n",
      "\n",
      "Loss evaluation at time 971:\t8.9491\n",
      "\n",
      "Loss evaluation at time 972:\t8.9183\n",
      "\n",
      "Loss evaluation at time 973:\t8.8876\n",
      "\n",
      "Loss evaluation at time 974:\t8.8571\n",
      "\n",
      "Loss evaluation at time 975:\t8.8268\n",
      "\n",
      "Loss evaluation at time 976:\t8.7965\n",
      "\n",
      "Loss evaluation at time 977:\t8.7664\n",
      "\n",
      "Loss evaluation at time 978:\t8.7365\n",
      "\n",
      "Loss evaluation at time 979:\t8.7067\n",
      "\n",
      "Loss evaluation at time 980:\t8.6770\n",
      "\n",
      "Loss evaluation at time 981:\t8.6475\n",
      "\n",
      "Loss evaluation at time 982:\t8.6181\n",
      "\n",
      "Loss evaluation at time 983:\t8.5888\n",
      "\n",
      "Loss evaluation at time 984:\t8.5597\n",
      "\n",
      "Loss evaluation at time 985:\t8.5307\n",
      "\n",
      "Loss evaluation at time 986:\t8.5018\n",
      "\n",
      "Loss evaluation at time 987:\t8.4731\n",
      "\n",
      "Loss evaluation at time 988:\t8.4445\n",
      "\n",
      "Loss evaluation at time 989:\t8.4160\n",
      "\n",
      "Loss evaluation at time 990:\t8.3877\n",
      "\n",
      "Loss evaluation at time 991:\t8.3595\n",
      "\n",
      "Loss evaluation at time 992:\t8.3314\n",
      "\n",
      "Loss evaluation at time 993:\t8.3034\n",
      "\n",
      "Loss evaluation at time 994:\t22.2437\n",
      "\n",
      "Loss evaluation at time 995:\t8.3201\n",
      "\n",
      "Loss evaluation at time 996:\t22.1870\n",
      "\n",
      "Loss evaluation at time 997:\t22.1445\n",
      "\n",
      "Loss evaluation at time 998:\t22.1021\n",
      "\n",
      "Loss evaluation at time 999:\t22.0597\n",
      "\n",
      "Loss evaluation at time 1000:\t22.0173\n",
      "\n",
      "CPU times: user 2min 34s, sys: 663 ms, total: 2min 35s\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fpred, f, w, mean, t, loss = stochasticZFW(F, d, w0, method = \"IRDSA\", r=1, T=1000, eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdf0aca97d0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT:\n",
      "\n",
      "F(w_pred) = 183506.7064278634\n",
      "\n",
      "F(w) = 183528.72376379377\n",
      "\n",
      "w = [ 4.10911465e-04  1.57315358e-06  1.20546499e-08  1.41221084e-06\n",
      "  1.05317500e-06  5.22047748e-07  2.67517668e-01  7.31129174e-01\n",
      "  6.87140792e-04  2.27947111e-05  1.43396712e-04  3.39823294e-07\n",
      "  5.67333862e-07  1.01727444e-06  9.63924717e-07  1.88822163e-06\n",
      "  1.54709061e-06  2.07782710e-08  6.38127397e-07  6.93596671e-07\n",
      "  1.61734925e-06  1.37340846e-06  1.56981352e-06  1.64692333e-07\n",
      "  1.91960787e-06  1.94429340e-06  1.41479562e-06  3.39840463e-07\n",
      "  9.00787298e-07  7.39830121e-07  1.90022630e-06  3.50408370e-07\n",
      "  1.59961095e-06  9.77132823e-07  3.65768893e-07  6.18041258e-07\n",
      "  1.46576628e-06  1.82041291e-07  1.04983792e-06  1.99076184e-07\n",
      "  1.66399033e-06  1.93561704e-06  8.94293116e-07  4.80759533e-07\n",
      "  4.23719196e-07  1.66007264e-06  1.41407182e-06  1.66966478e-06\n",
      "  2.66707984e-05 -1.56600752e-05  3.38289454e-07  4.63816092e-07\n",
      "  8.41086607e-07  1.65207175e-06]\n",
      "\n",
      "average w = [ 5.72348063e-03  1.98020707e-04  1.51737905e-06  1.77762040e-04\n",
      "  1.32568403e-04  6.57127602e-05  4.62786450e-01  5.01884743e-01\n",
      "  1.34938472e-02  2.11928426e-03  4.05006115e-03  4.27752571e-05\n",
      "  7.14131499e-05  1.28049420e-04  1.21334024e-04  2.37679898e-04\n",
      "  1.94740030e-04  2.61546487e-06  8.03242861e-05  8.73064809e-05\n",
      "  2.03583837e-04  1.72877789e-04  1.97600276e-04  2.07306474e-05\n",
      "  2.41630641e-04  2.44737932e-04  1.78087398e-04  4.27774183e-05\n",
      "  1.13386601e-04  9.31261165e-05  2.39190985e-04  4.41076536e-05\n",
      "  2.01351028e-04  1.22996594e-04  4.60411594e-05  7.77959434e-05\n",
      "  1.84503331e-04  2.29144475e-05  1.32148349e-04  2.50587147e-05\n",
      "  2.09454783e-04  2.43645795e-04  1.12569146e-04  6.05156062e-05\n",
      "  5.33356538e-05  2.08961644e-04  1.77996291e-04  2.10169055e-04\n",
      "  2.10718675e-03 -1.97121196e-03  4.25821850e-05  5.83828506e-05\n",
      "  1.05871777e-04  2.07954532e-04]\n",
      "\n",
      "T = 1000\n"
     ]
    }
   ],
   "source": [
    "print(f'OUTPUT:\\n\\nF(w_pred) = {fpred}\\n\\nF(w) = {f}\\n\\nw = {w}\\n\\naverage w = {mean}\\n\\nT = {t}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeroth order stochastic accelerated gradient method with inexact updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InexactUpdate(g, d, v, r, gamma, mu):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    - g: gradient approximation \n",
    "    - d: dimension\n",
    "    - v: starting point\n",
    "    - r: radius\n",
    "    - gamma: decreasing coefficient\n",
    "    - mu: threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    haty = v\n",
    "    t = 1\n",
    "    while True:\n",
    "        # ARGMIN PROBLEM\n",
    "        ht1 = g + gamma*(haty - v)\n",
    "        i_k = np.argmax(np.abs(ht1))\n",
    "        ei = e(i_k, d) * r\n",
    "        yt = np.sign(-ht1[i_k]) * ei\n",
    "        if np.dot(ht1, yt - haty) >= - mu:\n",
    "            break\n",
    "        else:\n",
    "            haty = (t-1)/(t+1) * haty + 2/(t+1)*yt\n",
    "            t +=1\n",
    "    return haty\n",
    "    \n",
    "\n",
    "L = 3\n",
    "D = 2*r*10 # we will start from m = 6, up to T * (T+1) / D * (d+3)\n",
    "B = 1\n",
    "\n",
    "\n",
    "def IZFW(F, d, w0, L, B, D, r = 1, T = 100, eps = 1e-6):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    - F: loss function\n",
    "    - d: dimension\n",
    "    - w0: starting point\n",
    "    - L: lipschitz\n",
    "    - B: 1\n",
    "    - D: number greater than diamater l1 ball\n",
    "    - r: radius of the ball\n",
    "    - T: max iteration\n",
    "    - eps: tolerance\n",
    "    \"\"\"\n",
    "    \n",
    "    alpha = lambda t: 2/(t+2)\n",
    "    gamma = lambda t: 4*L/t\n",
    "    mu = lambda t: L*D/(t*T)\n",
    "    m = lambda t: t * (t+1) / D * (d+3)#np.max([(d+5)*B*T, d+3])\n",
    "    c = 1 / (np.sqrt(2*T)) * np.max([1/(d+3), np.sqrt(D/(d*(T+1)))]) # smoothing parameter now fixed\n",
    "    \n",
    "    loss = []\n",
    "    v, w = w0, w0\n",
    "    partial = 0\n",
    "    \n",
    "    for t in range(1, T+1):\n",
    "        dt = (1-alpha(t)) * w + alpha(t) * v\n",
    "        g = IRDSA(F, dt, int(np.ceil(m(t))), c, d)\n",
    "        v = InexactUpdate(g, d, v, r, gamma(t), mu(t)) #ICG\n",
    "        w_pred = w\n",
    "        w = (1 - alpha(t)) * w + alpha(t) * v\n",
    "        partial += w\n",
    "        loss_eval = np.abs(F(w_pred) - F(w))\n",
    "        loss.append(loss_eval)\n",
    "        print(f\"Loss evaluation at time {t}:\\t{loss_eval:.4f}\\n\")\n",
    "        print(int(np.ceil(m(t))))\n",
    "        if loss_eval < eps: break # check stopping condition\n",
    "    return F(w_pred), F(w), w, partial/T, t, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I parametri degli algoritmi (L per deterministic FW e IGC + tutti quelli di IGC che sono collegati al gradiente, tipo varianza del grad e grad stesso)\n",
    "\n",
    "I grafici uguali o no? Che differenza c'è tra # oracolo e # di iterazioni? (Loss disponibile solo a fine chiamate oracolo)\n",
    "\n",
    "I dataset: il primo ok, secondo stesso preprocessing ma abbiamo risultati diversi, il terzo non sappiamo cos'è e come si usa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss evaluation at time 1:\t343218.6203\n",
      "\n",
      "57\n",
      "Loss evaluation at time 2:\t60852.1867\n",
      "\n",
      "171\n",
      "Loss evaluation at time 3:\t21546.1982\n",
      "\n",
      "342\n",
      "Loss evaluation at time 4:\t10174.2399\n",
      "\n",
      "570\n",
      "Loss evaluation at time 5:\t5634.6010\n",
      "\n",
      "855\n",
      "Loss evaluation at time 6:\t199.7743\n",
      "\n",
      "1197\n",
      "Loss evaluation at time 7:\t3182.5927\n",
      "\n",
      "1596\n",
      "Loss evaluation at time 8:\t967.1668\n",
      "\n",
      "2052\n",
      "Loss evaluation at time 9:\t2234.7473\n",
      "\n",
      "2565\n",
      "Loss evaluation at time 10:\t1091.7662\n",
      "\n",
      "3135\n",
      "Loss evaluation at time 11:\t935.3902\n",
      "\n",
      "3762\n",
      "Loss evaluation at time 12:\t1803.3786\n",
      "\n",
      "4446\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-3dca07a451d7>\u001b[0m in \u001b[0;36mIZFW\u001b[0;34m(F, d, w0, L, B, r, T, eps)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIRDSA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInexactUpdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#ICG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mw_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ec57065f0da8>\u001b[0m in \u001b[0;36mIRDSA\u001b[0;34m(F, w, m, c, d)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mF_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mF_w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ec57065f0da8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mF_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mF_w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-af15dedb837a>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# define the objective function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fpred, f, w, mean, t, loss = IZFW(F, d, w0, L, B, r = 1, T = 100, eps = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb6ef864710>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT:\n",
      "\n",
      "F(w_pred) = 197914.107239128\n",
      "\n",
      "F(w) = 197869.3747248715\n",
      "\n",
      "w = [2.34933557e-02 4.02983567e-06 3.08795393e-08 3.61756009e-06\n",
      " 3.69130200e-03 1.33729259e-06 4.01673147e-01 5.04176608e-01\n",
      " 4.69849198e-02 2.87166285e-06 1.98059062e-02 8.70501166e-07\n",
      " 1.45329881e-06 2.60587958e-06 2.46921740e-06 4.83692308e-06\n",
      " 3.96307199e-06 5.32262194e-08 1.63464558e-06 1.77673727e-06\n",
      " 4.14304857e-06 3.51816278e-06 4.02127965e-06 4.21880637e-07\n",
      " 4.91732298e-06 4.98055814e-06 3.62418132e-06 8.70545149e-07\n",
      " 2.30748277e-06 1.89517021e-06 4.86767458e-06 8.97616203e-07\n",
      " 4.09760962e-06 2.50305167e-06 9.36964163e-07 1.58319234e-06\n",
      " 3.75474925e-06 4.66322230e-07 2.68929516e-06 5.09959305e-07\n",
      " 4.26252570e-06 4.95833253e-06 2.29084708e-06 1.23152751e-06\n",
      " 1.08541133e-06 4.25249003e-06 3.62232723e-06 4.27706155e-06\n",
      " 2.70622791e-06 2.62828100e-07 8.66572037e-07 1.18812470e-06\n",
      " 2.15455175e-06 4.23199472e-06]\n",
      "\n",
      "average w = [5.64144616e-02 2.03506701e-04 1.55941674e-06 1.82686785e-04\n",
      " 1.64107509e-02 6.75332759e-05 4.14493922e-01 4.50918711e-01\n",
      " 3.27384495e-02 1.45018974e-04 2.01982629e-02 4.39603089e-05\n",
      " 7.33915900e-05 1.31596919e-04 1.24695479e-04 2.44264616e-04\n",
      " 2.00135135e-04 2.68792408e-06 8.25496016e-05 8.97252321e-05\n",
      " 2.09223953e-04 1.77667220e-04 2.03074622e-04 2.13049722e-05\n",
      " 2.48324811e-04 2.51518186e-04 1.83021157e-04 4.39625300e-05\n",
      " 1.16527880e-04 9.57060956e-05 2.45817567e-04 4.53296183e-05\n",
      " 2.06929286e-04 1.26404109e-04 4.73166902e-05 7.99512133e-05\n",
      " 1.89614837e-04 2.35492726e-05 1.35809405e-04 2.57529449e-05\n",
      " 2.15257548e-04 2.50395793e-04 1.15687778e-04 6.21921392e-05\n",
      " 5.48132723e-05 2.14750747e-04 1.82927525e-04 2.15991608e-04\n",
      " 1.36664510e-04 1.32728190e-05 4.37618879e-05 6.00002974e-05\n",
      " 1.08804863e-04 2.13715733e-04]\n",
      "\n",
      "T = 100\n"
     ]
    }
   ],
   "source": [
    "print(f'OUTPUT:\\n\\nF(w_pred) = {fpred}\\n\\nF(w) = {f}\\n\\nw = {w}\\n\\naverage w = {mean}\\n\\nT = {t}')# m=6, T=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT:\n",
      "\n",
      "F(w_pred) = 198152.00822366346\n",
      "\n",
      "F(w) = 198018.65622128965\n",
      "\n",
      "w = [4.47739238e-02 1.14471662e-03 4.80743181e-09 5.63194071e-07\n",
      " 4.20009460e-07 2.08194264e-07 3.76933956e-01 5.25665416e-01\n",
      " 2.27723602e-02 4.47070249e-07 2.64906774e-02 1.35522585e-07\n",
      " 2.20039787e-03 4.05692205e-07 3.84416172e-07 7.53028653e-07\n",
      " 6.16984540e-07 8.28643904e-09 2.54487188e-07 2.76608507e-07\n",
      " 6.45003906e-07 5.47719559e-07 6.26046507e-07 6.56798139e-08\n",
      " 7.65545583e-07 7.75390248e-07 5.64224887e-07 1.35529433e-07\n",
      " 3.59236773e-07 2.95046551e-07 7.57816151e-07 1.39743946e-07\n",
      " 6.37929816e-07 3.89683605e-07 1.45869771e-07 2.46476774e-07\n",
      " 5.84552147e-07 7.25986323e-08 4.18678626e-07 7.93922008e-08\n",
      " 6.63604513e-07 7.71930090e-07 3.56646873e-07 1.91728395e-07\n",
      " 1.68980532e-07 6.62042126e-07 5.63936236e-07 6.65867503e-07\n",
      " 4.21314775e-07 4.09179734e-08 1.34910885e-07 1.84971298e-07\n",
      " 3.35427952e-07 6.58851346e-07]\n",
      "\n",
      "average w = [2.18088624e-02 5.61318427e-03 7.23518488e-07 8.47607077e-05\n",
      " 6.32114238e-05 3.13332367e-05 3.41893760e-01 5.85978471e-01\n",
      " 2.39068738e-02 6.72840725e-05 1.35136211e-02 2.03961491e-05\n",
      " 4.49321245e-03 6.10566769e-05 5.78546338e-05 1.13330812e-04\n",
      " 9.28561732e-05 1.24710908e-06 3.83003219e-05 4.16295803e-05\n",
      " 9.70730878e-05 8.24317936e-05 9.42199993e-05 9.88481199e-06\n",
      " 1.15214610e-04 1.16696232e-04 8.49158455e-05 2.03971796e-05\n",
      " 5.40651343e-05 4.44045059e-05 1.14051331e-04 2.10314639e-05\n",
      " 9.60084372e-05 5.86473826e-05 2.19534005e-05 3.70947545e-05\n",
      " 8.79750981e-05 1.09260942e-05 6.30111331e-05 1.19485262e-05\n",
      " 9.98724792e-05 1.16175478e-04 5.36753544e-05 2.88551235e-05\n",
      " 2.54315700e-05 9.96373400e-05 8.48724035e-05 1.00213059e-04\n",
      " 6.34078736e-05 6.15815500e-06 2.03040882e-05 2.78381804e-05\n",
      " 5.04819067e-05 9.91571276e-05]\n",
      "\n",
      "T = 300\n"
     ]
    }
   ],
   "source": [
    "print(f'OUTPUT:\\n\\nF(w_pred) = {fpred}\\n\\nF(w) = {f}\\n\\nw = {w}\\n\\naverage w = {mean}\\n\\nT = {t}')#100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
