{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e(i, d):\n",
    "    ei = np.zeros(d)\n",
    "    ei[i] = 1\n",
    "    return ei\n",
    "\n",
    "\n",
    "\n",
    "def KWSA(F, w, m, c, d):\n",
    "    \"\"\" \n",
    "    Kiefer-Wolfowitz stochastic approximation\n",
    "    for gradient estimation \n",
    "    \n",
    "    INPUT:\n",
    "    - F: objective function\n",
    "    - w: current weight\n",
    "    - m: sample size (null in this case)\n",
    "    - d: dimension\n",
    "    - c: costant\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    F_wc = np.array([F(w + c * e(i, d)) for i in range(d)])\n",
    "    return (F_wc - F(w)) / c\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def IRDSA(F, w, m, c, d):\n",
    "    \"\"\" \n",
    "    Improvised Random Direction stochastic approximation\n",
    "    for gradient estimation \n",
    "    \n",
    "    INPUT:\n",
    "    - F: objective function\n",
    "    - w: current weight\n",
    "    - m: sample dimension\n",
    "    - d: features dimension\n",
    "    - c: costant\n",
    "    \n",
    "    \"\"\"\n",
    "    z = np.random.normal(0, 1, (d, m))\n",
    "    F_w = F(w)\n",
    "    return np.mean([(F(w + c * z[:,i]) - F_w) / c * z[:,i] for i in range(m)], axis = 0)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def detZFW(F, L, d, w0, r=1, T=100, eps=1e-5):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    - F: loss function\n",
    "    - L: Lip constant\n",
    "    - d: dimension\n",
    "    - w0: starting point\n",
    "    - r: radius of the ball\n",
    "    - T: max iteration\n",
    "    - eps: tolerance\n",
    "    \"\"\"\n",
    "\n",
    "    gamma = lambda t: 2/(t+2)\n",
    "    c = lambda t: L*gamma(t)/d\n",
    "    w = w0\n",
    "    partial = 0\n",
    "    for t in range(1, T+1):\n",
    "        # comupute the gradient approx\n",
    "        gt = KWSA(F, w, None, c(t), d)\n",
    "        # compute the linear problem solution on the L1 Ball of radius r\n",
    "        i_k = np.argmax(np.abs(gt))\n",
    "        ei = e(i_k, d) * r\n",
    "        v = np.sign(-gt[i_k]) * ei\n",
    "        # compute step \n",
    "        w_pred = w\n",
    "        w = (1 - gamma(t)) * w + gamma(t) * v\n",
    "        partial += w\n",
    "        loss_eval = F(w_pred) - F(w)\n",
    "        print(f\"Loss evaluation at time {t}:\\t{loss_eval:.4f}\\n\")\n",
    "        if loss_eval < eps: break # check stopping condition\n",
    "    return F(w_pred), F(w), w, partial/T, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X, y = datasets.load_svmlight_file(\"../Data/covtype.libsvm.binary.scale.bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space Dimensions\n",
      "d: 54\n",
      "n: 581012\n"
     ]
    }
   ],
   "source": [
    "# space dimension\n",
    "d = X.shape[1]\n",
    "print(f\"Space Dimensions\\nd: {d}\")\n",
    "print(f\"n: {y.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w_star = np.linalg.inv(X * X.T) * X * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the objective function\n",
    "F = lambda w: 0.5 * np.sum(np.power(y - X @ w, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L: 6.401824257555926\n"
     ]
    }
   ],
   "source": [
    "# initialize prarameters for the algorithm\n",
    "\n",
    "# stating point \n",
    "np.random.seed(1007)\n",
    "w0 = np.random.rand(d)\n",
    "w0 = w0/sum(w0)\n",
    "#print(w0)\n",
    "#print(F(w0))\n",
    "\n",
    "# Lipschitz constant computation\n",
    "L = 2/X.shape[0] * norm(X.T @ X)\n",
    "print(f\"L: {L}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss evaluation at time 1:\t320442.8827\n",
      "\n",
      "Loss evaluation at time 2:\t57384.8266\n",
      "\n",
      "Loss evaluation at time 3:\t20408.6305\n",
      "\n",
      "Loss evaluation at time 4:\t9658.8938\n",
      "\n",
      "Loss evaluation at time 5:\t5356.1125\n",
      "\n",
      "Loss evaluation at time 6:\t3287.2771\n",
      "\n",
      "Loss evaluation at time 7:\t2165.7518\n",
      "\n",
      "Loss evaluation at time 8:\t1503.7615\n",
      "\n",
      "Loss evaluation at time 9:\t1087.3006\n",
      "\n",
      "Loss evaluation at time 10:\t811.9696\n",
      "\n",
      "Loss evaluation at time 11:\t622.5471\n",
      "\n",
      "Loss evaluation at time 12:\t487.8967\n",
      "\n",
      "Loss evaluation at time 13:\t389.5270\n",
      "\n",
      "Loss evaluation at time 14:\t315.9734\n",
      "\n",
      "Loss evaluation at time 15:\t259.8651\n",
      "\n",
      "Loss evaluation at time 16:\t216.3140\n",
      "\n",
      "Loss evaluation at time 17:\t181.9897\n",
      "\n",
      "Loss evaluation at time 18:\t154.5695\n",
      "\n",
      "Loss evaluation at time 19:\t132.3991\n",
      "\n",
      "Loss evaluation at time 20:\t114.2785\n",
      "\n",
      "Loss evaluation at time 21:\t99.3227\n",
      "\n",
      "Loss evaluation at time 22:\t86.8693\n",
      "\n",
      "Loss evaluation at time 23:\t76.4157\n",
      "\n",
      "Loss evaluation at time 24:\t67.5755\n",
      "\n",
      "Loss evaluation at time 25:\t60.0491\n",
      "\n",
      "Loss evaluation at time 26:\t53.6009\n",
      "\n",
      "Loss evaluation at time 27:\t48.0445\n",
      "\n",
      "Loss evaluation at time 28:\t43.2307\n",
      "\n",
      "Loss evaluation at time 29:\t39.0395\n",
      "\n",
      "Loss evaluation at time 30:\t35.3733\n",
      "\n",
      "Loss evaluation at time 31:\t32.1524\n",
      "\n",
      "Loss evaluation at time 32:\t29.3112\n",
      "\n",
      "Loss evaluation at time 33:\t26.7953\n",
      "\n",
      "Loss evaluation at time 34:\t24.5593\n",
      "\n",
      "Loss evaluation at time 35:\t22.5655\n",
      "\n",
      "Loss evaluation at time 36:\t20.7819\n",
      "\n",
      "Loss evaluation at time 37:\t19.1815\n",
      "\n",
      "Loss evaluation at time 38:\t17.7413\n",
      "\n",
      "Loss evaluation at time 39:\t16.4418\n",
      "\n",
      "Loss evaluation at time 40:\t15.2663\n",
      "\n",
      "Loss evaluation at time 41:\t14.2002\n",
      "\n",
      "Loss evaluation at time 42:\t13.2311\n",
      "\n",
      "Loss evaluation at time 43:\t12.3483\n",
      "\n",
      "Loss evaluation at time 44:\t11.5423\n",
      "\n",
      "Loss evaluation at time 45:\t10.8050\n",
      "\n",
      "Loss evaluation at time 46:\t10.1292\n",
      "\n",
      "Loss evaluation at time 47:\t9.5086\n",
      "\n",
      "Loss evaluation at time 48:\t8.9377\n",
      "\n",
      "Loss evaluation at time 49:\t8.4116\n",
      "\n",
      "Loss evaluation at time 50:\t7.9260\n",
      "\n",
      "CPU times: user 47.3 s, sys: 748 ms, total: 48 s\n",
      "Wall time: 48.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fpred, f, w, mean, t = detZFW(F, L, d, w0, T=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT:\n",
      "\n",
      "F(w_pred) = 179835.97225864613\n",
      "\n",
      "F(w) = 179828.04624133222\n",
      "\n",
      "w = [1.47886743e-05 2.15045112e-05 1.64783245e-07 1.93044749e-05\n",
      " 1.43965686e-05 7.13622735e-06 1.90413191e-05 9.99260054e-01\n",
      " 2.00170176e-05 1.53241251e-05 2.09504029e-05 4.64527679e-06\n",
      " 7.75527420e-06 1.39058193e-05 1.31765456e-05 2.58113916e-05\n",
      " 2.11482385e-05 2.84032384e-07 8.72299940e-06 9.48124680e-06\n",
      " 2.21086520e-05 1.87740586e-05 2.14588535e-05 2.25129202e-06\n",
      " 2.62404316e-05 2.65778749e-05 1.93398080e-05 4.64551149e-06\n",
      " 1.23134770e-05 1.01132434e-05 2.59754916e-05 4.78997143e-06\n",
      " 2.18661750e-05 1.33570962e-05 4.99994491e-06 8.44842824e-06\n",
      " 2.00365608e-05 2.48844679e-06 1.43509519e-05 2.72130838e-06\n",
      " 2.27462207e-05 2.64592719e-05 1.22247036e-05 6.57183054e-06\n",
      " 5.79210720e-06 2.26926672e-05 1.93299139e-05 2.28237888e-05\n",
      " 1.44413106e-05 1.40253605e-06 4.62430968e-06 6.34021907e-06\n",
      " 1.14973875e-05 2.25832975e-05]\n",
      "\n",
      "average w = [3.77111196e-04 5.48365036e-04 4.20197276e-06 4.92264110e-04\n",
      " 3.67112500e-04 1.81973798e-04 4.85553637e-04 9.81131375e-01\n",
      " 5.10433948e-04 3.90765190e-04 5.34235274e-04 1.18454558e-04\n",
      " 1.97759492e-04 3.54598393e-04 3.36001912e-04 6.58190487e-04\n",
      " 5.39280083e-04 7.24282579e-06 2.22436485e-04 2.41771793e-04\n",
      " 5.63770625e-04 4.78738494e-04 5.47200765e-04 5.74079465e-05\n",
      " 6.69131006e-04 6.77735811e-04 4.93165103e-04 1.18460543e-04\n",
      " 3.13993665e-04 2.57887707e-04 6.62375037e-04 1.22144271e-04\n",
      " 5.57587462e-04 3.40605953e-04 1.27498595e-04 2.15434920e-04\n",
      " 5.10932301e-04 6.34553931e-05 3.65949273e-04 6.93933638e-05\n",
      " 5.80028629e-04 6.74711433e-04 3.11729943e-04 1.67581679e-04\n",
      " 1.47698734e-04 5.78663013e-04 4.92912805e-04 5.82006613e-04\n",
      " 3.68253420e-04 3.57646694e-05 1.17919897e-04 1.61675586e-04\n",
      " 2.93183381e-04 5.75874087e-04]\n",
      "\n",
      "T = 50\n"
     ]
    }
   ],
   "source": [
    "print(f'OUTPUT:\\n\\nF(w_pred) = {fpred}\\n\\nF(w) = {f}\\n\\nw = {w}\\n\\naverage w = {mean}\\n\\nT = {t}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Free Frank Wolfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochasticZFW(F, d,  w0, method = \"IRDSA\", r=1, T=100, eps=1e-5):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    - F: loss function\n",
    "    - d: dimension\n",
    "    - w0: starting point\n",
    "    - method: zeroth order oracle\n",
    "    - r: radius of the ball\n",
    "    - T: max iteration\n",
    "    - eps: tolerance\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters_dict = {\"KWSA\": {\"m\": None, \n",
    "                                \"c\": lambda t: 2 / (np.sqrt(d) * np.power(t+8, 1/3)),\n",
    "                                \"p\": lambda t: 4 / np.power(t+8, 2/3),\n",
    "                                \"oracle\": KWSA},\n",
    "                       \n",
    "                   \n",
    "                       \"RDSA\": {\"m\": 1, \n",
    "                                \"c\": lambda t: 2 / (np.power(d, 3/2) * np.power(t+8, 1/3)),\n",
    "                                \"p\": lambda t: 4 / (np.power(d, 1/3) * np.power(t+8, 2/3)),\n",
    "                                \"oracle\": IRDSA},\n",
    "                   \n",
    "                       \"IRDSA\": {\"m\": 6, \n",
    "                                \"c\": lambda t: 2 * np.sqrt(6) / (np.power(d, 3/2) * np.power(t+8, 1/3)),\n",
    "                                \"p\": lambda t: 4 / (np.power(1+d/6, 1/3) * np.power(t+8, 2/3)),\n",
    "                                \"oracle\": IRDSA}\n",
    "                  \n",
    "                        }\n",
    "    \n",
    "    return sZFW(F, d, w0, Parameters_dict[method], r, T, eps)\n",
    "    \n",
    "  \n",
    "\n",
    "    \n",
    "def sZFW(F, d, w0, params, r, T, eps):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    - F: loss function\n",
    "    - d: dimension\n",
    "    - w0: starting point\n",
    "    - params: dict of parameters for the selected method\n",
    "    - r: radius of the ball\n",
    "    - T: max iteration\n",
    "    - eps: tolerance\n",
    "    \"\"\"\n",
    "    \n",
    "    loss = []\n",
    "    gamma = lambda t: 2/(t+8)\n",
    "    w = w0\n",
    "    dt = np.zeros(d)\n",
    "    partial = 0\n",
    "    for t in range(1, T+1):\n",
    "        # comupute the gradient approx\n",
    "        gt = params[\"oracle\"](F, w, params[\"m\"], params[\"c\"](t), d)\n",
    "        dt = (1 - params[\"p\"](t)) * dt + params[\"p\"](t) * gt\n",
    "        # compute the linear problem solution on the L1 Ball of radius r\n",
    "        ei = e(np.argmax(np.abs(dt)), d) * r\n",
    "        v = np.sign(-dt) * ei\n",
    "        # compute step \n",
    "        w_pred = w\n",
    "        w = (1 - gamma(t)) * w + gamma(t) * v\n",
    "        partial += w\n",
    "        loss_eval = np.abs(F(w_pred) - F(w))\n",
    "        loss.append(loss_eval)\n",
    "        print(f\"Loss evaluation at time {t}:\\t{loss_eval:.4f}\\n\")\n",
    "        if loss_eval < eps: break # check stopping condition\n",
    "    return F(w_pred), F(w), w, partial/T, t, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss evaluation at time 1:\t23485.3026\n",
      "\n",
      "Loss evaluation at time 2:\t118187.9164\n",
      "\n",
      "Loss evaluation at time 3:\t77077.7907\n",
      "\n",
      "Loss evaluation at time 4:\t9683.7472\n",
      "\n",
      "Loss evaluation at time 5:\t36613.9823\n",
      "\n",
      "Loss evaluation at time 6:\t50942.6387\n",
      "\n",
      "Loss evaluation at time 7:\t8156.1616\n",
      "\n",
      "Loss evaluation at time 8:\t22736.7139\n",
      "\n",
      "Loss evaluation at time 9:\t25373.2420\n",
      "\n",
      "Loss evaluation at time 10:\t43955.3835\n",
      "\n",
      "Loss evaluation at time 11:\t35083.8555\n",
      "\n",
      "Loss evaluation at time 12:\t3283.3129\n",
      "\n",
      "Loss evaluation at time 13:\t26776.8020\n",
      "\n",
      "Loss evaluation at time 14:\t740.9106\n",
      "\n",
      "Loss evaluation at time 15:\t21462.7202\n",
      "\n",
      "Loss evaluation at time 16:\t18111.1744\n",
      "\n",
      "Loss evaluation at time 17:\t15421.5570\n",
      "\n",
      "Loss evaluation at time 18:\t13239.2585\n",
      "\n",
      "Loss evaluation at time 19:\t1806.8469\n",
      "\n",
      "Loss evaluation at time 20:\t9649.7009\n",
      "\n",
      "Loss evaluation at time 21:\t8900.0339\n",
      "\n",
      "Loss evaluation at time 22:\t8210.9718\n",
      "\n",
      "Loss evaluation at time 23:\t12445.3037\n",
      "\n",
      "Loss evaluation at time 24:\t11009.7996\n",
      "\n",
      "Loss evaluation at time 25:\t9365.5445\n",
      "\n",
      "Loss evaluation at time 26:\t8895.9147\n",
      "\n",
      "Loss evaluation at time 27:\t7970.5758\n",
      "\n",
      "Loss evaluation at time 28:\t7169.7228\n",
      "\n",
      "Loss evaluation at time 29:\t6473.1624\n",
      "\n",
      "Loss evaluation at time 30:\t5864.4859\n",
      "\n",
      "Loss evaluation at time 31:\t5330.2727\n",
      "\n",
      "Loss evaluation at time 32:\t4859.4776\n",
      "\n",
      "Loss evaluation at time 33:\t4442.9576\n",
      "\n",
      "Loss evaluation at time 34:\t4073.1021\n",
      "\n",
      "Loss evaluation at time 35:\t3743.5431\n",
      "\n",
      "Loss evaluation at time 36:\t3448.9256\n",
      "\n",
      "Loss evaluation at time 37:\t3184.7252\n",
      "\n",
      "Loss evaluation at time 38:\t2418.1327\n",
      "\n",
      "Loss evaluation at time 39:\t2315.3111\n",
      "\n",
      "Loss evaluation at time 40:\t2215.8586\n",
      "\n",
      "Loss evaluation at time 41:\t2120.0486\n",
      "\n",
      "Loss evaluation at time 42:\t4041.9286\n",
      "\n",
      "Loss evaluation at time 43:\t3762.7932\n",
      "\n",
      "Loss evaluation at time 44:\t3508.9930\n",
      "\n",
      "Loss evaluation at time 45:\t3277.7132\n",
      "\n",
      "Loss evaluation at time 46:\t3066.5049\n",
      "\n",
      "Loss evaluation at time 47:\t2873.2315\n",
      "\n",
      "Loss evaluation at time 48:\t2696.0233\n",
      "\n",
      "Loss evaluation at time 49:\t2533.2395\n",
      "\n",
      "Loss evaluation at time 50:\t2383.4361\n",
      "\n",
      "Loss evaluation at time 51:\t2245.3394\n",
      "\n",
      "Loss evaluation at time 52:\t2117.8227\n",
      "\n",
      "Loss evaluation at time 53:\t1999.8868\n",
      "\n",
      "Loss evaluation at time 54:\t1890.6442\n",
      "\n",
      "Loss evaluation at time 55:\t1789.3039\n",
      "\n",
      "Loss evaluation at time 56:\t1695.1603\n",
      "\n",
      "Loss evaluation at time 57:\t1607.5818\n",
      "\n",
      "Loss evaluation at time 58:\t1526.0026\n",
      "\n",
      "Loss evaluation at time 59:\t1449.9145\n",
      "\n",
      "Loss evaluation at time 60:\t1378.8601\n",
      "\n",
      "Loss evaluation at time 61:\t1312.4272\n",
      "\n",
      "Loss evaluation at time 62:\t1250.2436\n",
      "\n",
      "Loss evaluation at time 63:\t1191.9724\n",
      "\n",
      "Loss evaluation at time 64:\t1137.3088\n",
      "\n",
      "Loss evaluation at time 65:\t1085.9757\n",
      "\n",
      "Loss evaluation at time 66:\t3378.1510\n",
      "\n",
      "Loss evaluation at time 67:\t3382.3127\n",
      "\n",
      "Loss evaluation at time 68:\t3377.2728\n",
      "\n",
      "Loss evaluation at time 69:\t860.3649\n",
      "\n",
      "Loss evaluation at time 70:\t820.3875\n",
      "\n",
      "Loss evaluation at time 71:\t782.8619\n",
      "\n",
      "Loss evaluation at time 72:\t747.6033\n",
      "\n",
      "Loss evaluation at time 73:\t714.4433\n",
      "\n",
      "Loss evaluation at time 74:\t683.2284\n",
      "\n",
      "Loss evaluation at time 75:\t1099.9690\n",
      "\n",
      "Loss evaluation at time 76:\t2105.3808\n",
      "\n",
      "Loss evaluation at time 77:\t1097.9368\n",
      "\n",
      "Loss evaluation at time 78:\t2049.2861\n",
      "\n",
      "Loss evaluation at time 79:\t1998.7951\n",
      "\n",
      "Loss evaluation at time 80:\t1949.4723\n",
      "\n",
      "Loss evaluation at time 81:\t1901.3270\n",
      "\n",
      "Loss evaluation at time 82:\t1854.3618\n",
      "\n",
      "Loss evaluation at time 83:\t1808.5741\n",
      "\n",
      "Loss evaluation at time 84:\t1763.9568\n",
      "\n",
      "Loss evaluation at time 85:\t928.1291\n",
      "\n",
      "Loss evaluation at time 86:\t892.4916\n",
      "\n",
      "Loss evaluation at time 87:\t858.6663\n",
      "\n",
      "Loss evaluation at time 88:\t826.5396\n",
      "\n",
      "Loss evaluation at time 89:\t796.0064\n",
      "\n",
      "Loss evaluation at time 90:\t766.9691\n",
      "\n",
      "Loss evaluation at time 91:\t739.3373\n",
      "\n",
      "Loss evaluation at time 92:\t713.0269\n",
      "\n",
      "Loss evaluation at time 93:\t687.9600\n",
      "\n",
      "Loss evaluation at time 94:\t664.0639\n",
      "\n",
      "Loss evaluation at time 95:\t641.2710\n",
      "\n",
      "Loss evaluation at time 96:\t619.5183\n",
      "\n",
      "Loss evaluation at time 97:\t598.7470\n",
      "\n",
      "Loss evaluation at time 98:\t578.9023\n",
      "\n",
      "Loss evaluation at time 99:\t559.9330\n",
      "\n",
      "Loss evaluation at time 100:\t541.7913\n",
      "\n",
      "Loss evaluation at time 101:\t524.4325\n",
      "\n",
      "Loss evaluation at time 102:\t507.8146\n",
      "\n",
      "Loss evaluation at time 103:\t491.8984\n",
      "\n",
      "Loss evaluation at time 104:\t476.6472\n",
      "\n",
      "Loss evaluation at time 105:\t462.0264\n",
      "\n",
      "Loss evaluation at time 106:\t448.0038\n",
      "\n",
      "Loss evaluation at time 107:\t434.5489\n",
      "\n",
      "Loss evaluation at time 108:\t421.6332\n",
      "\n",
      "Loss evaluation at time 109:\t409.2298\n",
      "\n",
      "Loss evaluation at time 110:\t397.3134\n",
      "\n",
      "Loss evaluation at time 111:\t385.8604\n",
      "\n",
      "Loss evaluation at time 112:\t374.8482\n",
      "\n",
      "Loss evaluation at time 113:\t364.2558\n",
      "\n",
      "Loss evaluation at time 114:\t354.0633\n",
      "\n",
      "Loss evaluation at time 115:\t344.2518\n",
      "\n",
      "Loss evaluation at time 116:\t334.8037\n",
      "\n",
      "Loss evaluation at time 117:\t325.7021\n",
      "\n",
      "Loss evaluation at time 118:\t316.9313\n",
      "\n",
      "Loss evaluation at time 119:\t308.4763\n",
      "\n",
      "Loss evaluation at time 120:\t300.3229\n",
      "\n",
      "Loss evaluation at time 121:\t606.3652\n",
      "\n",
      "Loss evaluation at time 122:\t590.4356\n",
      "\n",
      "Loss evaluation at time 123:\t269.5644\n",
      "\n",
      "Loss evaluation at time 124:\t566.5879\n",
      "\n",
      "Loss evaluation at time 125:\t252.1124\n",
      "\n",
      "Loss evaluation at time 126:\t544.1897\n",
      "\n",
      "Loss evaluation at time 127:\t530.4601\n",
      "\n",
      "Loss evaluation at time 128:\t517.1939\n",
      "\n",
      "Loss evaluation at time 129:\t504.3714\n",
      "\n",
      "Loss evaluation at time 130:\t491.9743\n",
      "\n",
      "Loss evaluation at time 131:\t479.9848\n",
      "\n",
      "Loss evaluation at time 132:\t468.3864\n",
      "\n",
      "Loss evaluation at time 133:\t457.1631\n",
      "\n",
      "Loss evaluation at time 134:\t446.2998\n",
      "\n",
      "Loss evaluation at time 135:\t435.7820\n",
      "\n",
      "Loss evaluation at time 136:\t425.5960\n",
      "\n",
      "Loss evaluation at time 137:\t415.7288\n",
      "\n",
      "Loss evaluation at time 138:\t406.1680\n",
      "\n",
      "Loss evaluation at time 139:\t396.9016\n",
      "\n",
      "Loss evaluation at time 140:\t387.9183\n",
      "\n",
      "Loss evaluation at time 141:\t379.2073\n",
      "\n",
      "Loss evaluation at time 142:\t370.7584\n",
      "\n",
      "Loss evaluation at time 143:\t362.5616\n",
      "\n",
      "Loss evaluation at time 144:\t354.6076\n",
      "\n",
      "Loss evaluation at time 145:\t346.8873\n",
      "\n",
      "Loss evaluation at time 146:\t339.3923\n",
      "\n",
      "Loss evaluation at time 147:\t332.1142\n",
      "\n",
      "Loss evaluation at time 148:\t325.0453\n",
      "\n",
      "Loss evaluation at time 149:\t318.1779\n",
      "\n",
      "Loss evaluation at time 150:\t311.5050\n",
      "\n",
      "Loss evaluation at time 151:\t305.0197\n",
      "\n",
      "Loss evaluation at time 152:\t298.7153\n",
      "\n",
      "Loss evaluation at time 153:\t292.5855\n",
      "\n",
      "Loss evaluation at time 154:\t286.6243\n",
      "\n",
      "Loss evaluation at time 155:\t280.8259\n",
      "\n",
      "Loss evaluation at time 156:\t275.1848\n",
      "\n",
      "Loss evaluation at time 157:\t269.6955\n",
      "\n",
      "Loss evaluation at time 158:\t264.3530\n",
      "\n",
      "Loss evaluation at time 159:\t259.1524\n",
      "\n",
      "Loss evaluation at time 160:\t254.0889\n",
      "\n",
      "Loss evaluation at time 161:\t249.1580\n",
      "\n",
      "Loss evaluation at time 162:\t244.3554\n",
      "\n",
      "Loss evaluation at time 163:\t239.6769\n",
      "\n",
      "Loss evaluation at time 164:\t235.1185\n",
      "\n",
      "Loss evaluation at time 165:\t230.6764\n",
      "\n",
      "Loss evaluation at time 166:\t226.3467\n",
      "\n",
      "Loss evaluation at time 167:\t222.1260\n",
      "\n",
      "Loss evaluation at time 168:\t218.0108\n",
      "\n",
      "Loss evaluation at time 169:\t213.9978\n",
      "\n",
      "Loss evaluation at time 170:\t210.0839\n",
      "\n",
      "Loss evaluation at time 171:\t206.2659\n",
      "\n",
      "Loss evaluation at time 172:\t202.5410\n",
      "\n",
      "Loss evaluation at time 173:\t198.9062\n",
      "\n",
      "Loss evaluation at time 174:\t195.3589\n",
      "\n",
      "Loss evaluation at time 175:\t191.8964\n",
      "\n",
      "Loss evaluation at time 176:\t188.5162\n",
      "\n",
      "Loss evaluation at time 177:\t185.2158\n",
      "\n",
      "Loss evaluation at time 178:\t181.9929\n",
      "\n",
      "Loss evaluation at time 179:\t178.8451\n",
      "\n",
      "Loss evaluation at time 180:\t175.7704\n",
      "\n",
      "Loss evaluation at time 181:\t172.7665\n",
      "\n",
      "Loss evaluation at time 182:\t169.8314\n",
      "\n",
      "Loss evaluation at time 183:\t166.9632\n",
      "\n",
      "Loss evaluation at time 184:\t164.1600\n",
      "\n",
      "Loss evaluation at time 185:\t161.4198\n",
      "\n",
      "Loss evaluation at time 186:\t158.7409\n",
      "\n",
      "Loss evaluation at time 187:\t156.1217\n",
      "\n",
      "Loss evaluation at time 188:\t153.5604\n",
      "\n",
      "Loss evaluation at time 189:\t151.0554\n",
      "\n",
      "Loss evaluation at time 190:\t148.6052\n",
      "\n",
      "Loss evaluation at time 191:\t146.2083\n",
      "\n",
      "Loss evaluation at time 192:\t143.8632\n",
      "\n",
      "Loss evaluation at time 193:\t141.5685\n",
      "\n",
      "Loss evaluation at time 194:\t16.7779\n",
      "\n",
      "Loss evaluation at time 195:\t138.9859\n",
      "\n",
      "Loss evaluation at time 196:\t136.8008\n",
      "\n",
      "Loss evaluation at time 197:\t134.6619\n",
      "\n",
      "Loss evaluation at time 198:\t20.2773\n",
      "\n",
      "Loss evaluation at time 199:\t132.3024\n",
      "\n",
      "Loss evaluation at time 200:\t130.2628\n",
      "\n",
      "Loss evaluation at time 201:\t128.2654\n",
      "\n",
      "Loss evaluation at time 202:\t126.3089\n",
      "\n",
      "Loss evaluation at time 203:\t124.3926\n",
      "\n",
      "Loss evaluation at time 204:\t122.5151\n",
      "\n",
      "Loss evaluation at time 205:\t26.0797\n",
      "\n",
      "Loss evaluation at time 206:\t120.5237\n",
      "\n",
      "Loss evaluation at time 207:\t118.7292\n",
      "\n",
      "Loss evaluation at time 208:\t116.9705\n",
      "\n",
      "Loss evaluation at time 209:\t115.2468\n",
      "\n",
      "Loss evaluation at time 210:\t113.5571\n",
      "\n",
      "Loss evaluation at time 211:\t30.1525\n",
      "\n",
      "Loss evaluation at time 212:\t30.2301\n",
      "\n",
      "Loss evaluation at time 213:\t30.2952\n",
      "\n",
      "Loss evaluation at time 214:\t111.6862\n",
      "\n",
      "Loss evaluation at time 215:\t110.0796\n",
      "\n",
      "Loss evaluation at time 216:\t108.5040\n",
      "\n",
      "Loss evaluation at time 217:\t32.3992\n",
      "\n",
      "Loss evaluation at time 218:\t32.4160\n",
      "\n",
      "Loss evaluation at time 219:\t32.4228\n",
      "\n",
      "Loss evaluation at time 220:\t32.4200\n",
      "\n",
      "Loss evaluation at time 221:\t32.4081\n",
      "\n",
      "Loss evaluation at time 222:\t32.3874\n",
      "\n",
      "Loss evaluation at time 223:\t32.3584\n",
      "\n",
      "Loss evaluation at time 224:\t32.3216\n",
      "\n",
      "Loss evaluation at time 225:\t32.2773\n",
      "\n",
      "Loss evaluation at time 226:\t32.2258\n",
      "\n",
      "Loss evaluation at time 227:\t32.1675\n",
      "\n",
      "Loss evaluation at time 228:\t32.1028\n",
      "\n",
      "Loss evaluation at time 229:\t32.0320\n",
      "\n",
      "Loss evaluation at time 230:\t31.9553\n",
      "\n",
      "Loss evaluation at time 231:\t31.8732\n",
      "\n",
      "Loss evaluation at time 232:\t31.7858\n",
      "\n",
      "Loss evaluation at time 233:\t106.6559\n",
      "\n",
      "Loss evaluation at time 234:\t105.2086\n",
      "\n",
      "Loss evaluation at time 235:\t103.7876\n",
      "\n",
      "Loss evaluation at time 236:\t102.3924\n",
      "\n",
      "Loss evaluation at time 237:\t101.0224\n",
      "\n",
      "Loss evaluation at time 238:\t99.6771\n",
      "\n",
      "Loss evaluation at time 239:\t98.3558\n",
      "\n",
      "Loss evaluation at time 240:\t97.0580\n",
      "\n",
      "Loss evaluation at time 241:\t95.7833\n",
      "\n",
      "Loss evaluation at time 242:\t94.5310\n",
      "\n",
      "Loss evaluation at time 243:\t93.3007\n",
      "\n",
      "Loss evaluation at time 244:\t92.0919\n",
      "\n",
      "Loss evaluation at time 245:\t90.9042\n",
      "\n",
      "Loss evaluation at time 246:\t89.7370\n",
      "\n",
      "Loss evaluation at time 247:\t88.5900\n",
      "\n",
      "Loss evaluation at time 248:\t87.4627\n",
      "\n",
      "Loss evaluation at time 249:\t39.4059\n",
      "\n",
      "Loss evaluation at time 250:\t39.2442\n",
      "\n",
      "Loss evaluation at time 251:\t39.0794\n",
      "\n",
      "Loss evaluation at time 252:\t38.9115\n",
      "\n",
      "Loss evaluation at time 253:\t38.7408\n",
      "\n",
      "Loss evaluation at time 254:\t86.8870\n",
      "\n",
      "Loss evaluation at time 255:\t38.9431\n",
      "\n",
      "Loss evaluation at time 256:\t38.7647\n",
      "\n",
      "Loss evaluation at time 257:\t38.5842\n",
      "\n",
      "Loss evaluation at time 258:\t38.4015\n",
      "\n",
      "Loss evaluation at time 259:\t38.2168\n",
      "\n",
      "Loss evaluation at time 260:\t38.0303\n",
      "\n",
      "Loss evaluation at time 261:\t37.8422\n",
      "\n",
      "Loss evaluation at time 262:\t37.6524\n",
      "\n",
      "Loss evaluation at time 263:\t37.4613\n",
      "\n",
      "Loss evaluation at time 264:\t37.2688\n",
      "\n",
      "Loss evaluation at time 265:\t37.0751\n",
      "\n",
      "Loss evaluation at time 266:\t36.8804\n",
      "\n",
      "Loss evaluation at time 267:\t36.6846\n",
      "\n",
      "Loss evaluation at time 268:\t36.4880\n",
      "\n",
      "Loss evaluation at time 269:\t36.2906\n",
      "\n",
      "Loss evaluation at time 270:\t36.0924\n",
      "\n",
      "Loss evaluation at time 271:\t35.8937\n",
      "\n",
      "Loss evaluation at time 272:\t35.6945\n",
      "\n",
      "Loss evaluation at time 273:\t35.4948\n",
      "\n",
      "Loss evaluation at time 274:\t35.2947\n",
      "\n",
      "Loss evaluation at time 275:\t35.0944\n",
      "\n",
      "Loss evaluation at time 276:\t34.8938\n",
      "\n",
      "Loss evaluation at time 277:\t34.6930\n",
      "\n",
      "Loss evaluation at time 278:\t34.4922\n",
      "\n",
      "Loss evaluation at time 279:\t34.2914\n",
      "\n",
      "Loss evaluation at time 280:\t34.0906\n",
      "\n",
      "Loss evaluation at time 281:\t87.9717\n",
      "\n",
      "Loss evaluation at time 282:\t34.2541\n",
      "\n",
      "Loss evaluation at time 283:\t87.0029\n",
      "\n",
      "Loss evaluation at time 284:\t85.9904\n",
      "\n",
      "Loss evaluation at time 285:\t34.7532\n",
      "\n",
      "Loss evaluation at time 286:\t85.0635\n",
      "\n",
      "Loss evaluation at time 287:\t84.0837\n",
      "\n",
      "Loss evaluation at time 288:\t83.1191\n",
      "\n",
      "Loss evaluation at time 289:\t82.1694\n",
      "\n",
      "Loss evaluation at time 290:\t81.2343\n",
      "\n",
      "Loss evaluation at time 291:\t80.3134\n",
      "\n",
      "Loss evaluation at time 292:\t36.4524\n",
      "\n",
      "Loss evaluation at time 293:\t36.2386\n",
      "\n",
      "Loss evaluation at time 294:\t79.5942\n",
      "\n",
      "Loss evaluation at time 295:\t78.7029\n",
      "\n",
      "Loss evaluation at time 296:\t77.8249\n",
      "\n",
      "Loss evaluation at time 297:\t36.8769\n",
      "\n",
      "Loss evaluation at time 298:\t36.6608\n",
      "\n",
      "Loss evaluation at time 299:\t77.1627\n",
      "\n",
      "Loss evaluation at time 300:\t76.3121\n",
      "\n",
      "Loss evaluation at time 301:\t75.4741\n",
      "\n",
      "Loss evaluation at time 302:\t74.6485\n",
      "\n",
      "Loss evaluation at time 303:\t73.8351\n",
      "\n",
      "Loss evaluation at time 304:\t73.0335\n",
      "\n",
      "Loss evaluation at time 305:\t72.2437\n",
      "\n",
      "Loss evaluation at time 306:\t71.4653\n",
      "\n",
      "Loss evaluation at time 307:\t70.6982\n",
      "\n",
      "Loss evaluation at time 308:\t69.9422\n",
      "\n",
      "Loss evaluation at time 309:\t69.1970\n",
      "\n",
      "Loss evaluation at time 310:\t68.4626\n",
      "\n",
      "Loss evaluation at time 311:\t67.7386\n",
      "\n",
      "Loss evaluation at time 312:\t67.0249\n",
      "\n",
      "Loss evaluation at time 313:\t66.3213\n",
      "\n",
      "Loss evaluation at time 314:\t65.6276\n",
      "\n",
      "Loss evaluation at time 315:\t64.9438\n",
      "\n",
      "Loss evaluation at time 316:\t64.2695\n",
      "\n",
      "Loss evaluation at time 317:\t63.6046\n",
      "\n",
      "Loss evaluation at time 318:\t62.9489\n",
      "\n",
      "Loss evaluation at time 319:\t62.3024\n",
      "\n",
      "Loss evaluation at time 320:\t61.6648\n",
      "\n",
      "Loss evaluation at time 321:\t61.0359\n",
      "\n",
      "Loss evaluation at time 322:\t60.4157\n",
      "\n",
      "Loss evaluation at time 323:\t59.8040\n",
      "\n",
      "Loss evaluation at time 324:\t59.2006\n",
      "\n",
      "Loss evaluation at time 325:\t58.6054\n",
      "\n",
      "Loss evaluation at time 326:\t58.0182\n",
      "\n",
      "Loss evaluation at time 327:\t57.4390\n",
      "\n",
      "Loss evaluation at time 328:\t56.8675\n",
      "\n",
      "Loss evaluation at time 329:\t56.3037\n",
      "\n",
      "Loss evaluation at time 330:\t55.7474\n",
      "\n",
      "Loss evaluation at time 331:\t55.1985\n",
      "\n",
      "Loss evaluation at time 332:\t54.6568\n",
      "\n",
      "Loss evaluation at time 333:\t54.1224\n",
      "\n",
      "Loss evaluation at time 334:\t53.5949\n",
      "\n",
      "Loss evaluation at time 335:\t53.0744\n",
      "\n",
      "Loss evaluation at time 336:\t52.5606\n",
      "\n",
      "Loss evaluation at time 337:\t52.0536\n",
      "\n",
      "Loss evaluation at time 338:\t51.5531\n",
      "\n",
      "Loss evaluation at time 339:\t51.0592\n",
      "\n",
      "Loss evaluation at time 340:\t50.5715\n",
      "\n",
      "Loss evaluation at time 341:\t50.0902\n",
      "\n",
      "Loss evaluation at time 342:\t49.6150\n",
      "\n",
      "Loss evaluation at time 343:\t49.1459\n",
      "\n",
      "Loss evaluation at time 344:\t48.6827\n",
      "\n",
      "Loss evaluation at time 345:\t48.2254\n",
      "\n",
      "Loss evaluation at time 346:\t47.7739\n",
      "\n",
      "Loss evaluation at time 347:\t47.3281\n",
      "\n",
      "Loss evaluation at time 348:\t43.8731\n",
      "\n",
      "Loss evaluation at time 349:\t43.6559\n",
      "\n",
      "Loss evaluation at time 350:\t43.4390\n",
      "\n",
      "Loss evaluation at time 351:\t43.2225\n",
      "\n",
      "Loss evaluation at time 352:\t43.0063\n",
      "\n",
      "Loss evaluation at time 353:\t42.7906\n",
      "\n",
      "Loss evaluation at time 354:\t42.5753\n",
      "\n",
      "Loss evaluation at time 355:\t42.3605\n",
      "\n",
      "Loss evaluation at time 356:\t42.1461\n",
      "\n",
      "Loss evaluation at time 357:\t41.9323\n",
      "\n",
      "Loss evaluation at time 358:\t41.7190\n",
      "\n",
      "Loss evaluation at time 359:\t41.5062\n",
      "\n",
      "Loss evaluation at time 360:\t41.2940\n",
      "\n",
      "Loss evaluation at time 361:\t41.0825\n",
      "\n",
      "Loss evaluation at time 362:\t40.8715\n",
      "\n",
      "Loss evaluation at time 363:\t40.6612\n",
      "\n",
      "Loss evaluation at time 364:\t40.4515\n",
      "\n",
      "Loss evaluation at time 365:\t40.2425\n",
      "\n",
      "Loss evaluation at time 366:\t40.0342\n",
      "\n",
      "Loss evaluation at time 367:\t39.8266\n",
      "\n",
      "Loss evaluation at time 368:\t39.6197\n",
      "\n",
      "Loss evaluation at time 369:\t39.4135\n",
      "\n",
      "Loss evaluation at time 370:\t39.2081\n",
      "\n",
      "Loss evaluation at time 371:\t39.0034\n",
      "\n",
      "Loss evaluation at time 372:\t38.7995\n",
      "\n",
      "Loss evaluation at time 373:\t51.0482\n",
      "\n",
      "Loss evaluation at time 374:\t50.5928\n",
      "\n",
      "Loss evaluation at time 375:\t50.1429\n",
      "\n",
      "Loss evaluation at time 376:\t49.6984\n",
      "\n",
      "Loss evaluation at time 377:\t49.2592\n",
      "\n",
      "Loss evaluation at time 378:\t48.8251\n",
      "\n",
      "Loss evaluation at time 379:\t48.3963\n",
      "\n",
      "Loss evaluation at time 380:\t47.9725\n",
      "\n",
      "Loss evaluation at time 381:\t47.5537\n",
      "\n",
      "Loss evaluation at time 382:\t47.1398\n",
      "\n",
      "Loss evaluation at time 383:\t46.7307\n",
      "\n",
      "Loss evaluation at time 384:\t46.3265\n",
      "\n",
      "Loss evaluation at time 385:\t45.9269\n",
      "\n",
      "Loss evaluation at time 386:\t45.5320\n",
      "\n",
      "Loss evaluation at time 387:\t45.1416\n",
      "\n",
      "Loss evaluation at time 388:\t44.7558\n",
      "\n",
      "Loss evaluation at time 389:\t44.3744\n",
      "\n",
      "Loss evaluation at time 390:\t43.9973\n",
      "\n",
      "Loss evaluation at time 391:\t43.6246\n",
      "\n",
      "Loss evaluation at time 392:\t43.2561\n",
      "\n",
      "Loss evaluation at time 393:\t42.8918\n",
      "\n",
      "Loss evaluation at time 394:\t42.5317\n",
      "\n",
      "Loss evaluation at time 395:\t42.1756\n",
      "\n",
      "Loss evaluation at time 396:\t41.8235\n",
      "\n",
      "Loss evaluation at time 397:\t41.4754\n",
      "\n",
      "Loss evaluation at time 398:\t41.1312\n",
      "\n",
      "Loss evaluation at time 399:\t40.7908\n",
      "\n",
      "Loss evaluation at time 400:\t40.4542\n",
      "\n",
      "Loss evaluation at time 401:\t40.1214\n",
      "\n",
      "Loss evaluation at time 402:\t39.7922\n",
      "\n",
      "Loss evaluation at time 403:\t39.4667\n",
      "\n",
      "Loss evaluation at time 404:\t39.1447\n",
      "\n",
      "Loss evaluation at time 405:\t38.8263\n",
      "\n",
      "Loss evaluation at time 406:\t38.5114\n",
      "\n",
      "Loss evaluation at time 407:\t38.1999\n",
      "\n",
      "Loss evaluation at time 408:\t37.8918\n",
      "\n",
      "Loss evaluation at time 409:\t37.5871\n",
      "\n",
      "Loss evaluation at time 410:\t37.2856\n",
      "\n",
      "Loss evaluation at time 411:\t36.9874\n",
      "\n",
      "Loss evaluation at time 412:\t36.6925\n",
      "\n",
      "Loss evaluation at time 413:\t36.4006\n",
      "\n",
      "Loss evaluation at time 414:\t36.1120\n",
      "\n",
      "Loss evaluation at time 415:\t35.8263\n",
      "\n",
      "Loss evaluation at time 416:\t35.5438\n",
      "\n",
      "Loss evaluation at time 417:\t35.2642\n",
      "\n",
      "Loss evaluation at time 418:\t34.9876\n",
      "\n",
      "Loss evaluation at time 419:\t34.7139\n",
      "\n",
      "Loss evaluation at time 420:\t34.4431\n",
      "\n",
      "Loss evaluation at time 421:\t34.1752\n",
      "\n",
      "Loss evaluation at time 422:\t33.9100\n",
      "\n",
      "Loss evaluation at time 423:\t33.6476\n",
      "\n",
      "Loss evaluation at time 424:\t33.3880\n",
      "\n",
      "Loss evaluation at time 425:\t33.1310\n",
      "\n",
      "Loss evaluation at time 426:\t40.9100\n",
      "\n",
      "Loss evaluation at time 427:\t33.0400\n",
      "\n",
      "Loss evaluation at time 428:\t32.7874\n",
      "\n",
      "Loss evaluation at time 429:\t32.5374\n",
      "\n",
      "Loss evaluation at time 430:\t32.2899\n",
      "\n",
      "Loss evaluation at time 431:\t32.0450\n",
      "\n",
      "Loss evaluation at time 432:\t31.8026\n",
      "\n",
      "Loss evaluation at time 433:\t31.5627\n",
      "\n",
      "Loss evaluation at time 434:\t31.3252\n",
      "\n",
      "Loss evaluation at time 435:\t31.0901\n",
      "\n",
      "Loss evaluation at time 436:\t30.8573\n",
      "\n",
      "Loss evaluation at time 437:\t30.6270\n",
      "\n",
      "Loss evaluation at time 438:\t40.7653\n",
      "\n",
      "Loss evaluation at time 439:\t40.5956\n",
      "\n",
      "Loss evaluation at time 440:\t30.7206\n",
      "\n",
      "Loss evaluation at time 441:\t30.4929\n",
      "\n",
      "Loss evaluation at time 442:\t30.2675\n",
      "\n",
      "Loss evaluation at time 443:\t40.4230\n",
      "\n",
      "Loss evaluation at time 444:\t40.2557\n",
      "\n",
      "Loss evaluation at time 445:\t40.0888\n",
      "\n",
      "Loss evaluation at time 446:\t39.9223\n",
      "\n",
      "Loss evaluation at time 447:\t39.7561\n",
      "\n",
      "Loss evaluation at time 448:\t39.5904\n",
      "\n",
      "Loss evaluation at time 449:\t39.4251\n",
      "\n",
      "Loss evaluation at time 450:\t39.2601\n",
      "\n",
      "Loss evaluation at time 451:\t39.0956\n",
      "\n",
      "Loss evaluation at time 452:\t38.9316\n",
      "\n",
      "Loss evaluation at time 453:\t38.7680\n",
      "\n",
      "Loss evaluation at time 454:\t31.7185\n",
      "\n",
      "Loss evaluation at time 455:\t31.4881\n",
      "\n",
      "Loss evaluation at time 456:\t31.2600\n",
      "\n",
      "Loss evaluation at time 457:\t31.0341\n",
      "\n",
      "Loss evaluation at time 458:\t30.8104\n",
      "\n",
      "Loss evaluation at time 459:\t30.5889\n",
      "\n",
      "Loss evaluation at time 460:\t30.3695\n",
      "\n",
      "Loss evaluation at time 461:\t30.1522\n",
      "\n",
      "Loss evaluation at time 462:\t29.9371\n",
      "\n",
      "Loss evaluation at time 463:\t29.7240\n",
      "\n",
      "Loss evaluation at time 464:\t29.5129\n",
      "\n",
      "Loss evaluation at time 465:\t29.3039\n",
      "\n",
      "Loss evaluation at time 466:\t29.0968\n",
      "\n",
      "Loss evaluation at time 467:\t28.8918\n",
      "\n",
      "Loss evaluation at time 468:\t28.6886\n",
      "\n",
      "Loss evaluation at time 469:\t28.4874\n",
      "\n",
      "Loss evaluation at time 470:\t28.2881\n",
      "\n",
      "Loss evaluation at time 471:\t28.0907\n",
      "\n",
      "Loss evaluation at time 472:\t27.8951\n",
      "\n",
      "Loss evaluation at time 473:\t27.7014\n",
      "\n",
      "Loss evaluation at time 474:\t27.5095\n",
      "\n",
      "Loss evaluation at time 475:\t27.3193\n",
      "\n",
      "Loss evaluation at time 476:\t27.1310\n",
      "\n",
      "Loss evaluation at time 477:\t26.9443\n",
      "\n",
      "Loss evaluation at time 478:\t26.7595\n",
      "\n",
      "Loss evaluation at time 479:\t26.5763\n",
      "\n",
      "Loss evaluation at time 480:\t26.3948\n",
      "\n",
      "Loss evaluation at time 481:\t26.2150\n",
      "\n",
      "Loss evaluation at time 482:\t26.0368\n",
      "\n",
      "Loss evaluation at time 483:\t25.8603\n",
      "\n",
      "Loss evaluation at time 484:\t25.6853\n",
      "\n",
      "Loss evaluation at time 485:\t25.5120\n",
      "\n",
      "Loss evaluation at time 486:\t25.3402\n",
      "\n",
      "Loss evaluation at time 487:\t25.1700\n",
      "\n",
      "Loss evaluation at time 488:\t25.0014\n",
      "\n",
      "Loss evaluation at time 489:\t24.8342\n",
      "\n",
      "Loss evaluation at time 490:\t24.6686\n",
      "\n",
      "Loss evaluation at time 491:\t24.5045\n",
      "\n",
      "Loss evaluation at time 492:\t24.3418\n",
      "\n",
      "Loss evaluation at time 493:\t24.1806\n",
      "\n",
      "Loss evaluation at time 494:\t24.0208\n",
      "\n",
      "Loss evaluation at time 495:\t23.8624\n",
      "\n",
      "Loss evaluation at time 496:\t23.7055\n",
      "\n",
      "Loss evaluation at time 497:\t23.5499\n",
      "\n",
      "Loss evaluation at time 498:\t23.3957\n",
      "\n",
      "Loss evaluation at time 499:\t23.2429\n",
      "\n",
      "Loss evaluation at time 500:\t23.0914\n",
      "\n",
      "Loss evaluation at time 501:\t22.9412\n",
      "\n",
      "Loss evaluation at time 502:\t22.7924\n",
      "\n",
      "Loss evaluation at time 503:\t22.6449\n",
      "\n",
      "Loss evaluation at time 504:\t22.4986\n",
      "\n",
      "Loss evaluation at time 505:\t22.3536\n",
      "\n",
      "Loss evaluation at time 506:\t22.2099\n",
      "\n",
      "Loss evaluation at time 507:\t22.0674\n",
      "\n",
      "Loss evaluation at time 508:\t21.9262\n",
      "\n",
      "Loss evaluation at time 509:\t21.7861\n",
      "\n",
      "Loss evaluation at time 510:\t21.6473\n",
      "\n",
      "Loss evaluation at time 511:\t21.5097\n",
      "\n",
      "Loss evaluation at time 512:\t21.3732\n",
      "\n",
      "Loss evaluation at time 513:\t21.2379\n",
      "\n",
      "Loss evaluation at time 514:\t21.1038\n",
      "\n",
      "Loss evaluation at time 515:\t20.9708\n",
      "\n",
      "Loss evaluation at time 516:\t20.8390\n",
      "\n",
      "Loss evaluation at time 517:\t20.7082\n",
      "\n",
      "Loss evaluation at time 518:\t20.5786\n",
      "\n",
      "Loss evaluation at time 519:\t20.4500\n",
      "\n",
      "Loss evaluation at time 520:\t20.3225\n",
      "\n",
      "Loss evaluation at time 521:\t20.1961\n",
      "\n",
      "Loss evaluation at time 522:\t20.0708\n",
      "\n",
      "Loss evaluation at time 523:\t19.9465\n",
      "\n",
      "Loss evaluation at time 524:\t19.8233\n",
      "\n",
      "Loss evaluation at time 525:\t19.7010\n",
      "\n",
      "Loss evaluation at time 526:\t37.6686\n",
      "\n",
      "Loss evaluation at time 527:\t37.5415\n",
      "\n",
      "Loss evaluation at time 528:\t37.4145\n",
      "\n",
      "Loss evaluation at time 529:\t37.2877\n",
      "\n",
      "Loss evaluation at time 530:\t20.1098\n",
      "\n",
      "Loss evaluation at time 531:\t37.1369\n",
      "\n",
      "Loss evaluation at time 532:\t37.0109\n",
      "\n",
      "Loss evaluation at time 533:\t20.2464\n",
      "\n",
      "Loss evaluation at time 534:\t20.1229\n",
      "\n",
      "Loss evaluation at time 535:\t20.0005\n",
      "\n",
      "Loss evaluation at time 536:\t19.8791\n",
      "\n",
      "Loss evaluation at time 537:\t19.7587\n",
      "\n",
      "Loss evaluation at time 538:\t19.6392\n",
      "\n",
      "Loss evaluation at time 539:\t19.5208\n",
      "\n",
      "Loss evaluation at time 540:\t19.4032\n",
      "\n",
      "Loss evaluation at time 541:\t19.2867\n",
      "\n",
      "Loss evaluation at time 542:\t19.1711\n",
      "\n",
      "Loss evaluation at time 543:\t19.0564\n",
      "\n",
      "Loss evaluation at time 544:\t18.9426\n",
      "\n",
      "Loss evaluation at time 545:\t18.8298\n",
      "\n",
      "Loss evaluation at time 546:\t18.7179\n",
      "\n",
      "Loss evaluation at time 547:\t18.6068\n",
      "\n",
      "Loss evaluation at time 548:\t18.4967\n",
      "\n",
      "Loss evaluation at time 549:\t18.3874\n",
      "\n",
      "Loss evaluation at time 550:\t18.2790\n",
      "\n",
      "Loss evaluation at time 551:\t18.1715\n",
      "\n",
      "Loss evaluation at time 552:\t18.0648\n",
      "\n",
      "Loss evaluation at time 553:\t17.9589\n",
      "\n",
      "Loss evaluation at time 554:\t17.8539\n",
      "\n",
      "Loss evaluation at time 555:\t17.7497\n",
      "\n",
      "Loss evaluation at time 556:\t17.6464\n",
      "\n",
      "Loss evaluation at time 557:\t17.5438\n",
      "\n",
      "Loss evaluation at time 558:\t17.4421\n",
      "\n",
      "Loss evaluation at time 559:\t17.3411\n",
      "\n",
      "Loss evaluation at time 560:\t17.2409\n",
      "\n",
      "Loss evaluation at time 561:\t17.1415\n",
      "\n",
      "Loss evaluation at time 562:\t17.0429\n",
      "\n",
      "Loss evaluation at time 563:\t16.9451\n",
      "\n",
      "Loss evaluation at time 564:\t16.8480\n",
      "\n",
      "Loss evaluation at time 565:\t16.7516\n",
      "\n",
      "Loss evaluation at time 566:\t16.6560\n",
      "\n",
      "Loss evaluation at time 567:\t16.5612\n",
      "\n",
      "Loss evaluation at time 568:\t16.4670\n",
      "\n",
      "Loss evaluation at time 569:\t16.3736\n",
      "\n",
      "Loss evaluation at time 570:\t16.2809\n",
      "\n",
      "Loss evaluation at time 571:\t16.1889\n",
      "\n",
      "Loss evaluation at time 572:\t16.0976\n",
      "\n",
      "Loss evaluation at time 573:\t16.0070\n",
      "\n",
      "Loss evaluation at time 574:\t15.9170\n",
      "\n",
      "Loss evaluation at time 575:\t15.8278\n",
      "\n",
      "Loss evaluation at time 576:\t15.7392\n",
      "\n",
      "Loss evaluation at time 577:\t15.6513\n",
      "\n",
      "Loss evaluation at time 578:\t15.5641\n",
      "\n",
      "Loss evaluation at time 579:\t15.4775\n",
      "\n",
      "Loss evaluation at time 580:\t15.3916\n",
      "\n",
      "Loss evaluation at time 581:\t15.3063\n",
      "\n",
      "Loss evaluation at time 582:\t15.2216\n",
      "\n",
      "Loss evaluation at time 583:\t15.1376\n",
      "\n",
      "Loss evaluation at time 584:\t15.0542\n",
      "\n",
      "Loss evaluation at time 585:\t14.9714\n",
      "\n",
      "Loss evaluation at time 586:\t14.8893\n",
      "\n",
      "Loss evaluation at time 587:\t14.8077\n",
      "\n",
      "Loss evaluation at time 588:\t14.7267\n",
      "\n",
      "Loss evaluation at time 589:\t14.6464\n",
      "\n",
      "Loss evaluation at time 590:\t14.5666\n",
      "\n",
      "Loss evaluation at time 591:\t14.4874\n",
      "\n",
      "Loss evaluation at time 592:\t14.4088\n",
      "\n",
      "Loss evaluation at time 593:\t14.3308\n",
      "\n",
      "Loss evaluation at time 594:\t14.2533\n",
      "\n",
      "Loss evaluation at time 595:\t14.1764\n",
      "\n",
      "Loss evaluation at time 596:\t14.1001\n",
      "\n",
      "Loss evaluation at time 597:\t14.0243\n",
      "\n",
      "Loss evaluation at time 598:\t13.9491\n",
      "\n",
      "Loss evaluation at time 599:\t13.8744\n",
      "\n",
      "Loss evaluation at time 600:\t13.8002\n",
      "\n",
      "Loss evaluation at time 601:\t13.7266\n",
      "\n",
      "Loss evaluation at time 602:\t13.6535\n",
      "\n",
      "Loss evaluation at time 603:\t13.5809\n",
      "\n",
      "Loss evaluation at time 604:\t13.5089\n",
      "\n",
      "Loss evaluation at time 605:\t13.4373\n",
      "\n",
      "Loss evaluation at time 606:\t13.3663\n",
      "\n",
      "Loss evaluation at time 607:\t13.2958\n",
      "\n",
      "Loss evaluation at time 608:\t13.2258\n",
      "\n",
      "Loss evaluation at time 609:\t13.1562\n",
      "\n",
      "Loss evaluation at time 610:\t13.0872\n",
      "\n",
      "Loss evaluation at time 611:\t13.0187\n",
      "\n",
      "Loss evaluation at time 612:\t12.9506\n",
      "\n",
      "Loss evaluation at time 613:\t12.8830\n",
      "\n",
      "Loss evaluation at time 614:\t12.8159\n",
      "\n",
      "Loss evaluation at time 615:\t12.7493\n",
      "\n",
      "Loss evaluation at time 616:\t12.6831\n",
      "\n",
      "Loss evaluation at time 617:\t12.6174\n",
      "\n",
      "Loss evaluation at time 618:\t12.5522\n",
      "\n",
      "Loss evaluation at time 619:\t12.4874\n",
      "\n",
      "Loss evaluation at time 620:\t12.4230\n",
      "\n",
      "Loss evaluation at time 621:\t12.3591\n",
      "\n",
      "Loss evaluation at time 622:\t12.2957\n",
      "\n",
      "Loss evaluation at time 623:\t12.2327\n",
      "\n",
      "Loss evaluation at time 624:\t12.1701\n",
      "\n",
      "Loss evaluation at time 625:\t12.1079\n",
      "\n",
      "Loss evaluation at time 626:\t12.0462\n",
      "\n",
      "Loss evaluation at time 627:\t11.9849\n",
      "\n",
      "Loss evaluation at time 628:\t11.9240\n",
      "\n",
      "Loss evaluation at time 629:\t11.8636\n",
      "\n",
      "Loss evaluation at time 630:\t11.8035\n",
      "\n",
      "Loss evaluation at time 631:\t11.7439\n",
      "\n",
      "Loss evaluation at time 632:\t11.6846\n",
      "\n",
      "Loss evaluation at time 633:\t11.6258\n",
      "\n",
      "Loss evaluation at time 634:\t11.5674\n",
      "\n",
      "Loss evaluation at time 635:\t11.5093\n",
      "\n",
      "Loss evaluation at time 636:\t11.4517\n",
      "\n",
      "Loss evaluation at time 637:\t11.3944\n",
      "\n",
      "Loss evaluation at time 638:\t11.3375\n",
      "\n",
      "Loss evaluation at time 639:\t11.2811\n",
      "\n",
      "Loss evaluation at time 640:\t11.2249\n",
      "\n",
      "Loss evaluation at time 641:\t11.1692\n",
      "\n",
      "Loss evaluation at time 642:\t11.1138\n",
      "\n",
      "Loss evaluation at time 643:\t11.0589\n",
      "\n",
      "Loss evaluation at time 644:\t11.0042\n",
      "\n",
      "Loss evaluation at time 645:\t10.9500\n",
      "\n",
      "Loss evaluation at time 646:\t10.8961\n",
      "\n",
      "Loss evaluation at time 647:\t10.8425\n",
      "\n",
      "Loss evaluation at time 648:\t10.7893\n",
      "\n",
      "Loss evaluation at time 649:\t10.7365\n",
      "\n",
      "Loss evaluation at time 650:\t10.6840\n",
      "\n",
      "Loss evaluation at time 651:\t10.6318\n",
      "\n",
      "Loss evaluation at time 652:\t10.5800\n",
      "\n",
      "Loss evaluation at time 653:\t10.5286\n",
      "\n",
      "Loss evaluation at time 654:\t10.4774\n",
      "\n",
      "Loss evaluation at time 655:\t10.4266\n",
      "\n",
      "Loss evaluation at time 656:\t10.3762\n",
      "\n",
      "Loss evaluation at time 657:\t10.3260\n",
      "\n",
      "Loss evaluation at time 658:\t10.2762\n",
      "\n",
      "Loss evaluation at time 659:\t10.2267\n",
      "\n",
      "Loss evaluation at time 660:\t10.1776\n",
      "\n",
      "Loss evaluation at time 661:\t10.1287\n",
      "\n",
      "Loss evaluation at time 662:\t10.0802\n",
      "\n",
      "Loss evaluation at time 663:\t10.0320\n",
      "\n",
      "Loss evaluation at time 664:\t9.9841\n",
      "\n",
      "Loss evaluation at time 665:\t9.9365\n",
      "\n",
      "Loss evaluation at time 666:\t9.8892\n",
      "\n",
      "Loss evaluation at time 667:\t9.8422\n",
      "\n",
      "Loss evaluation at time 668:\t9.7955\n",
      "\n",
      "Loss evaluation at time 669:\t9.7491\n",
      "\n",
      "Loss evaluation at time 670:\t9.7030\n",
      "\n",
      "Loss evaluation at time 671:\t32.6093\n",
      "\n",
      "Loss evaluation at time 672:\t9.7527\n",
      "\n",
      "Loss evaluation at time 673:\t9.7067\n",
      "\n",
      "Loss evaluation at time 674:\t9.6611\n",
      "\n",
      "Loss evaluation at time 675:\t9.6157\n",
      "\n",
      "Loss evaluation at time 676:\t9.5706\n",
      "\n",
      "Loss evaluation at time 677:\t9.5258\n",
      "\n",
      "Loss evaluation at time 678:\t9.4813\n",
      "\n",
      "Loss evaluation at time 679:\t9.4371\n",
      "\n",
      "Loss evaluation at time 680:\t9.3931\n",
      "\n",
      "Loss evaluation at time 681:\t9.3495\n",
      "\n",
      "Loss evaluation at time 682:\t9.3061\n",
      "\n",
      "Loss evaluation at time 683:\t9.2629\n",
      "\n",
      "Loss evaluation at time 684:\t9.2201\n",
      "\n",
      "Loss evaluation at time 685:\t9.1775\n",
      "\n",
      "Loss evaluation at time 686:\t9.1351\n",
      "\n",
      "Loss evaluation at time 687:\t9.0931\n",
      "\n",
      "Loss evaluation at time 688:\t9.0513\n",
      "\n",
      "Loss evaluation at time 689:\t9.0097\n",
      "\n",
      "Loss evaluation at time 690:\t8.9684\n",
      "\n",
      "Loss evaluation at time 691:\t8.9274\n",
      "\n",
      "Loss evaluation at time 692:\t8.8866\n",
      "\n",
      "Loss evaluation at time 693:\t8.8461\n",
      "\n",
      "Loss evaluation at time 694:\t8.8058\n",
      "\n",
      "Loss evaluation at time 695:\t8.7657\n",
      "\n",
      "Loss evaluation at time 696:\t8.7259\n",
      "\n",
      "Loss evaluation at time 697:\t8.6864\n",
      "\n",
      "Loss evaluation at time 698:\t8.6471\n",
      "\n",
      "Loss evaluation at time 699:\t8.6080\n",
      "\n",
      "Loss evaluation at time 700:\t8.5692\n",
      "\n",
      "Loss evaluation at time 701:\t8.5306\n",
      "\n",
      "Loss evaluation at time 702:\t8.4922\n",
      "\n",
      "Loss evaluation at time 703:\t8.4541\n",
      "\n",
      "Loss evaluation at time 704:\t8.4162\n",
      "\n",
      "Loss evaluation at time 705:\t8.3785\n",
      "\n",
      "Loss evaluation at time 706:\t8.3411\n",
      "\n",
      "Loss evaluation at time 707:\t8.3038\n",
      "\n",
      "Loss evaluation at time 708:\t8.2668\n",
      "\n",
      "Loss evaluation at time 709:\t8.2301\n",
      "\n",
      "Loss evaluation at time 710:\t8.1935\n",
      "\n",
      "Loss evaluation at time 711:\t8.1572\n",
      "\n",
      "Loss evaluation at time 712:\t8.1211\n",
      "\n",
      "Loss evaluation at time 713:\t8.0852\n",
      "\n",
      "Loss evaluation at time 714:\t8.0495\n",
      "\n",
      "Loss evaluation at time 715:\t8.0140\n",
      "\n",
      "Loss evaluation at time 716:\t7.9787\n",
      "\n",
      "Loss evaluation at time 717:\t7.9437\n",
      "\n",
      "Loss evaluation at time 718:\t7.9088\n",
      "\n",
      "Loss evaluation at time 719:\t7.8742\n",
      "\n",
      "Loss evaluation at time 720:\t7.8397\n",
      "\n",
      "Loss evaluation at time 721:\t7.8055\n",
      "\n",
      "Loss evaluation at time 722:\t7.7714\n",
      "\n",
      "Loss evaluation at time 723:\t7.7376\n",
      "\n",
      "Loss evaluation at time 724:\t7.7039\n",
      "\n",
      "Loss evaluation at time 725:\t7.6705\n",
      "\n",
      "Loss evaluation at time 726:\t7.6373\n",
      "\n",
      "Loss evaluation at time 727:\t7.6042\n",
      "\n",
      "Loss evaluation at time 728:\t7.5713\n",
      "\n",
      "Loss evaluation at time 729:\t7.5387\n",
      "\n",
      "Loss evaluation at time 730:\t7.5062\n",
      "\n",
      "Loss evaluation at time 731:\t7.4739\n",
      "\n",
      "Loss evaluation at time 732:\t7.4418\n",
      "\n",
      "Loss evaluation at time 733:\t7.4099\n",
      "\n",
      "Loss evaluation at time 734:\t7.3781\n",
      "\n",
      "Loss evaluation at time 735:\t7.3466\n",
      "\n",
      "Loss evaluation at time 736:\t7.3152\n",
      "\n",
      "Loss evaluation at time 737:\t7.2840\n",
      "\n",
      "Loss evaluation at time 738:\t7.2530\n",
      "\n",
      "Loss evaluation at time 739:\t7.2221\n",
      "\n",
      "Loss evaluation at time 740:\t7.1915\n",
      "\n",
      "Loss evaluation at time 741:\t7.1610\n",
      "\n",
      "Loss evaluation at time 742:\t7.1307\n",
      "\n",
      "Loss evaluation at time 743:\t7.1005\n",
      "\n",
      "Loss evaluation at time 744:\t7.0706\n",
      "\n",
      "Loss evaluation at time 745:\t7.0408\n",
      "\n",
      "Loss evaluation at time 746:\t7.0111\n",
      "\n",
      "Loss evaluation at time 747:\t6.9817\n",
      "\n",
      "Loss evaluation at time 748:\t6.9524\n",
      "\n",
      "Loss evaluation at time 749:\t6.9233\n",
      "\n",
      "Loss evaluation at time 750:\t6.8943\n",
      "\n",
      "Loss evaluation at time 751:\t6.8655\n",
      "\n",
      "Loss evaluation at time 752:\t6.8369\n",
      "\n",
      "Loss evaluation at time 753:\t6.8084\n",
      "\n",
      "Loss evaluation at time 754:\t6.7800\n",
      "\n",
      "Loss evaluation at time 755:\t6.7519\n",
      "\n",
      "Loss evaluation at time 756:\t6.7239\n",
      "\n",
      "Loss evaluation at time 757:\t6.6960\n",
      "\n",
      "Loss evaluation at time 758:\t6.6683\n",
      "\n",
      "Loss evaluation at time 759:\t6.6408\n",
      "\n",
      "Loss evaluation at time 760:\t6.6134\n",
      "\n",
      "Loss evaluation at time 761:\t6.5862\n",
      "\n",
      "Loss evaluation at time 762:\t6.5591\n",
      "\n",
      "Loss evaluation at time 763:\t6.5322\n",
      "\n",
      "Loss evaluation at time 764:\t6.5054\n",
      "\n",
      "Loss evaluation at time 765:\t6.4787\n",
      "\n",
      "Loss evaluation at time 766:\t6.4522\n",
      "\n",
      "Loss evaluation at time 767:\t6.4259\n",
      "\n",
      "Loss evaluation at time 768:\t6.3997\n",
      "\n",
      "Loss evaluation at time 769:\t6.3736\n",
      "\n",
      "Loss evaluation at time 770:\t6.3477\n",
      "\n",
      "Loss evaluation at time 771:\t6.3219\n",
      "\n",
      "Loss evaluation at time 772:\t6.2963\n",
      "\n",
      "Loss evaluation at time 773:\t6.2708\n",
      "\n",
      "Loss evaluation at time 774:\t6.2455\n",
      "\n",
      "Loss evaluation at time 775:\t6.2202\n",
      "\n",
      "Loss evaluation at time 776:\t6.1952\n",
      "\n",
      "Loss evaluation at time 777:\t6.1702\n",
      "\n",
      "Loss evaluation at time 778:\t6.1454\n",
      "\n",
      "Loss evaluation at time 779:\t6.1207\n",
      "\n",
      "Loss evaluation at time 780:\t6.0962\n",
      "\n",
      "Loss evaluation at time 781:\t6.0718\n",
      "\n",
      "Loss evaluation at time 782:\t6.0475\n",
      "\n",
      "Loss evaluation at time 783:\t6.0234\n",
      "\n",
      "Loss evaluation at time 784:\t5.9993\n",
      "\n",
      "Loss evaluation at time 785:\t5.9755\n",
      "\n",
      "Loss evaluation at time 786:\t5.9517\n",
      "\n",
      "Loss evaluation at time 787:\t5.9281\n",
      "\n",
      "Loss evaluation at time 788:\t5.9046\n",
      "\n",
      "Loss evaluation at time 789:\t5.8812\n",
      "\n",
      "Loss evaluation at time 790:\t5.8579\n",
      "\n",
      "Loss evaluation at time 791:\t5.8348\n",
      "\n",
      "Loss evaluation at time 792:\t5.8118\n",
      "\n",
      "Loss evaluation at time 793:\t5.7889\n",
      "\n",
      "Loss evaluation at time 794:\t5.7661\n",
      "\n",
      "Loss evaluation at time 795:\t5.7435\n",
      "\n",
      "Loss evaluation at time 796:\t5.7209\n",
      "\n",
      "Loss evaluation at time 797:\t5.6985\n",
      "\n",
      "Loss evaluation at time 798:\t5.6762\n",
      "\n",
      "Loss evaluation at time 799:\t5.6540\n",
      "\n",
      "Loss evaluation at time 800:\t5.6320\n",
      "\n",
      "Loss evaluation at time 801:\t5.6100\n",
      "\n",
      "Loss evaluation at time 802:\t5.5882\n",
      "\n",
      "Loss evaluation at time 803:\t5.5665\n",
      "\n",
      "Loss evaluation at time 804:\t5.5449\n",
      "\n",
      "Loss evaluation at time 805:\t5.5234\n",
      "\n",
      "Loss evaluation at time 806:\t5.5020\n",
      "\n",
      "Loss evaluation at time 807:\t5.4808\n",
      "\n",
      "Loss evaluation at time 808:\t5.4596\n",
      "\n",
      "Loss evaluation at time 809:\t5.4386\n",
      "\n",
      "Loss evaluation at time 810:\t5.4176\n",
      "\n",
      "Loss evaluation at time 811:\t5.3968\n",
      "\n",
      "Loss evaluation at time 812:\t5.3761\n",
      "\n",
      "Loss evaluation at time 813:\t5.3555\n",
      "\n",
      "Loss evaluation at time 814:\t5.3350\n",
      "\n",
      "Loss evaluation at time 815:\t5.3146\n",
      "\n",
      "Loss evaluation at time 816:\t5.2943\n",
      "\n",
      "Loss evaluation at time 817:\t5.2741\n",
      "\n",
      "Loss evaluation at time 818:\t5.2540\n",
      "\n",
      "Loss evaluation at time 819:\t5.2340\n",
      "\n",
      "Loss evaluation at time 820:\t5.2141\n",
      "\n",
      "Loss evaluation at time 821:\t5.1943\n",
      "\n",
      "Loss evaluation at time 822:\t5.1747\n",
      "\n",
      "Loss evaluation at time 823:\t5.1551\n",
      "\n",
      "Loss evaluation at time 824:\t5.1356\n",
      "\n",
      "Loss evaluation at time 825:\t5.1162\n",
      "\n",
      "Loss evaluation at time 826:\t5.0969\n",
      "\n",
      "Loss evaluation at time 827:\t5.0777\n",
      "\n",
      "Loss evaluation at time 828:\t5.0586\n",
      "\n",
      "Loss evaluation at time 829:\t5.0397\n",
      "\n",
      "Loss evaluation at time 830:\t5.0208\n",
      "\n",
      "Loss evaluation at time 831:\t5.0019\n",
      "\n",
      "Loss evaluation at time 832:\t4.9832\n",
      "\n",
      "Loss evaluation at time 833:\t4.9646\n",
      "\n",
      "Loss evaluation at time 834:\t4.9461\n",
      "\n",
      "Loss evaluation at time 835:\t4.9277\n",
      "\n",
      "Loss evaluation at time 836:\t4.9093\n",
      "\n",
      "Loss evaluation at time 837:\t4.8911\n",
      "\n",
      "Loss evaluation at time 838:\t4.8729\n",
      "\n",
      "Loss evaluation at time 839:\t4.8549\n",
      "\n",
      "Loss evaluation at time 840:\t4.8369\n",
      "\n",
      "Loss evaluation at time 841:\t4.8190\n",
      "\n",
      "Loss evaluation at time 842:\t4.8012\n",
      "\n",
      "Loss evaluation at time 843:\t4.7835\n",
      "\n",
      "Loss evaluation at time 844:\t4.7659\n",
      "\n",
      "Loss evaluation at time 845:\t4.7484\n",
      "\n",
      "Loss evaluation at time 846:\t4.7309\n",
      "\n",
      "Loss evaluation at time 847:\t4.7136\n",
      "\n",
      "Loss evaluation at time 848:\t4.6963\n",
      "\n",
      "Loss evaluation at time 849:\t4.6791\n",
      "\n",
      "Loss evaluation at time 850:\t4.6620\n",
      "\n",
      "Loss evaluation at time 851:\t4.6450\n",
      "\n",
      "Loss evaluation at time 852:\t4.6280\n",
      "\n",
      "Loss evaluation at time 853:\t4.6112\n",
      "\n",
      "Loss evaluation at time 854:\t4.5944\n",
      "\n",
      "Loss evaluation at time 855:\t4.5777\n",
      "\n",
      "Loss evaluation at time 856:\t4.5611\n",
      "\n",
      "Loss evaluation at time 857:\t4.5446\n",
      "\n",
      "Loss evaluation at time 858:\t26.9483\n",
      "\n",
      "Loss evaluation at time 859:\t26.9014\n",
      "\n",
      "Loss evaluation at time 860:\t26.8545\n",
      "\n",
      "Loss evaluation at time 861:\t26.8075\n",
      "\n",
      "Loss evaluation at time 862:\t26.7605\n",
      "\n",
      "Loss evaluation at time 863:\t4.8398\n",
      "\n",
      "Loss evaluation at time 864:\t26.6878\n",
      "\n",
      "Loss evaluation at time 865:\t26.6408\n",
      "\n",
      "Loss evaluation at time 866:\t26.5938\n",
      "\n",
      "Loss evaluation at time 867:\t26.5467\n",
      "\n",
      "Loss evaluation at time 868:\t5.0681\n",
      "\n",
      "Loss evaluation at time 869:\t26.4746\n",
      "\n",
      "Loss evaluation at time 870:\t26.4276\n",
      "\n",
      "Loss evaluation at time 871:\t26.3805\n",
      "\n",
      "Loss evaluation at time 872:\t26.3334\n",
      "\n",
      "Loss evaluation at time 873:\t26.2863\n",
      "\n",
      "Loss evaluation at time 874:\t5.3527\n",
      "\n",
      "Loss evaluation at time 875:\t26.2149\n",
      "\n",
      "Loss evaluation at time 876:\t5.3933\n",
      "\n",
      "Loss evaluation at time 877:\t5.3740\n",
      "\n",
      "Loss evaluation at time 878:\t5.3547\n",
      "\n",
      "Loss evaluation at time 879:\t5.3356\n",
      "\n",
      "Loss evaluation at time 880:\t5.3165\n",
      "\n",
      "Loss evaluation at time 881:\t5.2975\n",
      "\n",
      "Loss evaluation at time 882:\t5.2786\n",
      "\n",
      "Loss evaluation at time 883:\t5.2598\n",
      "\n",
      "Loss evaluation at time 884:\t5.2411\n",
      "\n",
      "Loss evaluation at time 885:\t5.2225\n",
      "\n",
      "Loss evaluation at time 886:\t5.2039\n",
      "\n",
      "Loss evaluation at time 887:\t5.1855\n",
      "\n",
      "Loss evaluation at time 888:\t5.1671\n",
      "\n",
      "Loss evaluation at time 889:\t5.1488\n",
      "\n",
      "Loss evaluation at time 890:\t5.1307\n",
      "\n",
      "Loss evaluation at time 891:\t5.1126\n",
      "\n",
      "Loss evaluation at time 892:\t5.0945\n",
      "\n",
      "Loss evaluation at time 893:\t5.0766\n",
      "\n",
      "Loss evaluation at time 894:\t5.0588\n",
      "\n",
      "Loss evaluation at time 895:\t5.0410\n",
      "\n",
      "Loss evaluation at time 896:\t5.0233\n",
      "\n",
      "Loss evaluation at time 897:\t5.0058\n",
      "\n",
      "Loss evaluation at time 898:\t4.9882\n",
      "\n",
      "Loss evaluation at time 899:\t4.9708\n",
      "\n",
      "Loss evaluation at time 900:\t4.9535\n",
      "\n",
      "Loss evaluation at time 901:\t4.9362\n",
      "\n",
      "Loss evaluation at time 902:\t4.9190\n",
      "\n",
      "Loss evaluation at time 903:\t4.9019\n",
      "\n",
      "Loss evaluation at time 904:\t4.8849\n",
      "\n",
      "Loss evaluation at time 905:\t4.8680\n",
      "\n",
      "Loss evaluation at time 906:\t4.8511\n",
      "\n",
      "Loss evaluation at time 907:\t4.8343\n",
      "\n",
      "Loss evaluation at time 908:\t4.8176\n",
      "\n",
      "Loss evaluation at time 909:\t4.8010\n",
      "\n",
      "Loss evaluation at time 910:\t4.7844\n",
      "\n",
      "Loss evaluation at time 911:\t4.7680\n",
      "\n",
      "Loss evaluation at time 912:\t4.7516\n",
      "\n",
      "Loss evaluation at time 913:\t4.7352\n",
      "\n",
      "Loss evaluation at time 914:\t4.7190\n",
      "\n",
      "Loss evaluation at time 915:\t4.7028\n",
      "\n",
      "Loss evaluation at time 916:\t4.6867\n",
      "\n",
      "Loss evaluation at time 917:\t4.6707\n",
      "\n",
      "Loss evaluation at time 918:\t4.6547\n",
      "\n",
      "Loss evaluation at time 919:\t4.6389\n",
      "\n",
      "Loss evaluation at time 920:\t4.6231\n",
      "\n",
      "Loss evaluation at time 921:\t4.6073\n",
      "\n",
      "Loss evaluation at time 922:\t4.5917\n",
      "\n",
      "Loss evaluation at time 923:\t4.5761\n",
      "\n",
      "Loss evaluation at time 924:\t4.5606\n",
      "\n",
      "Loss evaluation at time 925:\t4.5451\n",
      "\n",
      "Loss evaluation at time 926:\t4.5298\n",
      "\n",
      "Loss evaluation at time 927:\t4.5144\n",
      "\n",
      "Loss evaluation at time 928:\t4.4992\n",
      "\n",
      "Loss evaluation at time 929:\t4.4840\n",
      "\n",
      "Loss evaluation at time 930:\t4.4689\n",
      "\n",
      "Loss evaluation at time 931:\t4.4539\n",
      "\n",
      "Loss evaluation at time 932:\t4.4390\n",
      "\n",
      "Loss evaluation at time 933:\t4.4241\n",
      "\n",
      "Loss evaluation at time 934:\t4.4092\n",
      "\n",
      "Loss evaluation at time 935:\t4.3945\n",
      "\n",
      "Loss evaluation at time 936:\t4.3798\n",
      "\n",
      "Loss evaluation at time 937:\t4.3651\n",
      "\n",
      "Loss evaluation at time 938:\t4.3506\n",
      "\n",
      "Loss evaluation at time 939:\t4.3361\n",
      "\n",
      "Loss evaluation at time 940:\t4.3217\n",
      "\n",
      "Loss evaluation at time 941:\t4.3073\n",
      "\n",
      "Loss evaluation at time 942:\t4.2930\n",
      "\n",
      "Loss evaluation at time 943:\t4.2787\n",
      "\n",
      "Loss evaluation at time 944:\t4.2646\n",
      "\n",
      "Loss evaluation at time 945:\t4.2505\n",
      "\n",
      "Loss evaluation at time 946:\t4.2364\n",
      "\n",
      "Loss evaluation at time 947:\t4.2224\n",
      "\n",
      "Loss evaluation at time 948:\t4.2085\n",
      "\n",
      "Loss evaluation at time 949:\t4.1946\n",
      "\n",
      "Loss evaluation at time 950:\t4.1808\n",
      "\n",
      "Loss evaluation at time 951:\t4.1671\n",
      "\n",
      "Loss evaluation at time 952:\t4.1534\n",
      "\n",
      "Loss evaluation at time 953:\t4.1398\n",
      "\n",
      "Loss evaluation at time 954:\t4.1262\n",
      "\n",
      "Loss evaluation at time 955:\t4.1127\n",
      "\n",
      "Loss evaluation at time 956:\t4.0993\n",
      "\n",
      "Loss evaluation at time 957:\t4.0859\n",
      "\n",
      "Loss evaluation at time 958:\t4.0726\n",
      "\n",
      "Loss evaluation at time 959:\t4.0593\n",
      "\n",
      "Loss evaluation at time 960:\t4.0461\n",
      "\n",
      "Loss evaluation at time 961:\t4.0330\n",
      "\n",
      "Loss evaluation at time 962:\t4.0199\n",
      "\n",
      "Loss evaluation at time 963:\t4.0068\n",
      "\n",
      "Loss evaluation at time 964:\t3.9938\n",
      "\n",
      "Loss evaluation at time 965:\t3.9809\n",
      "\n",
      "Loss evaluation at time 966:\t3.9681\n",
      "\n",
      "Loss evaluation at time 967:\t3.9552\n",
      "\n",
      "Loss evaluation at time 968:\t3.9425\n",
      "\n",
      "Loss evaluation at time 969:\t3.9298\n",
      "\n",
      "Loss evaluation at time 970:\t3.9172\n",
      "\n",
      "Loss evaluation at time 971:\t3.9046\n",
      "\n",
      "Loss evaluation at time 972:\t3.8920\n",
      "\n",
      "Loss evaluation at time 973:\t3.8795\n",
      "\n",
      "Loss evaluation at time 974:\t3.8671\n",
      "\n",
      "Loss evaluation at time 975:\t3.8547\n",
      "\n",
      "Loss evaluation at time 976:\t3.8424\n",
      "\n",
      "Loss evaluation at time 977:\t3.8302\n",
      "\n",
      "Loss evaluation at time 978:\t3.8179\n",
      "\n",
      "Loss evaluation at time 979:\t3.8058\n",
      "\n",
      "Loss evaluation at time 980:\t3.7937\n",
      "\n",
      "Loss evaluation at time 981:\t3.7816\n",
      "\n",
      "Loss evaluation at time 982:\t3.7696\n",
      "\n",
      "Loss evaluation at time 983:\t3.7577\n",
      "\n",
      "Loss evaluation at time 984:\t3.7457\n",
      "\n",
      "Loss evaluation at time 985:\t3.7339\n",
      "\n",
      "Loss evaluation at time 986:\t3.7221\n",
      "\n",
      "Loss evaluation at time 987:\t3.7103\n",
      "\n",
      "Loss evaluation at time 988:\t3.6986\n",
      "\n",
      "Loss evaluation at time 989:\t3.6870\n",
      "\n",
      "Loss evaluation at time 990:\t3.6754\n",
      "\n",
      "Loss evaluation at time 991:\t3.6638\n",
      "\n",
      "Loss evaluation at time 992:\t3.6523\n",
      "\n",
      "Loss evaluation at time 993:\t3.6409\n",
      "\n",
      "Loss evaluation at time 994:\t23.5413\n",
      "\n",
      "Loss evaluation at time 995:\t23.5056\n",
      "\n",
      "Loss evaluation at time 996:\t23.4700\n",
      "\n",
      "Loss evaluation at time 997:\t23.4343\n",
      "\n",
      "Loss evaluation at time 998:\t23.3985\n",
      "\n",
      "Loss evaluation at time 999:\t23.3628\n",
      "\n",
      "Loss evaluation at time 1000:\t23.3270\n",
      "\n",
      "CPU times: user 2min 34s, sys: 603 ms, total: 2min 35s\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fpred, f, w, mean, t, loss = stochasticZFW(F, d, w0, method = \"IRDSA\", r=1, T=1000, eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12e987090>]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F(w_pred) = 181525.35998540587\n",
      "\n",
      "F(w) = 181548.68696763652\n",
      "\n",
      "w = [ 5.23105600e-05  1.57315358e-06  1.20546499e-08  1.41221084e-06\n",
      "  8.57775646e-05  1.66030158e-04  1.17959417e-01  8.79298339e-01\n",
      "  1.74521049e-03  2.87057150e-05  5.17760294e-04  3.39823294e-07\n",
      "  5.67333862e-07  1.01727444e-06  9.63924717e-07  1.88822163e-06\n",
      "  1.54709061e-06  2.07782710e-08  6.38127397e-07  6.93596671e-07\n",
      "  1.61734925e-06  1.37340846e-06  1.56981352e-06  1.64692333e-07\n",
      "  1.91960787e-06  1.94429340e-06  1.41479562e-06  3.39840463e-07\n",
      " -1.48618898e-05  7.39830121e-07  1.90022630e-06  3.50408370e-07\n",
      "  1.59961095e-06  9.77132823e-07  3.65768893e-07  6.18041258e-07\n",
      "  1.46576628e-06  1.82041291e-07  1.04983792e-06  1.99076184e-07\n",
      "  1.66399033e-06  1.93561704e-06  8.94293116e-07  4.80759533e-07\n",
      "  4.23719196e-07  3.12150923e-05  1.41407182e-06  2.53136805e-05\n",
      "  1.05644808e-06  1.02601942e-07  3.38289454e-07  3.19891704e-05\n",
      "  8.41086607e-07  1.65207175e-06]\n",
      "\n",
      "average w = [ 2.08459174e-03  1.98020707e-04  1.51737905e-06  1.77762040e-04\n",
      "  4.04725094e-03  5.89904609e-03  2.49391609e-01  6.90678393e-01\n",
      "  2.24283710e-02  2.11333187e-03  9.67307702e-03  4.27752571e-05\n",
      "  7.14131499e-05  1.28049420e-04  1.21334024e-04  2.37679898e-04\n",
      "  1.94740030e-04  2.61546487e-06  8.03242861e-05  8.73064809e-05\n",
      "  2.03583837e-04  1.72877789e-04  1.97600276e-04  2.07306474e-05\n",
      "  2.41630641e-04  2.44737932e-04  1.78087398e-04  4.27774183e-05\n",
      " -1.87074038e-03  9.31261165e-05  2.39190985e-04  4.41076536e-05\n",
      "  2.01351028e-04  1.22996594e-04  4.60411594e-05  7.77959434e-05\n",
      "  1.84503331e-04  2.29144475e-05  1.32148349e-04  2.50587147e-05\n",
      "  2.09454783e-04  2.43645795e-04  1.12569146e-04  6.05156062e-05\n",
      "  5.33356538e-05  2.17919974e-03  1.77996291e-04  2.18635953e-03\n",
      "  1.32980402e-04  1.29150195e-05  4.25821850e-05  2.02663682e-03\n",
      "  1.05871777e-04  2.07954532e-04]\n",
      "\n",
      "T = 1000\n"
     ]
    }
   ],
   "source": [
    "print(f'OUTPUT:\\n\\nF(w_pred) = {fpred}\\n\\nF(w) = {f}\\n\\nw = {w}\\n\\naverage w = {mean}\\n\\nT = {t}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeroth order stochastic accelerated gradient method with inexact updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InexactUpdate(g, d, v, r, gamma, mu):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    - g: gradient approximation \n",
    "    - d: dimension\n",
    "    - v: starting point\n",
    "    - r: radius\n",
    "    - gamma: decreasing coefficient\n",
    "    - mu: threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    haty = v\n",
    "    t = 1\n",
    "    while True:\n",
    "        # ARGMIN PROBLEM\n",
    "        ht1 = g + gamma*(haty - v)\n",
    "        i_k = np.argmax(np.abs(ht1))\n",
    "        ei = e(i_k, d) * r\n",
    "        yt = np.sign(-ht1[i_k]) * ei\n",
    "        if np.dot(ht1, yt - haty) >= - mu:\n",
    "            break\n",
    "        else:\n",
    "            haty = (t-1)/(t+1) * haty + 2/(t+1)*yt\n",
    "            t +=1\n",
    "    \n",
    "    return haty\n",
    "    \n",
    "\n",
    "L = 2/X.shape[0] * norm(X.T @ X)\n",
    "# D = 2*r\n",
    "B = 1\n",
    "\n",
    "\n",
    "def IZFW(F, d, w0, L, B, r = 1, T = 100, eps = 1e-6):\n",
    "    \"\"\"\n",
    "    INPUT\n",
    "    - F: loss function\n",
    "    - d: dimension\n",
    "    - w0: starting point\n",
    "    - L: lipschitz\n",
    "    - B: 1\n",
    "    - r: radius of the ball\n",
    "    - T: max iteration\n",
    "    - eps: tolerance\n",
    "    \"\"\"\n",
    "    \n",
    "    alpha = lambda t: 2/(t+2)\n",
    "    gamma = lambda t: 4*L/t\n",
    "    mu = lambda t: L*2*r/(t*T)\n",
    "    m = lambda t: 1000#t * (t+1) / 2*r * np.max([(d+5)*B*T, d+3])\n",
    "    c = 1 / (np.sqrt(2*T)) * np.max([1/(d+3), np.sqrt(2*r/(d*(T+1)))]) # smoothing parameter now fixed\n",
    "    \n",
    "    loss = []\n",
    "    v, w = w0, w0\n",
    "    partial = 0\n",
    "    \n",
    "    for t in range(1, T+1):\n",
    "        dt = (1-alpha(t)) * w + alpha(t) * v\n",
    "        g = IRDSA(F, dt, int(np.ceil(m(t))), c, d)\n",
    "        v = InexactUpdate(g, d, v, r, gamma(t), mu(t)) #ICG\n",
    "        w_pred = w\n",
    "        w = (1 - alpha(t)) * w + alpha(t) * v\n",
    "        partial += w\n",
    "        loss_eval = np.abs(F(w_pred) - F(w))\n",
    "        loss.append(loss_eval)\n",
    "        print(f\"Loss evaluation at time {t}:\\t{loss_eval:.4f}\\n\")\n",
    "        if loss_eval < eps: break # check stopping condition\n",
    "    return F(w_pred), F(w), w, partial/T, t, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I parametri degli algoritmi (L per deterministic FW e IGC + tutti quelli di IGC che sono collegati al gradiente, tipo varianza del grad e grad stesso)\n",
    "\n",
    "I grafici uguali o no? Che differenza c'è tra # oracolo e # di iterazioni? (Loss disponibile solo a fine chiamate oracolo)\n",
    "\n",
    "I dataset: il primo ok, secondo stesso preprocessing ma abbiamo risultati diversi, il terzo non sappiamo cos'è e come si usa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss evaluation at time 1:\t320442.8827\n",
      "\n",
      "Loss evaluation at time 2:\t57384.8266\n",
      "\n",
      "Loss evaluation at time 3:\t13680.5950\n",
      "\n",
      "Loss evaluation at time 4:\t12292.4937\n",
      "\n",
      "Loss evaluation at time 5:\t1789.5429\n",
      "\n",
      "Loss evaluation at time 6:\t5529.8398\n",
      "\n",
      "Loss evaluation at time 7:\t3539.5671\n",
      "\n",
      "Loss evaluation at time 8:\t2407.7284\n",
      "\n",
      "Loss evaluation at time 9:\t1714.8834\n",
      "\n",
      "Loss evaluation at time 10:\t1266.1618\n",
      "\n",
      "Loss evaluation at time 11:\t962.3049\n",
      "\n",
      "Loss evaluation at time 12:\t748.9804\n",
      "\n",
      "Loss evaluation at time 13:\t594.6753\n",
      "\n",
      "Loss evaluation at time 14:\t480.2226\n",
      "\n",
      "Loss evaluation at time 15:\t393.4907\n",
      "\n",
      "Loss evaluation at time 16:\t326.5382\n",
      "\n",
      "Loss evaluation at time 17:\t274.0130\n",
      "\n",
      "Loss evaluation at time 18:\t1134.4838\n",
      "\n",
      "Loss evaluation at time 19:\t339.4222\n",
      "\n",
      "Loss evaluation at time 20:\t1018.0201\n",
      "\n",
      "Loss evaluation at time 21:\t379.4279\n",
      "\n",
      "Loss evaluation at time 22:\t328.5088\n",
      "\n",
      "Loss evaluation at time 23:\t286.3929\n",
      "\n",
      "Loss evaluation at time 24:\t251.2445\n",
      "\n",
      "Loss evaluation at time 25:\t221.6710\n",
      "\n",
      "Loss evaluation at time 26:\t196.6024\n",
      "\n",
      "Loss evaluation at time 27:\t175.2069\n",
      "\n",
      "Loss evaluation at time 28:\t783.4365\n",
      "\n",
      "Loss evaluation at time 29:\t739.5783\n",
      "\n",
      "Loss evaluation at time 30:\t696.4437\n",
      "\n",
      "Loss evaluation at time 31:\t297.6351\n",
      "\n",
      "Loss evaluation at time 32:\t268.4829\n",
      "\n",
      "Loss evaluation at time 33:\t634.7776\n",
      "\n",
      "Loss evaluation at time 34:\t278.3615\n",
      "\n",
      "Loss evaluation at time 35:\t591.5255\n",
      "\n",
      "Loss evaluation at time 36:\t284.0566\n",
      "\n",
      "Loss evaluation at time 37:\t553.4518\n",
      "\n",
      "Loss evaluation at time 38:\t286.6601\n",
      "\n",
      "Loss evaluation at time 39:\t262.8885\n",
      "\n",
      "Loss evaluation at time 40:\t241.7017\n",
      "\n",
      "Loss evaluation at time 41:\t508.5884\n",
      "\n",
      "Loss evaluation at time 42:\t245.6675\n",
      "\n",
      "Loss evaluation at time 43:\t227.1446\n",
      "\n",
      "Loss evaluation at time 44:\t210.4579\n",
      "\n",
      "Loss evaluation at time 45:\t195.3843\n",
      "\n",
      "Loss evaluation at time 46:\t464.0739\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-ec34768f444d>\u001b[0m in \u001b[0;36mIZFW\u001b[0;34m(F, d, w0, L, B, r, T, eps)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIRDSA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInexactUpdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#ICG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mw_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-ec57065f0da8>\u001b[0m in \u001b[0;36mIRDSA\u001b[0;34m(F, w, m, c, d)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mF_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mF_w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-ec57065f0da8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mF_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mF_w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-af15dedb837a>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# define the objective function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    562\u001b[0m             raise ValueError(\"Scalar operands are not allowed, \"\n\u001b[1;32m    563\u001b[0m                              \"use '*' instead\")\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rmatmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;31m# Fast path for the most common case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_mul_vector\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;31m# csr_matvec or csc_matvec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_matvec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fpred, f, w, mean, t, loss = IZFW(F, d, w0, L, B, r = 1, T = 300, eps = 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fec891ea090>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'OUTPUT:\\n\\nF(w_pred) = {fpred}\\n\\nF(w) = {f}\\n\\nw = {w}\\n\\naverage w = {mean}\\n\\nT = {t}')# m=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT:\n",
      "\n",
      "F(w_pred) = 198152.00822366346\n",
      "\n",
      "F(w) = 198018.65622128965\n",
      "\n",
      "w = [4.47739238e-02 1.14471662e-03 4.80743181e-09 5.63194071e-07\n",
      " 4.20009460e-07 2.08194264e-07 3.76933956e-01 5.25665416e-01\n",
      " 2.27723602e-02 4.47070249e-07 2.64906774e-02 1.35522585e-07\n",
      " 2.20039787e-03 4.05692205e-07 3.84416172e-07 7.53028653e-07\n",
      " 6.16984540e-07 8.28643904e-09 2.54487188e-07 2.76608507e-07\n",
      " 6.45003906e-07 5.47719559e-07 6.26046507e-07 6.56798139e-08\n",
      " 7.65545583e-07 7.75390248e-07 5.64224887e-07 1.35529433e-07\n",
      " 3.59236773e-07 2.95046551e-07 7.57816151e-07 1.39743946e-07\n",
      " 6.37929816e-07 3.89683605e-07 1.45869771e-07 2.46476774e-07\n",
      " 5.84552147e-07 7.25986323e-08 4.18678626e-07 7.93922008e-08\n",
      " 6.63604513e-07 7.71930090e-07 3.56646873e-07 1.91728395e-07\n",
      " 1.68980532e-07 6.62042126e-07 5.63936236e-07 6.65867503e-07\n",
      " 4.21314775e-07 4.09179734e-08 1.34910885e-07 1.84971298e-07\n",
      " 3.35427952e-07 6.58851346e-07]\n",
      "\n",
      "average w = [2.18088624e-02 5.61318427e-03 7.23518488e-07 8.47607077e-05\n",
      " 6.32114238e-05 3.13332367e-05 3.41893760e-01 5.85978471e-01\n",
      " 2.39068738e-02 6.72840725e-05 1.35136211e-02 2.03961491e-05\n",
      " 4.49321245e-03 6.10566769e-05 5.78546338e-05 1.13330812e-04\n",
      " 9.28561732e-05 1.24710908e-06 3.83003219e-05 4.16295803e-05\n",
      " 9.70730878e-05 8.24317936e-05 9.42199993e-05 9.88481199e-06\n",
      " 1.15214610e-04 1.16696232e-04 8.49158455e-05 2.03971796e-05\n",
      " 5.40651343e-05 4.44045059e-05 1.14051331e-04 2.10314639e-05\n",
      " 9.60084372e-05 5.86473826e-05 2.19534005e-05 3.70947545e-05\n",
      " 8.79750981e-05 1.09260942e-05 6.30111331e-05 1.19485262e-05\n",
      " 9.98724792e-05 1.16175478e-04 5.36753544e-05 2.88551235e-05\n",
      " 2.54315700e-05 9.96373400e-05 8.48724035e-05 1.00213059e-04\n",
      " 6.34078736e-05 6.15815500e-06 2.03040882e-05 2.78381804e-05\n",
      " 5.04819067e-05 9.91571276e-05]\n",
      "\n",
      "T = 300\n"
     ]
    }
   ],
   "source": [
    "print(f'OUTPUT:\\n\\nF(w_pred) = {fpred}\\n\\nF(w) = {f}\\n\\nw = {w}\\n\\naverage w = {mean}\\n\\nT = {t}')#100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = lambda t: t * (t+1) / 2*1 * np.max([(d+5)*1*100, d+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29795000.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
